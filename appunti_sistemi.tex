\documentclass[a4paper]{report}
\usepackage[italian]{babel}
\usepackage[latin1]{inputenc}
\usepackage[T1]{fontenc}
\usepackage[pdftex]{graphicx}
\usepackage{subfig}
\usepackage[pdftex,colorlinks=true]{hyperref} 
\hypersetup{linkcolor=blue}
\usepackage{amssymb}
\usepackage{verbatim}
\usepackage{enumitem}

\hypersetup{ colorlinks,
  linkcolor=blue,
  filecolor=green,
  urlcolor=blue,
  citecolor=blue }

\usepackage[normalem]{ulem}

\usepackage[intlimits,sumlimits]{amsmath}
\usepackage{amsthm}
\usepackage{mathrsfs}

\def\xcolorversion{2.00}
\def\xkeyvalversion{1.8}
\usepackage[version=0.96]{pgf}
\usepackage{tikz}
\usepackage{pgf}
\usetikzlibrary{automata,arrows,decorations.pathmorphing,backgrounds,fit,petri,shapes}
\tikzstyle{int}=[draw, fill=blue!20, minimum size=2em]
\tikzstyle{init} = [pin edge={to-,thin,black}]
\tikzstyle{pallino}=[circle,thick,draw=blue!75,fill=blue!20,minimum size=6mm]
\newtheorem{teorema}{Teorema}
\renewcommand{\arraystretch}{2}
\newtheorem{definizione}{Definizione}
\newtheorem{dimostrazione}{Dimostrazione}
\newcommand{\bo}{\bfseries } 

\usepackage{makeidx}
\makeindex

%\sloppy

\author{Collettivo studentesco Ingegneria Informatica Unisannio}
\title{Appunti di Sistemi}
\begin{document}
\maketitle
\setlength{\unitlength}{2cm}
	\begin{picture}(1,1)
  \put(0,0){\line(0,1){1}}
  \put(0,0){\line(1,0){1}}
  \put(0,0){\line(1,1){1}}
  \put(0,0){\line(1,2){.5}}
  \put(0,0){\line(1,3){.3333}}
  \put(0,0){\line(1,4){.25}}
  \put(0,0){\line(1,5){.2}}
  \put(0,0){\line(1,6){.1667}}
  \put(0,0){\line(2,1){1}}
  \put(0,0){\line(2,3){.6667}}
  \put(0,0){\line(2,5){.4}}
  \put(0,0){\line(3,1){1}}
  \put(0,0){\line(3,2){1}}
  \put(0,0){\line(3,4){.75}}
  \put(0,0){\line(3,5){.6}}
  \put(0,0){\line(4,1){1}}
  \put(0,0){\line(4,3){1}}
  \put(0,0){\line(4,5){.8}}
  \put(0,0){\line(5,1){1}}
  \put(0,0){\line(5,2){1}}
  \put(0,0){\line(5,3){1}}
  \put(0,0){\line(5,4){1}}
  \put(0,0){\line(5,6){.8333}}
  \put(0,0){\line(6,1){1}}
  \put(0,0){\line(6,5){1}}
\end{picture}

\section*{Prefazione}
\emph{Il presente documento \`e stato scritto con lo scopo di aiutare
  lo studente che deve affrontare l'esame di TEORIA DEI SISTEMI a ripetere
  gli argomenti trattati durante il corso, riassumendo i concetti
  fondamentali del programma. Tale documento NON deve assolutamente
  essere usato in sostituzione dei libri di testo.}
\tableofcontents

\chapter{Introduzione}

\section{Il controllo}
I \emph{problemi di controllo} hanno lo scopo di determinare le azioni
da compiere su di un processo assegnato, in modo tale che si ottenga
per esso il \emph{funzionamento desiderato}. Il processo, o
\emph{sistema sotto controllo}, \`e quell'oggetto su cui il problema
\`e posto. Il funzionamento desiderato \`e, invece, riferito al fatto
che l'andamento nel tempo delle variabili in gioco debba coincidere con
quello di altre variabili assegnate. 

Si identificano quindi: 
\begin{itemize}
\item \emph{variabili controllate}, cio\`e le grandezze di interesse;
\item \emph{segnale di riferimento}, cio\`e l'andamento desiderato
  delle variabili controllate, detto anche \emph{set-point}) nel
  caso sia un segnale costante;
\end{itemize}
Idealmente l'obiettivo di un generico problema di controllo \`e quello
di ottenere 
\begin{equation} 
  \label{eq:obiettivodiprog}
  \emph{variabile controllata} = \emph{segnale di riferimento} 
\end{equation}
Per ottenere tale risultato, si deve poter agire sul processo
attraverso le cosiddette \emph{variabili di controllo} che sono
assegnabili e manipolabili da chi effettua il controllo.
Esistono, per\`o, anche altre variabili da cui dipendono le variabili
controllate e sono i cosiddetti \emph{disturbi}, i quali non sono
manipolabili e influenzano il comportamento del processo. Dato che i
disturbi non sono noti a priori, \`e necessario definire quindi delle
incertezze. 

Bisogna ricordare che tutte le variabili che fanno parte di un
processo di controllo sono funzioni del tempo, solitamente
\emph{continuo}, ovvero descritte da una variabile reale,
convenzionalmente indicata con \textbf{t}. 

L'andamento della variabile di controllo \`e determinato da un organo
detto \emph{controllore} o \emph{regolatore}. In particolare l'insieme 
\framebox{processo + controllore} forma il \emph{sistema di controllo}.

\section{Specifiche di progetto}
Dalla relazione \ref{eq:obiettivodiprog} si evince che, essendo essa
una relazione \textit{ideale}, \`e di fatto irraggiungibile. Nella
realt\`a la relazione \ref{eq:obiettivodiprog} diventa: 
\begin{equation}\label{eq:obiettivoreale}
  \emph{variabile controllata}  \simeq \emph{segnale di riferimento}
\end{equation} 
e, introducendo l'\emph{errore} del sistema, abbiamo:
\begin{equation}\label{eq:deferrore}
  \emph{errore}  = \emph{segnale di riferimento} - \emph{variabile controllata}
\end{equation}
L'obiettivo, quindi, \`e quello di minimizzare quanto pi\`u possibile
l'errore in tutte le condizioni di funzionamento di interesse tenendo
conto dei vincoli sul valore minimo e massimo della variabile di
controllo per evitare eccessive sollecitazioni sul processo. 

\section{Controllo Feedforward e Feedback}
Un'importante classificazione del controllo \`e quella effettuata in base alle informazioni possedute dal regolatore (da non confondere con quelle del progettista del controllore). Tale classificazione definisce:
\begin{description}
\item[Controllo Feedforward]{\emph{(o controllo in anello aperto o ad
    azione diretta)}}: quando il controllore possiede informazioni
  solo sul segnale di riferimento ed eventualmente sul disturbo
  (figura \ref{fig:fig1})
\begin{figure}[!h]
  \begin{center}
    \includegraphics[scale=0.5]{./figures/feedforward.png}
    \caption{Feedforward Control}
    \label{fig:fig1}
  \end{center}
\end{figure}
\item[Controllo Feedback]{\emph{(o controllo in anello chiuso o in
    retroazione o feedback)}} (figura \ref{fig:fig2}): quando il
  controllore ha a disposizione anche la variabile controllata. 
\begin{figure}[!h]
  \begin{center}
    \includegraphics[scale=0.5]{./figures/feedback.png}\caption{Feedback Control}\label{fig:fig2}
  \end{center}
\end{figure}  
\end{description}
In particolare, nel controllo retroazionato, si vede che l'azione di
controllo impressa al processo in $t = \bar t$, dipende anche dalla
variabile controllata per $ t \leq \bar t$.

\section{Modelli matematici}
Al fine di affrontare nel modo giusto un problema di controllo, \`e
molto conveniente studiarlo prima in termini puramente
matematici. Ci\`o vuol dire che tutte le specifiche di
progetto (sull'errore e sul controllo) devono essere espresse in
termini formali ed inoltre \`e necessario disporre anche di una
descrizione matematica degli elementi che compaiono nel sistema di
controllo. Il modello matematico \`e, dunque, un insieme di relazioni matematiche
quali equazioni algebriche, differenziali, etc., che descrivono il
sistema di controllo formalizzando le variabili che interconnettono i
singoli componenti. 

{\em Un sistema ha infiniti modelli. Un modello rappresenta infiniti
  sistemi.}

\chapter{Sistemi dinamici a tempo continuo}
\section{Concetti fondamentali}
\subsection{Variabili di ingresso, stato e uscita}
Un sistema dinamico a tempo continuo \`e un modello
matematico di un oggetto fisico che interagisce con il mondo che lo
circonda attraverso due vettori di variabili dipendenti dal tempo $t$: 
\begin{itemize}
\item{\emph{variabili di ingresso}}: sono le azioni che vengono
  compiute sull'oggetto in esame da agenti esterni che ne influenzano
  il comportamento;
\item{\emph{variabili di uscita}}: \`e quanto del comportamento
  dell'oggetto stesso \`e di interesse. 
\end{itemize}
In particolare esiste un rapporto di \emph{causa-effetto} tra le
variabili di ingresso e quelle di uscita. Un sistema dinamico a tempo
continuo \`e schematizzato in figura \ref{fig:fig3}.
\begin{figure}[!h]
  \begin{center}
    \includegraphics[scale=0.5]{./figures/dynasys.png}
    \caption{Sistema Dinamico}\label{fig:fig3}
  \end{center}
\end{figure}  

\subsection{Rappresentazione I-S-U}
Formalizzando la definizione di sistema dinamico a tempo continuo
abbiamo le seguenti equazioni:
\begin{equation}\label{eq:eqstato}
  \dot{x}(t)=f(x(t),u(t),t)
\end{equation}
\begin{equation}\label{eq:eqout}
  y=g(x(t),u(t),t)
\end{equation}
che formano la cosiddetta \emph {rappresentazione I-S-U
  (Ingresso-Stato-Uscita)} o pi\`u semplicemente
\emph{rappresentazione di stato} del sistema.
L'equazione \ref{eq:eqstato} \`e la \emph{equazione di stato},
mentre la \ref{eq:eqout} \`e la \emph{trasformazione
  d'uscita}. Il numero \textbf{n} delle variabili di stato di un
sistema definisce l'\emph{ordine} del sistema. In figura
\ref{fig:fig4} \`e schematizzato un sistema dinamico a tempo continuo
con la sua equazione di stato e trasformazione d'uscita.
\begin{figure}[!h]
  \begin{center}
    \includegraphics[scale=0.5]{./figures/dynaeq.png}
    \caption{Sistema dinamico con equazioni di stato e trasformazione
      d'uscita}
    \label{fig:fig4}
  \end{center}
\end{figure} 

L'equazione di stato mette in relazione con l'ingresso le variabili
che descrivono la situazione interna del sistema, mentre la
trasformazione di uscita, sulla base di tale situazione e
dell'ingresso applicato in uno specifico istante \textbf{t}, consente
di determinare l'uscita all'istante \textbf{t}. 
% Per gli esempi consultare il testo di riferimento \cite{FCA} 

Nello scegliere le variabili di stato di un sistema, bisogna tener
conto che esse ci aiutano a capire quanto sia necessario conoscere
della situazione interna o della \emph{storia passata} del sistema per
poter calcolare l'uscita. 

Nei sistemi fisici, la situazione interna \`e generalmente definita da
accumuli di energia, quantit\`a di moto, massa e, quindi, pu\`o essere
opportuno scegliere come variabili di stato quelle da cui queste
grandezze dipendono. Ad esempio:
\begin{itemize}
\item nei sistemi elettrici \`e conveniente utilizzare come variabili
  di stato le tensioni dei condensatori o le correnti degli induttori,
  perch\`e da queste dipendono gli accumuli di energia elettrica e magnetica;
\item nei sistemi meccanici \`e utile usare, invece, posizione e
  velocit\`a come variabili di stato, perch\`e legate ad accumuli di
  energia potenziale, quantit\`a di moto ed energia cinetica;
\item nei sistemi termodinamici si possono usare come variabili di
  stato le temperature, perch\`e da esse dipendono le energie termiche
  immagazzinate.
\end{itemize}

\subsection{Classificazione dei sistemi}
I sistemi possono essere: 
\begin{itemize}
\item[**]{\textbf {Sistemi monovariabili e multivariabili (SISO e
    MIMO)}}: i sistemi SISO (\emph{Single Input Single Output}) sono
  dotati di una sola variabile di ingresso ed una sola variabile
  d'uscita; i sistemi MIMO (\emph{Multiple Input Multiple Output})
  sono gli altri.
\item[**]{\textbf{Sistemi propri, strettamente propri e non
    dinamici}}: in generale un sistema si dice \emph{proprio} quando
  il legame ingresso-uscita \`e di tipo differenziale. In questo caso,
  il tempo ha un'importanza notevole, poich\`e la relazione tra $x$ e
  $y$ non \`e immediata.

  Nei sistemi propri, per conoscere il valore dell'uscita occorre
  sapere necessariamente due informazioni: 
  \begin{itemize}
  \item la condizione iniziale, cio\`e il valore dell'uscita in un
    istante prefissato;
  \item l'insieme dei valori che l'ingresso assume all'istante di osservazione.
  \end{itemize}
  Per questo motivo, i sistemi propri vengono definiti {\em sistemi con
  memoria}, poich\`e l'uscita in un determinato istante $t$ dipende
  sia dal valore dell'ingresso in quell'instante sia da quanto \`e
  successo in precedenza; se,
  invece, la trasformazione d'uscita pu\`o essere espressa nella forma
  \begin{equation}\label{eq:eqstrpr}
    y(t) = g(x(t),t)
  \end{equation}
  ovvero se l'uscita dipende solo dallo stato e non dall'ingresso, allora il
  sistema si dice \emph{strettamente proprio}\index{Sistema
    strettamente proprio} o \emph{puramente dinamico}\index{Sistema
    puramente dinamico}; se, infine, l'uscita \`e nella forma
  \begin{equation}\label{eq:eqstaticsys}
    y(t) = g(u(t),t)
  \end{equation} ovvero se l'uscita dipende solo dall'ingresso e non c'\`e
  alcuno stato, allora il sistema \`e un particolare sistema proprio
  detto \emph{sistema non dinamico o statico}\index{Sistema non
    dinamico}\index{Sistema statico}.
\item[**]{\textbf{Sistemi invarianti e varianti nel tempo}}
Nel caso in cui le funzioni $f$ e $g$ non dipendano esplicitamente dal
tempo, allora il sistema si dice \emph{invariante nel tempo} o
\emph{stazionario}. In particolare si ha: 
\begin{equation}\label{eq:ltisys}
  \dot{x}(t) = f(x(t),u(t))
\end{equation}
\begin{equation}\label{eq:ltisys2}
  y(t)=g(x(t),u(t))
\end{equation}
Invece, se anche una sola delle funzioni $f$ e $g$ dipende
esplicitamente da $t$, il sistema si dice \emph{variante nel tempo} ed
in questo caso le equazioni del sistema sono le gi\`a note
\ref{eq:eqstato} e \ref{eq:eqout}.

\item[**]{\textbf{Sistemi lineari e non lineari}}: se le equazioni del
  sistema sono combinazioni lineari delle varie
componenti dei vettori $x(t)$ e $u(t)$, allora il sistema si dice
\emph{lineare}, altrimenti \`e \emph{non lineare}. La rappresentazione
I-S-U, espressa in forma matriciale, del generico sistema lineare
tempo invariante (LTI) \`e la seguente: 
\begin{equation}\label{eq:matltisys}
  \dot{x}(t)=Ax(t)+Bu(t)
\end{equation}
\begin{equation}
  y(t)=Cx(t)+Du(t)
\end{equation}
dove:
\begin{itemize}
\item {A \`e detta \emph{matrice della dinamica}. La sua dimensione
  \`e $[n \times n]$, dove n \`e il numero di variabili di
  stato}~\footnote{N.B. Se il sistema \`e T.V.(Tempo Variante) allora
  le matrici sono funzioni del tempo};
\item{B \`e la \emph{matrice degli ingressi}. La sua dimensione \`e
  $[n\times m]$, dove m \`e il numero degli ingressi};
\item{C \`e la \emph{matrice delle uscite}. Dimensionalmente \`e
  $[p\times n]$, dove p \`e il numero di uscite};
\item{D \`e la \emph{matrice di trasmissione}. Vale zero se
  non esiste un legame ingresso-uscita. La sua dimensione \`e
  $[p\times m]$}.
\end{itemize}
\end{itemize}

\section{Risposta impulsiva}
L'impulso \`e un artificio matematico usato per rappresentare segnali
brevi, ma intensi. In particolare si definisce l'\emph{impulso di
  Dirac} come:
\begin{displaymath}
\textrm{imp(t)}=\delta(t) = \left\{ \begin{array}{ll}
 1 & \textrm{if $t=0$}\\
 0 & \textrm{if $t\neq0$}\\
  \end{array} \right.
\end{displaymath}
Le sue propriet\`a sono:
\begin{enumerate}
\item {$P_\varepsilon(t)\ge 0$}
\item {$P_\varepsilon(t)=0$} all'esterno di [0,$\varepsilon$]
\item{$\int_{0}^{\varepsilon}P_\varepsilon(\tau) d\tau=1$} ha area
  unitaria $\forall \varepsilon$ 
\item{$\delta(t)\triangleq  \lim_{\varepsilon \rightarrow \infty}
  P_\varepsilon(t) $} 
\item{$\int_{-\infty}^{+\infty}\delta(t)dt=1$}
\item {$\int_{-\infty}^{+\infty}\delta(t)f(t)dt=f(0)$ Campionamento}
\end{enumerate}

\textsl{Se al sistema applichiamo un impulso, esso risponder\`a con i
  suoi \textbf{MODI NATURALI}}. 
\subsection{Risposta impulsiva del sistema}
In generale:
\begin{equation}
  Y_F(s)=G(s)U(s)\label{eq:eqlaprispf}
\end{equation}
se 
$$u(t)=\delta(t) \Rightarrow Y_F(s)=G(s)\cdot 1\Rightarrow
Y_F(s)=G(s) \stackrel
{{\mathfrak{L^{-1}}}}{\longrightarrow}\protect
g(t)=y_f(t)$$ 
con $\mathfrak{L}^{-1}$ pari all'\emph{Antitrasformata di Laplace}
(vedere Appendice \ref{apx:laplace})\\
\textbf{La risposta impulsiva \`e:}
\begin{equation}\label{eq:eqpulseresp}
  \protect\mathfrak{L}^{-1}[G(s)\mathfrak{L}(\delta(t)]
\end{equation}

\section{Equilibrio e punti di equilibrio}
Prendendo in considerazione i sistemi stazionari ed applicando ad essi
ingressi costanti, indicati come $u(t) = \bar{u}(t)$, si hanno
movimenti dello stato e dell'uscita anch'essi costanti nel
tempo. Questi movimenti costanti sono detti rispettivamente {\em
  stati} ed \emph{uscite di equilibrio}.

Per definizione: "Uno stato di equilibrio (o \emph{steady
  state})\index{Stato di equilibrio}\index{Steady state} \`e 
uno stato in cui un sistema, sollecitato da un ingresso costante, in
un qualunque istante di tempo, permane in questo stato
indefinitamente"~\footnote{Se il sistema da solo va in posizione di
  equilibrio, allora il punto di equilibrio \`e detto
  \emph{attrattivo}\index{Punto di equilibrio attrattivo} e il sistema
  \`e asintoticamente stabile} ovvero, se in $\bar{t}$ il sistema si
trova nello stato $x(\bar{t})=\bar{x}$, allora $\forall t >\bar{t}$,
il sistema si trover\`a nello stesso stato $x(t)=\bar{x}$.

In termini matematici, gli stati di equilibrio devono soddisfare
l'equazione $\dot{x}(t)=0$, cio\`e sono le soluzioni $\bar{x}$
costanti nel tempo dell'equazione: 
\begin{equation}\label{eq:eqsteady}
  f(\bar{x},\bar{u})=0
\end{equation}
A ciascuna delle soluzioni (se ne esistono), corrisponde un'uscita di
equilibrio $\bar{y}$, calcolabile mediante la relazione 
\begin{equation}\label{eq:outsteady}
  \bar{y}=g(\bar{x},\bar{u})
\end{equation}
In particolare, gli stati di equilibrio $\bar{x}$ sono le soluzioni
dell'equazione: 
\begin{equation}
  A\bar{x}+B\bar{u} = 0
\end{equation}
e ad ogni stato di equilibrio corrisponde un'uscita di equilibrio:
\begin{equation}
  \bar{y}=C\bar{x}+D\bar{u}
\end{equation}

\subsection{La matrice $A$}
La matrice $A$ \`e detta matrice della dinamica\index{Matrice della
  dinamica}\index{Matrice Jacobiana}\index{Jacobiano}, matrice
Jacobiana o Jacobiano. Ha dimensioni $n \times n$, con $n$ grado del sistema e numero
di variabili di stato. Se $A$ \`e invertibile, cio\`e se $det(A) \neq
0$, lo stato di equilibrio \`e:
\[
  \begin{array}{l}
    \bar{x} = -A^{-1} B \bar{u}\\
    \bar{y} = ( -C A^{-1} B + D) \bar{u}
  \end{array}
\]
La matrice $[D - CA^{-1} B]$ \`e il {\bf guadagno
  statico}\index{Guadagno statico}, una costante che rappresenta il
rapporto tra uscita ed ingresso a regime, quando, cio\`e, il
transitorio \`e esaurito. Se $det(A) = 0$ 
\[
  A \bar{x} + B \bar{u} = 0
\]
ammette infinite soluzioni o nessuna soluzione. Ci\`o implica infiniti
possibili stati di equilibrio o nessuno stato di equilibrio. In questo
caso la nozione di guadagno statico perde senso.

\section{Stabilit\`a}
Il criterio di stabilit\`a fu introdotto dal matematico
\href{http://it.wikipedia.org/wiki/Aleksandr_Michajlovi\%C4\%8D_Ljapunov}{Liapunov}. Liapunov
considerava che ``piccole'' perturbazioni dello stato
iniziale, rispetto ad un valore di riferimento, provocano solo ``piccole''
perturbazioni del movimento dello stato, che si annulleranno
eventualmente su tempi lunghi. 

\subsection{Stabilit\`a dell'equilibrio}
Si considera un sistema dinamico T.I. con ingresso costante
$u(t)=\bar{u}$, con $t \ge 0$, e un corrispondente stato di equilibrio
$\bar{x}$ detto \emph{nominale}. Inoltre si considera anche un
movimento dello stato $x(t)$, detto \emph{perturbato}, generato a
partire da $\bar{u}$ e da uno stato iniziale $x_0$.

Possiamo affermare che: \emph{"Uno stato di equilibrio si dice stabile
  se, ad una perturbazione arbitrariamente piccola, il movimento
  perturbato rimane ``vicino'' all'equilibrio nominale. \`E instabile
  se si ha un allontanamento dello stato del sistema dall'equilibrio
  stesso"}.

Definito ``polo dominante''\index{Polo dominante} come il polo che si
trova pi\`u a destra degli altri, di seguito mostriamo la tabella che
riassume i tipi di sistemi classificati secondo la stabilit\`a: 

\begin{table}[hbp!]
  \begin{center}
    \begin{tabular}[hbp!]{|c|p{5cm}|}
      \hline
      \multicolumn{2}{|c|}{STABILITA'} \\
      \hline
      \hline
      TIPO & Definizione \\
      \hline
      \hline
      \hline
      ASINTOTICAMENTE STABILE & Tutti i MODI NATURALI sono
      convergenti, ovvero tutti i poli sono a sinistra (il \emph{polo
        dominante} \`e a sinistra)\\ 
      \hline
      MARGINALMENTE STABILE & Non esistono modi naturali divergenti, ma ne
      esiste uno, o pi\`u di uno, limitato che non tende a $0$, ovvero il polo
      dominante \`e sull'asse immaginario \\ 
      \hline
      INSTABILE & Esiste un modo divergente, ovvero il polo dominante
      \`e a destra\\
      \hline
      DEBOLMENTE INSTABILE & Non esistono modi divergenti esponenziali, ma
      ne esiste uno divergente ``debolmente'' (ad esempio, potenze della
      $t$ che crescono pi\`u lentamente dell'esponenziale), ovvero il polo \`e
      sull'asse immaginario con molteplicit\`a maggiore di $1$.\\
      \hline
    \end{tabular}
    \caption{Stabilit\`a dei sistemi}
    \label{tab:tab1}
  \end{center}
\end{table}

\chapter{Sistemi LTI a tempo continuo}
\section{Evoluzione di un sistema}
Nei movimenti dello stato e dell'uscita di un sistema, si pu\`o
individuare un contributo dipendente solo dallo stato iniziale e uno
dipendente solo dall'ingresso. 

\begin{description}
\item[Evoluzione libera]\index{Evoluzione libera} (o movimenti
liberi) \`e il contributo al movimento dello stato e dell'uscita
funzione solo dello stato iniziale, ovvero quello che, a parit\`a di
stato iniziale, si avrebbe se l'ingresso fosse nullo. 
\item[Evoluzione forzata]\index{Evoluzione forzata} \`e il contributo
funzione solo dell'ingresso, ovvero quello che si avrebbe se, a parit\`a
di ingresso, lo stato iniziale fosse nullo. 
\end{description}
Il sistema LTI (Lineare Tempo Invariante) a tempo continuo \`e descritto
dalle equazioni \ref{eq:matltisys}. In questa sezione vengono
presentati due schemi riassuntivi che descrivono i modi di tali
sistemi con autovalori distinti e doppi.

La rappresentazione grafica viene effettuata sul piano
complesso\index{Piano complesso} o piano di Gauss\index{Piano di
  Gauss}. Il piano di Gauss pu\`o essere pensato come un piano
cartesiano modificato affinch\`e l'asse $x$ rappresenti la parte reale
({\em asse reale}) e l'asse $y$ rappresenti la parte immaginaria ({\em
asse immaginario}) di un numero complesso. Nel nostro caso il piano di
Gauss ci consentir\`a di avere una localizzazione chiara dei vari tipi
di poli dei nostri sistemi.

\section{Sistema del primo ordine}
L'evoluzione libera di un sistema del primo ordine ha un andamento di
tipo esponenziale: 
\[
y(t) = e^{\lambda t}
\]
Tale esponenziale, \`e convergente se $\lambda < 0$ , costante se
$\lambda = 0$, divergente se $\lambda > 0$.

\section{Sistema del secondo ordine}
\subsubsection{Poli distinti}
\begin{figure}[!h]
  \begin{center}
    \includegraphics[scale=0.7]{./figures/modisingol.png}
    \caption{Modi dei sistemi con autovalori distinti}\label{fig:modising}
  \end{center}
\end{figure} 
La figura \ref{fig:modising} mostra l'andamento dei modi naturali, o
risposta impulsiva, dei sistemi del secondo ordine, secondo il tipo di
poli del sistema.

\begin{description}
\item[A] Il polo dominante \`e a sinistra dell'asse immaginaria,
  cio\`e \`e a parte reale negativa e parte immaginaria
  nulla. Il sistema \`e asintoticamente stabile. L'andamento della
  funzione di uscita \`e di tipo esponenziale negativo:
  \[
  y_l(t) = k_1 e^{at} + k_2 e^{bt}
  \]
\item[B] Il polo dominante \`e complesso a parte reale negativa. Il sistema \`e
  asintoticamente stabile. L'andamento \`e una sinusoide di ampiezza
  sempre minore. La funzione di uscita \`e
  \[
  y_l(t) = k_1 e^{\alpha t}sin(\omega t) + k_2 e^{\alpha t}cos(\omega t)
  \]
  con $\alpha < 0$: l'oscillazione \`e convergente;
\item[C] Il polo dominante si trova nell'origine degli assi. Il
  sistema \`e marginalmente stabile. La funzione di uscita \`e pari a
  $y_l(t) = k_1 e^{at} + k_2 e^{bt}$. Se consideriamo $a = 0$, la
  funzione sar\`a una semiretta costante di ordinata $k_1$;
\item[D] Il polo dominante \`e complesso a parte reale nulla. Il
  sistema \`e marginalmente stabile. La funzione \`e una sinusoide
  costante, a media nulla;
\item[E] Il polo dominante \`e complesso a parte reale positiva. Il
  sistema \`e instabile; diverge come una sinusoide di ampiezza sempre
  maggiore. La funzione di uscita \`e
  \[
  y_l(t) = k_1 e^{\alpha t}sin(\omega t) + k_2 e^{\alpha t}cos(\omega t)
  \]
  con $\alpha > 0$.
\item[F] Il polo dominante ha parte reale positiva. Il sistema \`e
  instabile. La funzione \`e un esponenziale positivo.
\end{description}

Nota: nel caso di poli complessi, la risposta in evoluzione libera
pu\`o anche  porsi nella forma:
\[
y_l(t) = A e^{\alpha t} sin(\omega t + \beta)
\]
dove
\[
A = \sqrt{k^2_1 + k^2_2}
\]
\[
\beta = arctan \dfrac{k_2}{k_1}
\]

\subsubsection{Poli doppi}
\begin{figure}[!h]
  \begin{center}
    \includegraphics[scale=0.7]{./figures/modidoppi.png}
    \caption{Modi dei sistemi con autovalori doppi}\label{fig:modidop}
  \end{center}
\end{figure}
La figura \ref{fig:modidop} mostra l'andamento dei modi naturali, o
risposta impulsiva, dei sistemi del secondo ordine, secondo il tipo di
poli del sistema.

\begin{description}
\item[A] I poli sono a parte reale negativa. La funzione presenta una
  sovraelongazione prima di convergere;
\item[B] I poli sono complessi a parte reale negativa. Il sistema \`e
  asintoticamente stabile. L'andamento \`e una sinusoide di ampiezza
  sempre minore;
\item[C] I poli giacciono nell'origine degli assi. Il sistema \`e
  instabile. La funzione diverge con una pendenza inferiore ad un
  esponenziale, ma diverge;
\item[D - E] I poli sono complessi a parte reale nulla o positiva. In
  entrabi i casi, il sistema \`e instabile e la funzione \`e una
  sinusoide di ampiezza sempre maggiore;
\item[F] I poli sono reali a parte reale positiva. Il sistema \`e
  instabile. La funzione diverge esponenzialmente.
\end{description}

Nel caso dei modi con autovalori doppi, notiamo che le funzioni
partono dall'origine degli assi. Questo comportamento \`e facilmente
dimostrabile analizzando la risposta al gradino di sistemi del secondo
ordine con poli coincidenti. Risolvendo la risposta al gradino per $t
= 0$
\[
y(t) = \mu \left(1 - e^{- \frac{t}{T}} - \dfrac{t}{T}e^{- \frac{t}{T}}\right)
\]
notiamo che il punto di partenza \`e effettivamente lo
zero. Calcolandone la derivata prima, otteniamo la pendenza. Con la
derivata seconda, si ottiene la concavit\`a e la convessit\`a.

\section{Criteri di stabilit\`a}
In un sistema stazionario lineare, la determinazione delle propriet\`a
di stabilit\`a dipende solo dal movimento libero. Inoltre, anche il
calcolo del movimento libero pu\`o essere evitato in quanto \`e possibile
verificare condizioni di asintotica stabilit\`a e instabilit\`a,
valutando esclusivamente gli autovalori del sistema. Nell'appendice
\ref{apx:jacob} viene mostrato come valutare la stabilit\`a dei punti
di equilibrio di un sistema, attraverso il calcolo della matrice
\textsl{Jacobiana}. 
Seguono tre importanti teoremi sulla stabilit\`a dei sistemi:
\newtheorem{Th1}{Teorema}[section]
\newtheorem{Th2}[Th1]{Teorema}
\newtheorem{Th3}[Th1]{Teorema}
\newtheorem{Th4}[Th1]{Teorema}
 
\begin{Th1}\label{th:th1}
  Lo stato di equilibrio di un sistema lineare stazionario \`e stabile,
  asintoticamente stabile o instabile se e solo se tutti gli stati di
  equilibrio del sistema sono rispettivamente stabili, asintoticamente
  stabili o instabili. 
\end{Th1}

\begin{Th2}\label{th:th2}
  Un sistema lineare stazionario \`e stabile se e solo se tutti i
  movimenti liberi dello stato sono limitati, cio\`e non vanno
  all'infinito, per tutte le $t \geq 0$ e per tutti gli stati iniziali;
  \`e asintoticamente stabile se e solo se tutti i movimenti liberi dello
  stato sono tendenti a zero per $t \to \infty$; \`e instabile se e solo
  se almeno un movimento libero dello stato \`e divergente (ovvero non
  limitato).
\end{Th2}

\begin{Th3}\label{th:th3}
  Un sistema lineare stazionario \`e asintoticamente stabile se e solo
  se tutti i suoi autovalori hanno parte reale negativa ($\Re<0$).
\end{Th3}

\begin{Th4}\label{th:th4}
  Un sistema lineare stazionario \`e instabile se e solo se almeno uno
  dei suoi autovalori ha parte reale positiva ($\Re>0$).
\end{Th4}

\subsubsection{Propriet\`a dei sistemi asintoticamente stabili}
\begin{itemize}
\item Il movimento asintotico coincide con quello forzato, visto che
  il movimento libero tende ad annullarsi;
\item La risposta all'impulso tende a zero, poich\`e coincide con un
  movimento libero;
\item La risposta ad un qualunque ingresso di durata limitata tende a
  zero in modo asintotico;
\item Lo stato e l'uscita di equilibrio conseguenti ad un qualunque
  ingresso $u(t) = \bar{u}$ sono unici.
\end{itemize}

\subsection{Teorema di Routh}\label{pg:routh}\index{Teorema di Routh}
Il metodo utilizzato per valutare la stabilit\`a asintotica di un
sistema senza calcolare la sua evoluzione libera, cio\`e senza la
risoluzione di un'equazione differenziale, \`e quello definito
attraverso l'applicazione del \textsl{Teorema di Routh}.
Il Teorema di Routh prende in considerazione gli autovalori di un
sistema e ne valuta il segno. In particolare si utilizza il
\emph{polinomio caratteristico} nel dominio di Laplace:~\footnote{Vedere Appendice \ref{apx:laplace}}
\begin{equation}\label{eq:polycarat}
  \varphi(s)=det(sI-A)=s^n+p_1s^{n-1}+p_2s^{n-2}+\ldots+p_{n-1}s+p_n
\end{equation}
dove $n$ \`e il grado dell'equazione polinomiale e si considera l'\emph{equazione caratteristica}:
\begin{displaymath}
  \varphi(s)=0
\end{displaymath}

Applicando il teorema ~\ref{th:th3}, si pu\`o valutare l'asintotica
stabilit\`a valutando i coefficienti del polinomio
caratteristico~\ref{eq:polycarat} scritto in forma pi\`u generale:
\begin{equation}\label{eq:polycaratgen}
  \varphi(s)=\varphi_0 s^n+\varphi_1s^{n-1}+\varphi_2s^{n-2}+\ldots+\varphi_{n-1}s+\varphi_n ~con ~\varphi_0 \ne 0
\end{equation}

Si osservi inoltre che
\begin{equation}\label{eq:phigen}
  \varphi(s)=\varphi_0 \prod_{i=1}^{n}(s-s_i)
\end{equation}
per cui, se il sistema \`e asintoticamente stabile,
risulta $$\sum_{i=1}^n s_i < 0$$

\newtheorem{Th5}{Teorema}[section]
\begin{Th5}\label{th:th5}
  Se il sistema ~\ref{eq:matltisys} \`e asintoticamente stabile
  $\Rightarrow$ i coefficienti $\varphi_i$, $i=0,1,\ldots,n$, del
  polinomio caratteristico ~\ref{eq:polycarat} sono concordi, ovvero
  hanno tutti lo stesso segno.
\end{Th5}
A dimostrazione del teorema ~\ref{th:th5} si pu\`o imporre nella
~\ref{eq:phigen} la condizione
\begin{displaymath}
  \Re (s_i) < 0
\end{displaymath}

\subsubsection{Applicazione del Teorema di Routh}
Attraverso la definizione della cosiddetta {\em tabella di Routh},
\`e possibile formulare una condizione necessaria e sufficiente di
asintotica stabilit\`a. 
Tale tabella si costruisce a partire dal polinomio
caratteristico~\ref{eq:polycarat} ed ha $n + 1$ righe e una struttura
triangolare: ogni $2$ righe (eccetto la prima se $n$ \`e
pari), il numero di elementi (colonne) diminuisce di 1. 
In particolare la tabella si costruisce come segue:\\
\begin{center}
  \begin{tabular}{|r|l|}
    \hline
    potenze & coefficienti\\
    \hline
    n &
    $\varphi_0  ~\varphi_2 ~\varphi_4 ~\ldots ~\ldots$\\
    n-1 &
    $\varphi_1 ~\varphi_3  ~ \varphi_5  \ldots~\ldots$\\n-2 &
    $a_1 ~a_2 ~a_3 ~\ldots$\\
    n-3&
    $b_1 ~b_2 ~b_3 ~\ldots$\\
    n-4&
    $c_1 ~c_2 ~c_3 ~..$\\
    \ldots &\ldots ~\ldots\\
    1 &\ldots ~..\\
    0 & \ldots
  \end{tabular}
\end{center}
Le prime due righe contengono i coefficienti del polinomio
caratteristico in ordine, fino all'esaurimento. Successivamente i
coefficienti $a$, $b$ e $c$ si calcolano in base agli elementi delle
righe che li precedono, ovvero:
\begin{equation}
  a_1=-\frac{1}{\varphi_1}det\left(\left[
    \begin{array}{cc}
      \varphi_0 & \varphi_{2} \\
      \varphi_1&\varphi_{3}
    \end{array}
    \right]\right)
\end{equation}
\begin{equation}
  a_2=-\frac{1}{\varphi_1}det\left(\left[
    \begin{array}{cc}
      \varphi_0 & \varphi_4 \\
      \varphi_1 &\varphi_5
    \end{array}
    \right]\right)
\end{equation}
\begin{center}
  \begin{displaymath}
    \vdots
  \end{displaymath}
\end{center}
\begin{equation}
  b_1=-\frac{1}{a_1}det\left(\left[
    \begin{array}{cc}
      \varphi_1 & \varphi_3 \\
      a_1 &a_2
    \end{array}
    \right]\right)
\end{equation}
\begin{equation}
  b_2=-\frac{1}{a_1}det\left(\left[
    \begin{array}{cc}
      \varphi_1 & \varphi_5 \\
      a_1 &a_3
    \end{array}
    \right]\right)
\end{equation}
\begin{center}
  \begin{displaymath}
    \vdots
  \end{displaymath}
\end{center}
\begin{equation}
  c_1=-\frac{1}{b_1}det\left(\left[
    \begin{array}{cc}
      a_1 & a_2 \\
      b_1 &b_2
    \end{array}
    \right]\right)
\end{equation}
\begin{equation}
  c_2=-\frac{1}{b1_1}det\left(\left[
    \begin{array}{cc}
      a_1 & a_3 \\
      b_1 &b_3
    \end{array}
    \right]\right)
\end{equation}
\begin{center}
  \begin{displaymath}
    \vdots
  \end{displaymath}
\end{center}

Dopo aver effettuato tali calcoli si pu\`o affermare che:
\newtheorem{Th6}{Teorema}[section]
\begin{Th6}\label{th:routh}
Il sistema ~\ref{eq:matltisys} \`e asintoticamente stabile
se la tabella di Routh \`e ben definita e tutti gli elementi
della prima colonna sono di segno concorde. 
Il numero di radici nel semipiano a parte reale positiva \`e pari ai
cambiamenti di segno presenti nella prima colonna dell matrice di
Routh.
\end{Th6}
Una tabella di Routh \`e ``ben definita'' se tra gli elementi della
prima colonna non \`e presente alcuno zero. Per approfondimenti vedere
l'appendice ~\ref{apx:stabil}.

Se ne ricava che, supposto il coefficiente $\phi_0 > 0$ della equazione
\ref{eq:polycarat}, condizione necessaria e sufficiente perch\`e tutte
le radici nella \ref{eq:polycarat} siano a parte reale negativa \`e
che tutti i coefficienti della prima colonna della tabella di Routh
siano positivi. 

\section{Linearizzazione}
Prendiamo in considerazione un generico sistema MIMO, non lineare,
T.I. e proprio, descritto dalle equazioni precedentemente esposte
(\ref{eq:ltisys}) e sollecitato da un ingresso costante $u(t)=\bar{u}$. \\
Si fa poi riferimento al suo stato di equilibrio, ovvero quello stato
per cui vale l'identit\`a:
\begin{equation}
  0 = f(\bar{x},\bar{u})~\footnote{La dipendenza dal tempo \`e implicita,
    per cui la variabile \emph{t} pu\`o essere omessa}
\end{equation} a cui corrisponde l'uscita di equilibrio:
\begin{equation}
  \bar{y}=g(\bar{x},\bar{u})
\end{equation}
Il procedimento della \emph{linearizzazione} consiste nel descrivere
il comportamento di un sistema NL (Non Lineare) attorno al suo punto
di equilibrio nominale, approssimandolo ad un sistema lineare.
Pertanto si pone:
\begin{eqnarray}
  u(t)=\bar{u}+\delta u(t)\\
  x(t)=\bar{x}+\delta x(t)\\
  y(t)=\bar{y}+\delta y(t)\\
  x_{t_0}=\bar{x}+\delta x_{t_0}
\end{eqnarray}
dove $\delta u(t)$, $\delta x(t)$, $\delta y(t)$ e $\delta x_{t_0}$
rappresentano le variazioni (scostamenti) di $ u, x, y $ e dello stato
$x_{t_0}$. Con queste considerazioni, le equazioni \ref{eq:ltisys} e
\ref{eq:ltisys2} diventano:  
\begin{equation}\label{eq:linstate}
  \dot{\bar{x}}+\delta \dot{x}(t)=f(\bar{x}+\delta x(t),\bar{u} +\delta u(t))
\end{equation}
\begin{equation}\label{eq:linout}
  \bar{y}+\delta y(t)=g(\bar{x}+\delta x(t), \bar{u}+\delta u(t))
\end{equation} assumendo come condizione iniziale:
\begin{equation}\label{eq:lincondin}
  \bar{x}+\delta x(t_0)=\bar{x}+\delta x_{t_0}
\end{equation}
Ricordiamo che la ``serie di Taylor''\index{Serie di Taylor} di una
funzione $f$, definita in un intervallo aperto e derivabile infinite
volte, \`e espressa come una serie di potenze:
\begin{equation}\label{eq:serieDiTaylor}
  T(x) = \sum_{n=0}^{\infty} \dfrac{f^{(n)}(a)}{n!} (x - a)^n
\end{equation}
dove $f^{(n)}a$ \`e la derivata ennesima di $f$ valutata in $a$, ossia
la derivata parziale ennesima di $f$.
Sviluppando in serie di Taylor e troncando lo sviluppo al primo termine otteniamo:
\begin{equation}\label{eq:statetaylor}
  \delta \dot{x}(t)=f(\bar{x},\bar{u})+\frac{\partial f(x,u)}{\partial
    x} \Bigg |_{x=\bar{x},u=\bar{u}}\delta x(t)+\frac{\partial
    f(x,u)}{\partial u} \Bigg |_{x=\bar{x},u=\bar{u}}\delta u(t)
\end{equation}
\begin{equation}\label{eq:outtaylor}
  \bar{y}+\delta y(t)=g(\bar{x},\bar{u})+\frac{\partial
    g(x,u)}{\partial x} \Bigg |_{x=\bar{x},u=\bar{u}}\delta
  x(t)+\frac{\partial g(x,u)}{\partial u} \Bigg
  |_{x=\bar{x},u=\bar{u}}\delta u(t) 
\end{equation}
Combinando le \ref{eq:statetaylor} e \ref{eq:outtaylor} con le
\ref{eq:linstate}, \ref{eq:linout} e \ref{eq:lincondin} si ha : 
\begin{eqnarray}\label{eq:linsys}
  \left\{ \begin{array}{l}
    \delta \dot{x}(t)=A \delta x(t) + B \delta u(t)\\
    \delta y(t)=C \delta x(t) + \delta u(t)\\
    \delta x((t_0)=\delta x_{t_0}
  \end{array}\right.
\end{eqnarray}
dove:
\begin{eqnarray}\label{eq:linmatr}
  A=\frac{\partial f(x,u)}{\partial x} \Bigg |_{x=\bar{x},u=\bar{u}}\\
  B=\frac{\partial f(x,u)}{\partial u} \Bigg |_{x=\bar{x},u=\bar{u}}\\
  C=\frac{\partial g(x,u)}{\partial x }\Bigg |_{x=\bar{x},u=\bar{u}}\\
  D=\frac{\partial g(x,u)}{\partial u} \Bigg |_{x=\bar{x},u=\bar{u}}
\end{eqnarray}
In particolare, prendendo ad esempio un sistema del secondo ordine,
ovvero con due stati $x_1$ e $x_2$, avente le  matrici dimensionate
come segue: 
A[2x2], B[1x2], C[2x1] e D=0 e caratterizzato dalla seguente
rappresentazione ISU: 
\begin{equation}
  \left\{ \begin{array}{l}
    \dot{x_1}=f_1(x_1,x_2,u)\\
    \dot{x_2}=f_2(x_1,x_2,u)\\
    y=g(x_1, x_2, u)
  \end{array}\right.
\end{equation}
 
Le matrici del modello linearizzato (\ref{eq:linsys}) si calcolano in
questo modo: 
\begin{displaymath}\label{eq:matrix}
\mathbf{A} =
\left( \begin{array}{cc}
\frac{\partial f_1(x_1,x_2,u)}{\partial x_1}  & \frac{\partial f_1(x_1,x_2.u)}{\partial x_2} \\
\frac{\partial f_2(x_1,x_2.u)}{\partial x_1}  & \frac{\partial f_2(x_1,x_2,u)}{\partial x_2} \\
\end{array} \right)\Bigg |_{x_1=\bar{x_1},x_2=\bar{x_2},u=\bar{u}}\\
\end{displaymath}
\begin{displaymath}
\mathbf{B} =
\left( \begin{array}{c}
\frac{\partial f_1(x_1,x_2,u)}{\partial u}\\
\frac{\partial f_2(x_1,x_2.u)}{\partial u} 
\end{array} \right)\Bigg |_{x_1=\bar{x_1},x_2=\bar{x_2},u=\bar{u}}
\end{displaymath}
\begin{displaymath}
\mathbf{C} =
\left( \begin{array}{cc}
\frac{\partial g(x_1,x_2,u)}{\partial x_1}  & \frac{\partial g(x_1,x_2.u)}{\partial x_2} \\
\end{array} \right)\Bigg |_{x_1=\bar{x_1},x_2=\bar{x_2},u=\bar{u}}
\end{displaymath}

Abbiamo cos\`i ottenuto un sistema lineare e stazionario che lega le
variabili prime delle variabili in gioco che prende il nome di {\em
  sistema linearizzato} e che \`e di fondamentale importanza per
descrivere in maniera approssimata il comportamento del sistema in
esame attorno al punto di equilibrio stabile considerato, tenendo
presenti le sufficientemente piccole variazioni degli ingressi
($\delta{u}$) e dello stato iniziale ($\delta{x_{t0}}$) e delle
conseguenti variazioni dello stato ($\delta{x}$) e dell'uscita
($\delta{y}$).

\subsection{Stabilit\`a dell'equilibrio}
\begin{teorema}
  Lo stato di equilibrio $\bar{x}$, relativo all'ingresso $\bar{u}$, di un
  sistema non lineare risulta asintoticamente stabile se tutti gli
  autovalori del sistema linearizzato hanno parte reale negativa.
\end{teorema}
Va da se che si pu\`o evitare il calcolo degli autovalori e limitarsi a
valutare il polinomio caratteristico, sulla base del Teorema \ref{th:routh}.

%% FUNZIONE DI TRASFERIMENTO
\chapter{Funzione di Trasferimento}
\`E una nuova rappresentazione dei sistemi dimanici a tempo continuo
lineari e stazionari. Essa mette in relazione tra loro le trasformate
di Laplace delle variabili di ingresso e di uscita.

\section{Definizione della funzione di trasferimento}
Si considera il sistema \ref{eq:matltisys}. Applicando le
trasformate di Laplace (vedi appendice \ref{apx:laplace}) ad ambo i
membri si ha: 
\begin{displaymath}
  sX(s) - x(0) = AX(s) + BU(s)
\end{displaymath}
\begin{displaymath}
  Y(s) = CX(s) + DU(s)
\end{displaymath}
Proseguendo:
\[
  sX(s) - AX(s) = BU(s) + x(0)
\]
Per mettere in evidenza $X(s)$, dobbiamo moltiplicare $s$ per la
matrice identit\`a: \`e impossibile sottrarre la matrice $A$ allo
scalare $s$.
\[
  X(s)(SI - A) = BU(s) + x(0)
\]
Iterando, si ottengono le seguenti equazioni: 
\begin{eqnarray}\label{eq:tdlstateout}
  X(s)=\underbrace{(sI-A)^{-1}BU(s)}_{\mathfrak{L}\{Risposta \; forzata\}} +
  \underbrace{(sI-A)^{-1}x(0)}_{\mathfrak{L}\{Risposta \; libera\}}\\
  Y(s)=\underbrace{(C(sI-A)^{-1}B+D)U(s)}_{\mathfrak{L}\{Risposta \;
      forzata\}} +
  \underbrace{C(sI-A)^{-1}x(0)}_{\mathfrak{L}\{Risposta \; libera\}}
\end{eqnarray}
che rappresentano le trasformate di Laplace del movimento dello stato
e dell'uscita. In particolare, considerando le condizioni iniziali nulle si ha:
\begin{equation}\label{eq:transfout}
  Y(s)=G(s)U(s)
\end{equation}
Si definisce pertanto:
\begin{equation}\label{eq:fdt}
  G(s) \triangleq (C(sI-A)^{-1}B+D) \qquad
  \textrm{\emph{funzione/matrice di trasferimento}} 
\end{equation}
Effettuando l'antitrasformazione di Laplace (appendice
\ref{apx:laplace}) della \ref{eq:transfout}, si pu\`o conoscere il
movimento forzato $y_f$ che, nel caso di stato iniziale nullo,
coincide con il movimento d'uscita $y$.

Nel caso di sistemi SISO, se
$u(t)=\delta(t) \stackrel{\mathfrak{L}}{\Rightarrow} U(s)=1$ allora
\[
Y(s)=G(s)
\]
ovvero si pu\`o interpretare la funzione di trasferimento come la
trasformata di Laplace della risposta impulsiva (\ref{eq:eqpulseresp}). 

\subsection{Struttura della funzione di trasferimento}
In generale la \ref{eq:fdt} \`e una funzione razionale in $s$ data dal
rapporto di due polinomi ovvero: 
\begin{equation}\label{eq:genfdt}
  G(s)=\frac{N(s)}{D(s)}=\frac{\beta_\nu s^\nu+\beta_{\nu-1}s^{\nu-1}+
    \ldots+\beta_1s+\beta_0}{\alpha_\nu s^\nu+\alpha_{\nu-1}s^{\nu-1}+
    \ldots+\alpha_1s+\alpha_0}
\end{equation} 
Senza perdita di generalit\`a, si pu\`o considerare $D(s)$ come
polinomio monico, cio\`e $\alpha_\nu=1$.

\begin{itemize}
\item Se il sistema \`e strettamente proprio\index{Sistema
  strettamente proprio}, allora il grado del
  denominatore $D(s)$ sar\`a maggiore  del grado del numeratore $N(s)$.
\item Se il sistema \`e proprio\index{Sistema proprio}, allora il
  grado del denominatore $D(s)$ sar\`a pari al grado del numeratore
  $N(s)$. 
\item Per i sistemi impropri\index{Sistema improprio} il grado del
  numeratore $N(s)$ sar\`a maggiore del grado del denominatore $D(s)$.
\end{itemize}
La differenza tra il grado di $D(s)$ e quello di $N(s)$ \`e detta
\emph{\textbf{grado relativo}}\index{Grado relativo} ed indica la
\emph{prontezza del sistema}.

\subsubsection{Poli e zeri}
Le \emph{singolarit\`a} di un sistema \`e l'insieme dei \textbf{poli} e
degli \textbf{zeri}. Per definizione:
\begin{description}
\item[Poli] sono i valori che annullano il denominatore $D(s)$. Essi
  sono anche le radici dell'equazione $det(sI - A) = 0$, cio\`e sono gli
  autovalori del sistema;
\item[Zeri] sono i valori che annullano il numeratore $N(s)$.
\end{description}

\subsection{Relazione tra funzione di trasferimento ed equazioni
  differenziali} 
Considerando un sistema rappresentato dall'equazione differenziale:
\begin{displaymath}
  \frac{d^n y(t)}{dt^n}+\alpha_{n-1}\frac{d^{n-1} y(t)}{dt^{n-1}} +
  \ldots+\alpha_{1}\frac{dy(t)}{dt} + \alpha_0y(t)=
\end{displaymath}\label{eq:gendiffsys}
\begin{equation}
  =\beta_n\frac{d^n u(t)}{dt^n} + \beta_{n-1}\frac{d^{n-1}
    u(t)}{dt^{n-1}} + \ldots+\beta_{1}\frac{du(t)}{dt}+\beta_0u(t)
\end{equation}
ed effettuando per ambo i membri la trasformata di Laplace, tenendo
conto delle sue propriet\`a di derivazione, ed imponendo 
\begin{displaymath}
  y(0)=0 ~, \qquad \frac{d^iy(0)}{dt^i}=0 ~, \qquad i=1,2,\ldots,n-1
\end{displaymath}
si ha:
\begin{displaymath}
  s^nY(s)+\alpha_{n-1}s^{n-1}Y(s)+\ldots+\alpha_1sY(s)+\alpha_0Y(s)=
\end{displaymath}
\begin{equation}\label{eq:lapgendiffsys}
  = \beta_n s^nU(s)+\beta_{n-1}s^{n-1}U(s)+\ldots+\beta_1sU(s)+\beta_0U(s)
\end{equation}
da cui
\begin{equation}\label{eq:secgenfdt}
  \frac{Y(s)}{U(s)}=G(s)\triangleq \frac{\beta_n
    s^n+\beta_{n-1}s^{n-1} +
    \ldots+\beta_1s+\beta_0}{s^n+\alpha_{n-1}s^{n-1} + \ldots+\alpha_1s+\alpha_0}
\end{equation}

\subsection{Cancellazioni e stabilit\`a}
Quando valutiamo la $G(s)$, pu\`o capitare che ci siano radici comuni
tra numeratore e denominatore. Questa eventualit\`a pu\`o portarci nello
scenario in cui il numero di poli $v$ sia minore del numero degli $n$
autovalori del polinomio. Com'\`e noto la $G(s)$, nota anche come
rappresentazione esterna, descrive il legame tra l'ingresso e l'uscita
del sistema. Questo ci porta a considerare che gli autovalori che non
coincidono con i poli di $G(s)$ siano associati a parti ``nascoste''
del sistema. In questo caso, gli autovalori potrebbero perfino avere
parte reale positiva.

In definitva, per assicurarci che il polinomio caratteristico descriva
adeguatamente il sistema e ci garantisca l'asintotica stabilit\`a,
dobbiamo accertarci dell'assenza di cancellazioni di radici. Quando
nel calcolo della $G(s)$ non avvengono semplificazioni, il
denominatore coincide con il polinomio caratteristico ed i poli
coincidono con gli autovalori: la sola conoscenza dei poli \`e
sufficiente ad accertare la stabilit\`a del sistema.

\subsection{Ritardo di tempo}
\begin{equation}\label{eq:ritardoDiTempo}
  y(t) = u(t - \tau)
\end{equation}
L'equazione \ref{eq:ritardoDiTempo} descrive il ritardo di tempo, un
sistema lineare stazionario. Applicando la trasformata di Laplace ad
entrabi i membri otteniamo:
\[
  Y(s) = e^{- \tau s} U(s)
\]
che ci porta alla seguente funzione di trasferimento:
\[
  G(s) = e^{- \tau s}
\]
Se essa \`e moltiplicata per una generica funzione di trasferimento
$G'(s)$, le valutazioni si spostano su quest'ultima e solo alla fine
si applica la traslazione ai risultati ottenuti.

\section{Parametri della funzione dei trasferimento e sue rappresentazioni}
Molto spesso \`e conveniente rappresentare la G(s) di un sistema SISO in
uno di questi due modi:
\begin{equation}\label{eq:firstformfdt}
  G(s)=\dfrac{\rho \prod_i(s+z_i) \prod_i(s^2+2 \zeta_i \alpha_{ni}s +
    \alpha^{2}_{ni})}{s^g \prod_i(s+p_i) \prod_i(s^2+2 \xi_i
    \omega_{ni}s + \omega^2_{ni})}
\end{equation}
\begin{equation}\label{eq:secformfdt}
  G(s)= \dfrac{\mu \prod_i(1 + \tau_i s) \prod_i\left(1+\dfrac{2 \zeta_i
      s}{\alpha_{ni}} + \dfrac{s^2}{\alpha^{2}_{ni}}\right)}{s^g
    \prod_i (1+T_i s) \prod_i\left(1+\dfrac{2 \xi_i s} {\omega_{ni}} +
    \dfrac{s^2}{\omega^2_{ni}}\right)}
\end{equation}
Nelle equazioni \ref{eq:firstformfdt} e ~\ref{eq:secformfdt} si identificano:
\begin{itemize}
\item $\rho$ = \emph{costante di trasferimento}
\item $g$ = \emph{tipo} del sistema. In particolare
  \framebox{$g=(poli-zeri) \; nell'origine$}
\item $z_i$ e $p_i$ sono rispettivamente gli zeri ed i poli $\neq$ 0
  cambiati di segno
\item $\alpha_{ni}>0$ e $\omega_{ni}>0$ sono le \emph{pulsazioni
  naturali} rispettivamente degli zeri e dei poli complessi e coniugati.
\item $\zeta_i$ (``zita'') e $\xi_i$ (``x\`i'')(in modulo $< 1$), sono gli \emph{smorzamenti}
  rispettivamente degli zeri e dei poli complessi e coniugati.
\item $\mu$ \`e il \emph{guadagno}
\item $\tau_i$ e $T_i$ sono le \emph{costanti di tempo} ($\neq 0$) che
  per definizione coincidono con il reciproco cambiato di segno dei
  poli e degli zeri $\neq 0$
\end{itemize}
Combinando le due equazioni \ref{eq:firstformfdt} e
~\ref{eq:secformfdt} si pu\`o facilmente verificare che:
\begin{eqnarray}\label{eq:fdtparms}
  \mu=\dfrac{\rho \prod_iz_i\prod_i\alpha_{ni}^2}{\prod_ip_i\prod_i\omega^2_{ni}}\\
  \rho=\dfrac{\mu\prod_i\tau_i\prod_i\omega_{ni}^2}{\prod_iT_i\prod_i\alpha^2_{ni}}\\
  \tau_i=\dfrac{1}{z_i}\\
  T_i=\dfrac{1}{p_i}
\end{eqnarray}

\section{Il guadagno}
Si consideri un sistema con la funzione di trasferimento descritta
dalla \ref{eq:secformfdt}. Inoltre si supponga che esso sia
asintoticamente stabile, quindi $g \le 0$, $T_i > 0$, $\xi_i > 0$. Si
consideri il caso particolare in cui $g = 0$ e vi sia un ingresso
$u(t) = \bar{u}$ la cui trasformata di Laplace \`e
$U(s) = \dfrac{\bar u}{s}$.

Il teorema del valore finale\index{Teorema del valore finale}
(\ref{teoremaValoreFinale}) permette 
di calcolare il valore costante a regime di una funzione temporale,
data la sua trasformata di Laplace. Esso pu\`o essere correttamente
applicato solo se tutti i poli sono a sinistra dell'asse immaginario
ed un solo polo \`e nell'origine. In questo caso, il valore sar\`a una
costante diversa da zero. Se non ci sono poli nell'origine il valore
finale sar\`a zero. Se ci sono poli positivi, il valore finale \`e
indefinito: il sistema diverge.
\begin{equation}\label{eq:teoremaDelValoreFinale}
  \lim_{t \rightarrow \infty} f(t) = \lim_{s \rightarrow 0} s F(s)
\end{equation}

Calcolando la risposta di regime applicando il teorema del valore
finale, si ha:
\begin{displaymath}
  \bar y=\lim_{t \to \infty}y(t)=\lim_{s \to 0}sG(s)\dfrac{\bar u}{s}
  = \lim_{s \to 0}s(C(sI-A)^{-1}B+D)\dfrac{\bar u}{s}=
\end{displaymath}
\begin{equation}\label{eq:firstgain}
  =G(0)\bar u=(-CA^{-1}B+D)\bar u
\end{equation}
e per la \ref{eq:secformfdt} si ha:
\begin{equation}\label{eq:secgain}
  \bar y=\lim_{s \to 0}sG(s)\frac{\bar u}{s}=\mu \bar u
\end{equation}
Confrontando le due equazioni \ref{eq:firstgain}, ~\ref{eq:secgain}
risulta che:
\begin{equation}\label{eq:defgain}
  \mu = G(0) = -CA^{-1}B + D
\end{equation}
$\mu$ \`e il guadagno che in questo caso coincide con il guadagno
statico (per $g = 0$). Il guadagno statico si calcola valutando
$G(s)\Big|_{s=0}$. Il guadagno, quindi, \`e \emph{il rapporto tra
  uscita e ingresso}. Considerando la differenza tra i poli
nell'origine e gli zeri nell'origine $g$, nel caso in cui $g \ne 0$,
$\mu$ viene chiamato \emph{guadagno generalizzato}\index{Guadagno
  generalizzato} e si calcola come: 
\begin{equation}\label{eq:gengain}
  \mu=\lim_{s \to 0} s^g G(s)
\end{equation}

/!$\backslash$ in questo caso $\mu$ non \`e pi\`u il guadagno statico!

Una considerazione importante da fare \`e che i poli ``rallentano'' mentre
gli zeri ``accelerano'' per quanto riguarda l'evoluzione della risposta di
un sistema. In particolare, tornando alle costanti di tempo, si pu\`o dire
che quelle al denominatore $D(s)$ sono legate alla velocit\`a con cui si
esauriscono i transitori del sistema: maggiore \`e il valore di
una costante di tempo, pi\`u lentamente si esaurir\`a il contributo
sull'uscita dato dal polo corrispondente.

In conclusione, possiamo affermare che $y_{\infty}$ \`e nullo nel caso
di $g < 0$ (presenza di azioni derivative), altrimenti \`e pari al
guadagno $\mu$.

\section{Pulsazione naturale e smorzamento}\label{par:pulsazsmorz}
Note le equazioni \ref{eq:firstformfdt} e \ref{eq:secformfdt}, si
consideri una coppia di poli complessi e coniugati (o analogamente, di
zeri complessi e coniugati) $a \pm jb$ definiti come radici
dell'equazione $s^2 + 2\xi \omega_ns + \omega^2_n = 0$. Si definiscono:
\begin{eqnarray}
a=-\xi\omega_n\\
b=\omega_n\sqrt{1-\xi^2}
\end{eqnarray}
Quindi il modulo dei poli \`e la pulsazione naturale
$\omega_n$\index{Pulsazione naturale}, mentre
lo smorzamento $\xi$\index{Smorzamento} \`e il $\cos \theta$, dove
$\theta$ \`e l'angolo compreso tra la congiungente i poli con
l'origine e il semiasse reale negativo. 
\begin{figure}[!h]
  \begin{center}
    \includegraphics[scale=0.5]{./figures/complconj.png}
    \caption{Parametri dei poli complessi e coniugati}\label{fig:complparms}
  \end{center}
\end{figure}
Pertanto, tenendo fisso $\omega_n$, al variare di $\xi$ da $-1$ a $+1$
($cos \theta$ con $\theta = \pi$ o $\theta = 0$), i poli si spostanto
su una circonferenza di raggio $\omega_n$ centrata nell'origine. La
tabella \ref{tab:tabsmorz} mostra la posizione dei poli al variare
dello smorzamento $\xi$.
\begin{table}[!h]
\begin{center}
\begin{tabular}{c|c}
\hline
$\xi=0$ & poli immaginari puri in $s = \pm j\omega_n$\\
$\xi>0$ & poli a parte reale negativa\\
$\xi<0$ & poli a parte reale positiva\\
$\xi=1$ & poli reali coincidenti in $s = -\omega_n$\\
$\xi=-1$ & poli reali coincidenti in $s = \omega_n$\\
\hline
\end{tabular}
\caption{Posizione dei poli al variare dello smorzamento $\xi$}
\label{tab:tabsmorz}
\end{center}
\end{table}

\section{Risposta al gradino}
Per modellare un'improvvisa commutazione del valore dell'ingresso ed
analizzare il comportamento del sistema a tale variazione, si studia
il movimento dell'uscita in risposta al gradino. Il gradino che
prenderemo in considerazione si suppone di ampiezza unitaria, in
quanto per la propriet\`a della linearit\`a, la risposta al gradino di
ampiezza $\bar{u}$ \`e semplicemente data da quella del gradino unitario
moltiplicata per $\bar{u}$.

\subsection{Considerazioni sul valore iniziale e finale}
Per un sistema avente funzione di trasferimento pari a:
\begin{equation}
  G(s)=\dfrac{\beta_ms^m+\beta_{m-1}s^{m-1}+\ldots+\beta_0}{\alpha_ns^n
    + \alpha_{n-1}s^{n-1}+\ldots+\alpha_0}
\end{equation}
con $m \le n$, il valore iniziale della risposta al gradino, pu\`o
essere calcolato con il teorema del valore iniziale:
\begin{equation}\label{eq:teoremaDelValoreIniziale}
  \lim_{s \to \infty} sF(s) = f(0)
\end{equation}
che permette di determinare il valore asintotico iniziale della
funzione partendo dalla sua trasformata. Otteniamo quindi:
\begin{displaymath}
  y(0)=\lim_{s \to \infty}
  s\underbrace{\frac{\beta_ms^m+\beta_{m-1}s^{m-1}+\ldots+\beta_0}{\alpha_ns^n+\alpha_{n-1}
      s^{n-1}+\ldots+\alpha_0}\dfrac{1}{s}}_{\textsl{Risposta al
      gradino}} = \left\{ \begin{array}{ll}0 & m < n
    \\ \dfrac{\beta_n}{\alpha_n} & m = n\end{array}\right.
\end{displaymath}
Possiamo iterare il teorema del valore iniziale anche per le derivate
successive del valore iniziale, ricordando le regole di derivazione
della trasformata di Laplace (\ref{apx:laplace}).\\
Ad esempio, se $m < n$ e $y(0) = 0$ si ha:
\begin{displaymath}
  \dot{y}(0)=\lim_{s \to \infty}s(sY(s)-y(0))=
\end{displaymath}
\begin{displaymath}
  =\lim_{s \to \infty}s^2\dfrac{\beta_ms^m+\beta_{m-1}s^{m-1} +
    \ldots+\beta_0}{\alpha_ns^n +
    \alpha_{n-1}s^{n-1}+\ldots+\alpha_0}\frac{1}{s} =
  \left\{ \begin{array}{ll}0 & m<n-1 \\
    \dfrac{\beta_n}{\alpha_n} & m=n-1\end{array}\right.
\end{displaymath}
In generale, per $m < n$, sono nulle le prime ($n-m-1$) derivate di
$y$ in $t = 0$.

\subsection{Parametri della risposta al gradino}
I parametri caratterizzanti la risposta al gradino sono:
\begin{description}
\item[valore di regime~$y_\infty$] \hfill \\
  valore dell'uscita a transitorio esaurito:
  \begin{itemize}
  \item se $g = 0$ esso \`e pari a $\mu$; 
  \item se $g < 0$ esso \`e 0;
  \end{itemize}
\item[valore massimo~$y_{max}$]\hfill \\
  massimo valore assunto dall'uscita;
\item[sovraelongazione massima percentuale] $S\%$ \hfill \\
  ampiezza, in \%, della sovraelongazione massima rispetto a
  $y_\infty$, cio\`e
  \begin{displaymath}
    S\% = 100 \cdot \dfrac{y_{max}-y_\infty}{y_\infty}
  \end{displaymath}
\item[tempo di massima sovraelongazione~$T_M$] \hfill \\
  primo istante in cui $y = y_{max}$;
\item[tempo di salita $T_s$] \hfill \\
  tempo richiesto affinch\`e l'uscita passi dal 10\% al 90\% del suo
  valore di regime;
\item[tempo di ritardo o tempo all'emivalore $T_r$] \hfill \\ tempo
  necessario affinch\`e l'uscita raggiunga un valore pari a 0.5 volte
  $y_\infty$; 
\item[tempo di assestamento~$T_{a\varepsilon}$] \hfill \\
  tempo necessario affinch\`e il modulo della differenza tra l'uscita
  e il valore di regime
  $y_\infty$ rimanga definitivamente al di sotto di $\varepsilon\%$
  ovvero l'uscita sia compresa nell'intervallo
  $[(1-0.01\varepsilon)y_\infty,(1+0.01\varepsilon)y_\infty]$. Ad
  esempio con ``tempo al 99\%'', indicato con $T_{a1}$, si far\`a
  riferimento al tempo necessario affinch\`e l'uscita entri
  definitivamente nella fascia di ampiezza $\pm 0.01 y_\infty$. In
  generale si dir\`a che $T_{a\varepsilon}$ \`e il \emph{``tempo di
    assestamento al ($100-\varepsilon$)\%''}.
  Nota: un fenomeno si considera esaurito se raggiunge l'$1\%$ del
  valore iniziale (esponenziale decrescente a zero) o se raggiunge il
  $99\%$ del valore a regime (esponenziale convergente crescente).
\item[periodo di oscillazione $T_p$] \hfill \\
  distanza temporale tra i primi due massimi dell'uscita.
\end{description}

\begin{figure}[!h]
  \begin{center}
    \includegraphics[scale=0.5]{./figures/parms.png}
    \caption{Parametri della risposta al gradino}\label{fig:caratparms}
  \end{center}
\end{figure} 

\section {Sistemi del $I$ ordine}
Un sistema del primo ordine \`e caratterizzato dalla seguente funzione
di trasferimento:
\begin{equation}\label{eq:firstordfdt}
  G(s) = \dfrac{\mu}{1+sT}
\end{equation}
Calcolando la risposta al gradino:
\begin{displaymath}
  Y(s) = G(s)\dfrac{1}{s} = \dfrac{\mu}{(1+sT)s}
\end{displaymath}
Determiniamo l'antitrasformata (Appendice \ref{apx:laplace}) $y(t)$
sfruttando la teoria dei fratti semplici:
\[
  \dfrac{\mu}{(1 + sT)s} = \dfrac{A}{s} + \dfrac{B}{(1 + sT)}
\]
Moltiplichiamo ambo i membri per $s$:
\[
  \dfrac{\mu s}{(1 + sT)s} = A + \dfrac{Bs}{(1 + sT)}
\]
Facciamo tendere $s$ alla radice del denominatore di $A$, quindi a
zero.
\[
  A = \mu
\]
Per calcolare $B$, moltiplichiamo entrambi i membri per $(1 + sT)$:
\[
  \dfrac{\mu}{(1 + sT)s} \cdot (1 + sT) = \dfrac{A(1 + sT)}{s} + B
\]
Facciamo tendere $s$ alla radice del denominatore di $B$, cio\`e
$-\dfrac{1}{T}$:
\[
  B = - \mu T
\]
A questo punto abbiamo:
\[
  \dfrac{\mu}{s} - \dfrac{\mu T}{(1 + sT)}
\]
Calcoliamo le antitrasformate:
\[
  \mathscr{L}^{-1} \dfrac{\mu}{s} = \mu
\]
perch\`e $\mu$ \`e una costante e l'antitrasformata del gradino $\dfrac{1}{s}$
\`e $1$.
Ci resta:
\[
  - \dfrac{\mu T}{T} \cdot \dfrac{1}{\frac{1}{T} + s}
\]
Operiamo una messa in evidenza ed una semplificazione.
\[
  \mathscr{L}^{-1} \mu \cdot \dfrac{1}{s + \frac{1}{T}} = \mu \cdot
  e^{- \frac{t}{T}}
\]
Abbiamo in definitiva:
\[
  \mathscr{L}^{-1} Y(s) = \mu - \mu \cdot e^{- \frac{t}{T}}
\]
\begin{equation}\label{eq:rispgradfirst}
  y(t) = \mu(1-e^{-\frac{t}{T}}) \qquad, \qquad t\ge0
\end{equation}
Ponendo $t = 0$ si ha che:

\begin{itemize}
\item l'andamento $y(0) = 0$
\item la pendenza {\Large$\dfrac{dy(t)}{dt}\big |_{t=0} = \dfrac{\mu}{T}$}\\
per $T>0$:
\item il valore di regime $y_{\infty} = \mu$
\item $y_{max} = y_{\infty}$
\item $S\% = 0$
\item Il tempo di assestamento\index{Tempo di assestamento}
\begin{displaymath}
  T_{a\varepsilon} = T \ln{\dfrac{1}{0.01\varepsilon}} = -T \ln0.01 \varepsilon 
\end{displaymath}
\end{itemize}
Gli altri parametri caratteristici sono riportati nella tabella
\ref{tab:tabfirstordparms}.
\begin{table}[!h]
  \begin{center}
    \begin{tabular}{|c|c|c|c|c|}
      \hline
      $y_\infty$ & $T_s$ & $T_r$ & $T_{a5}$ & $T_{a1}$\\
      \hline
      $\mu$ & $\simeq 2.2T$ & $\simeq 0.7T$ & $\simeq 3T$ & $\simeq 4.6T$\\
      \hline
    \end{tabular}
  \end{center}
  \caption{Parametri del sistema \ref{eq:firstordfdt}}
  \label{tab:tabfirstordparms}
\end{table}

Da notare che gli ultimi 4 parametri in tabella
\ref{tab:tabfirstordparms} dipendono dalla costante di tempo $T$ e sono
direttamente proporzionali ad essa. In particolare il transitorio si
pu\`o dichiarare esaurito dopo un tempo \\
\begin{center}
  \framebox{$t\simeq 4 \div 5 T$}\label{transit}
\end{center}
\`E il tempo di assestamento ``all'1\%'', cio\`e $\varepsilon = 1$.

\begin{figure}[!h]
\begin{center}
\includegraphics[scale=0.5]{./figures/rispscal1.png}
\caption{Risposta al gradino del sistema \ref{eq:firstordfdt}}\label{fig:risp1}
\end{center}
\end{figure} 
Nota: ad una diminuzione di $T$, cio\`e ad uno spostamento verso
sinistra del polo, corrisponde una diminuzione del tempo di salita,
del tempo di ritardo e del tempo di assestamento.

\section{Sistemi del $II^{\circ}$ ordine}
\subsection{Sistemi con solo poli reali}
\subsubsection{Caso 1: poli distinti}
\begin{equation}\label{eq:secordfdt_c1}
  G(s) = \dfrac{\mu}{(1+sT_1)(1+sT_2)} \qquad, \qquad T_1>T_2
\end{equation}
Appicando la teoria dei fratti semplici\index{Fratti
  semplici}\label{FrattiSemplici}, abbiamo che la risposta al gradino
\`e:
\[
  \dfrac{A}{s} + \dfrac{B}{(1 + sT_1)} + \dfrac{C}{(1 + sT_2)} =
  \dfrac{\mu}{(1 + sT_1)(1 + sT_2)s}
\]
Moltiplichiamo ambo i membri per $s$ e facciamo tendere $s$ a zero:
\[
  \dfrac{\mu \xout{s}}{(1 + \xout{sT_1})(1 + \xout{sT_2})\xout{s}} = A
  + 0 + 0
\]
\[
  A = \mu
\]
Stesso discorso per $B$ e $C$. Avremo in questo modo:
\[
  Y(s) = \dfrac{\mu}{s} - \mu \dfrac{\frac{T_1^2}{(T_1 - T_2)}}{(1 + sT_1)} -
  \mu \dfrac{\frac{T_2^2}{(T_1 - T_2)}}{(1 + sT_2)}
\]
Mettendo in evidenza $\mu$ ed antitrasformando, otteniamo:
\begin{equation}\label{eq:rispgradsec_c1}
  y(t) = \mu \left( 1 - \frac{T_1}{T_1-T_2} e^{-\frac{t}{T_1}} +
  \frac{T_2}{T_1-T_2} e^{-\frac{t}{T_2}} \right) \qquad, \qquad t \ge 0
\end{equation}

\begin{figure}[!h]
  \begin{center}
    \includegraphics[scale=0.5]{./figures/rispscal2.png}
    \caption{Risposta al gradino del sistema \ref{eq:secordfdt_c1}}
    \label{fig:risp2}
  \end{center}
\end{figure} 

Alcune considerazioni conclusive:
\begin{itemize}
\item La risposta $y(t)$ ci mostra la presenza di due transitori;
\item La posizione del polo influenza la costante di tempo e, di
  conseguenza, la prontezza del sistema: pi\`u il polo \`e vicino allo
  zero pi\`u la costante di tempo \`e grande e pi\`u il sistema evolve
  lentamente;
\item La risposta non presenta sovraelongazione.
\end{itemize}

\subsubsection{Caso 2: poli coincidenti $(T_1 = T_2 = T)$}
\begin{equation}\label{eq:secordfdt_c2}
  G(s) = \dfrac{\mu}{(1 + sT)^2}
\end{equation}
La risposta al gradino della \ref{eq:secordfdt_c2} \`e:
\begin{equation}\label{eq:rispgradsec_c2}
  y(t) = \mu \left( 1 - e^{-\frac{t}{T}} -
  \dfrac{t}{T}e^{-\frac{t}{T}} \right)\qquad, \qquad t\ge 0
\end{equation}
I parametri caratteristici sono:
\begin{itemize}
\item $y_{\infty} = \mu$
\item $T_s \simeq 3.36T$
\item $T_r \simeq 1.68T$
\item $T_{a5} \simeq 4.74T$
\item $T_{a1} \simeq 6.64T$
\end{itemize}

\subsection{Sistemi con poli reali e uno zero}
\begin{equation}\label{eq:secordfdt_cc1}
  G(s)= \dfrac{\mu(1 + \tau s)}{(1 + sT_1)(1 + sT_2)}\qquad, \qquad
  T_1\neq\tau, T_2\neq \tau 
\end{equation}
Applicando, come di consueto la teoria dei fratti semplici, la
risposta al gradino della \ref{eq:secordfdt_cc1} \`e: 
\begin{equation}\label{eq:rispgradsec_cc1}
  y(t) = \mu \left( 1 - \dfrac{T_1-\tau}{T_1 - T_2}e^{-\frac{t}{T_1}} + 
  \dfrac{T_2 - \tau}{T_1 - T_2}e^{-\frac{t}{T_2}}\right) \qquad,
  \qquad t\ge0 
\end{equation}
In funzione della posizione dello zero rispetto ai poli, supposto $T_1
> T_2 > 0$, si distinguono i seguenti casi:

\subsubsection{I caso: $\tau < 0$}
La risposta, come mostrato in figura \ref{fig:risp3}, presenta una
\emph{sottoelongazione} iniziale, o {\em
  risposta inversa}\index{Risposta inversa}, che \`e tanto pi\`u
pronunciata quanto pi\`u lo zero $- \dfrac{1}{\tau}$ si avvicina
all'origine del piano complesso. 
\begin{figure}[!h]
\begin{center}
\includegraphics[scale=0.5]{./figures/rispscal3.png}
\caption{Risposta al gradino del sistema \ref{eq:secordfdt_cc1} con
  $\tau < 0$} \label{fig:risp3}
\end{center}
\end{figure}
Ricordiamo che la sottoelongazione\index{Sottoelongazione} $\sigma$
\`e definita come:
\begin{equation}
  \sigma  = \left . \frac{{\bar y - y_{\min }}}{{\bar y}} \right|
\end{equation}
dove $y_{\min }$ \`e il minimo valore assunto dall'uscita del sistema
e $\bar{y}$ \`e l'uscita all'equilibrio.

\subsubsection{II caso: $\tau>T_1>T_2$}
In questo caso (figura \ref{fig:risp4}), la risposta presenta una
\emph{sovraelongazione} tanto pi\`u evidente quanto pi\`u lo zero negativo
\`e vicino all'origine del piano complesso, rispetto alla posizione dei
poli. Per i sistemi di ordine elevato la presenza di una
sovraelongazione (da non confondere con andamenti oscillanti) nella
risposta al gradino, indica la presenza di uno zero reale negativo e
minore in modulo ai poli.
\begin{figure}[!h]
  \begin{center}
    \includegraphics[scale=0.5]{./figures/rispscal4.png}
    \caption{Risposta al gradino del sistema \ref{eq:secordfdt_cc1} con $\tau>0$}\label{fig:risp4}
  \end{center}
\end{figure} 
Ricordiamo che la sovraelongazione\index{Sovraelongazione} $\sigma$
\`e definita come:
\begin{equation}
  \sigma  = \left . \frac{{y_{\max } - \bar y}}{{\bar y}} \right|
\end{equation}
dove $y_{\max }$ \`e il massimo valore assunto dall'uscita del sistema
e $\bar{y}$ \`e l'uscita all'equilibrio.

\subsubsection{III caso: $\tau \simeq T_1\gg T_2$}
Con tali valori di $\tau$ e $T_1$, $T_2$, si pu\`o facilmente verificare
che la \ref{eq:rispgradsec_cc1} diventa approssimativamente:
\begin{equation}\label{eq:2ndOrdineCaso3}
  y(t)\simeq \mu (1 - e^{-\frac{t}{T_2}})\qquad , \qquad t\geq0
\end{equation}
aprossimabile, quindi, ad un sistema del primo ordine. Dalla figura
\ref{fig:risp5} si evince che la coppia polo-zero 
genera comunque un transitorio di piccola entit\`a, il quale fa andare
lentamente $y$ verso $y_\infty$. 
\begin{figure}[!h]\label{fig:risp5}
  \begin{center}
    \includegraphics[scale=0.5]{./figures/rispscal5.png}
    \caption{Risposta al gradino del sistema \ref{eq:secordfdt_cc1} con
      $\tau=0.92$}
  \end{center}
\end{figure} 
La \ref{fig:risp5} mostra come l'assenza di un polo nella \ref{eq:2ndOrdineCaso3},
cancellato grazie allo zero, velocizzi il sistema: i poli rallentano,
quindi meno poli portano ad un sistema pi\`u rapido nel raggiungere il
regime. 

\subsubsection{IV caso: $T_1 > \tau > T_2$}
La presenza di uno zero, tende a velocizzare la risposta di un
sistema. In figura \ref{fig:risp6} \`e riportato il caso in cui $T_1 =
2$ e $T_2 = 1$ con valori di $\tau = 0$ e $1.5$ . Con ragionamenti
analoghi al caso III, avendo posto $\tau \simeq T_2$ si ha che la
\ref{eq:rispgradsec_cc1} diventa
\begin{displaymath}
  y(t)\simeq \mu (1-e^{-\frac{t}{T_1}})\qquad , \qquad t\geq0
\end{displaymath}
\begin{figure}[!h]
  \begin{center}
    \includegraphics[scale=0.5]{./figures/rispscal6.png}
    \caption{Risposta al gradino del sistema \ref{eq:secordfdt_cc1} con
      due diversi valori di $\tau$}\label{fig:risp6}
  \end{center}
\end{figure}

\subsubsection{V caso: $T_1 > T_2 > \tau > 0$}
Per uno zero che si allontana dall'origine del piano complesso (ovvero
per $\tau$ che diminuisce), la risposta della \ref{eq:rispgradsec_cc1}
tende a diventare come la \ref{eq:rispgradsec_c1}, come mostrato in
figura \ref{fig:risp7}: per uno zero sempre pi\`u lontano dall'origine
del piano complesso, la risposta al gradino di un sistema con poli
reali ed uno zero approssima la risposta di un sistema con solo poli
reali. 
\begin{figure}[!h]
\begin{center}
\includegraphics[scale=0.5]{./figures/rispscal7.png}
\caption{Risposta al gradino del sistema \ref{eq:secordfdt_cc1} del
  \emph{caso V}}\label{fig:risp7} 
\end{center}
\end{figure} 

\subsection{Sistemi con poli complessi e coniugati}
La funzione di trasferimento di un sistema avente poli complessi
coniugati \`e:
\begin{equation}\label{eq:fdtcomplex}
  G(s) = \dfrac{\mu \omega^2_n}{s^2 + 2 \xi \omega_n s + \omega^2_n}
\end{equation}
con la pulsazione naturale $\omega_n > 0$ e lo smorzamento dei poli
$\xi$, $|\xi| < 1$. Applicando lo sviluppo in serie di Heaviside, la
risposta al gradino del sistema \ref{eq:fdtcomplex} risulta: 
\begin{equation}\label{eq:rispfdtcomplex}
  y(t) = \mu \left ( 1-\frac{1}{\sqrt{1-\xi^2}}e^{-\xi \omega_n t}\sin
  \left ( \omega_n t\sqrt{1-\xi^2} + \arccos(\xi) \right) \right)
\end{equation}
con $t \geq 0$. Abbiamo quindi un termine esponenziale che moltiplica un
termine sinusoidale, come mostrato in figura \ref{fig:risp8}.
\begin{figure}[!h]
  \begin{center}
    \includegraphics[scale=0.5]{./figures/rispscal8.png}
    \caption{Risposta al gradino del sistema \ref{eq:fdtcomplex}}
    \label{fig:risp8}
  \end{center}
\end{figure} 
In particolare
\begin{itemize}
\item per uno smorzamento $\xi > 0$ (figura \ref{fig:risp9}), il
  sistema \`e ASINTOTICAMENTE STABILE. L'esponenziale \`e decrescente e
  la risposta tende asintoticamente a $\mu$; 
\item per $\xi < 0$ l'esponenziale \`e positivo, il sistema \`e
  INSTABILE e l'uscita \`e divergente; 
\item per $\xi = 0$ l'esponenziale vale $1$, il sistema \`e STABILE,
  ma non asintoticamente e la \ref{eq:rispfdtcomplex} diventa
  \[
    y(t) = \mu(1-\cos(\omega_n t))\qquad , \qquad t\geq0
  \]
\end{itemize}

\begin{figure}[!h]
  \begin{center}
    \includegraphics[scale=0.5]{./figures/rispscal9.png}
    \caption{Risposta al gradino del sistema \ref{eq:fdtcomplex} per
      diversi valori di $\xi>0$}\label{fig:risp9}
  \end{center}
\end{figure} 

I parametri caratteristici del sistema con poli complessi e coniugati
sono riassunti nella tabella \ref{tab:tabfdtcomplexparms}:
\begin{table}[!hbp]
  \begin{center}
    \begin{tabular}{|c|c|c|c|c|}
      \hline
      $y_\infty$ & $S\%$ & $T_M$ & $T_P$ & stima di $T_{a\varepsilon}$\\
      \hline
      $\mu$ & $100e^{-\xi \pi / \sqrt1-\xi^2}$ & $\dfrac{\pi}{\omega_n
        \sqrt{1-\xi^2}}$ & $\dfrac{2\pi}{\omega_n \sqrt{1-\xi^2}}$ &
      $-\dfrac{1}{\xi \omega_n}\ln0.01\varepsilon$\\
      \hline
    \end{tabular}
  \end{center}
  \caption{Parametri del sistema \ref{eq:fdtcomplex}}
  \label{tab:tabfdtcomplexparms}
\end{table}

\begin{figure}[!h]
  \begin{center}
    \includegraphics[scale=0.5]{./figures/rispscalX.png}
    \caption{Risposta al gradino del sistema \ref{eq:fdtcomplex} e
      parametri caratteristici}\label{fig:rispX}
  \end{center}
\end{figure} 

% SCHEMI A BLOCCHI - CAPITOLO 5 DEL BOLZERN
\chapter{Interconnessione di sistemi e schemi a blocchi}
I sistemi possono essere collegati in serie, parallelo o in retroazione.

\section{Sistemi in serie}
Abbiamo due sistemi descritti dalle equazioni:
\begin{eqnarray}
  Y_a(s) = G_a(s)U_a(s)\\
  Y_b(s) = G_b(s)U_b(s)
\end{eqnarray}
Essi si dicono connessi in serie (o cascata) quando l'uscita del primo
diventa l'ingresso del secondo: $y_a = u_b$. Quindi, con $u(t) = u_a(t)$
e $y(t) = y_b(t)$, si ricava che 
\begin{equation}
  Y(s) = G_b(s)Y_a(s) = G_b(s)G_a(s)U(s)
\end{equation}
e la funzione di trasferimento diventa
\begin{equation}
  G(s) = \dfrac{Y(s)}{U(s)} = G_a(s)G_b(s)
\end{equation}
ovvero, \emph{la funzione di trasferimento totale di un sistema
  composto dalla serie di due sottosistemi \`e pari al prodotto delle
  singole funzioni di trasferimento}.
\begin{figure}[!hbp]
  \begin{center}
    \includegraphics[scale=0.5]{./figures/serie.png}
    \caption{Sistemi connessi in serie}\label{fig:syserie}
  \end{center}
\end{figure}

\section{Sistemi in parallelo}
Due sistemi si dicono connessi in parallelo se hanno lo stesso
ingresso e le loro uscite si sommano, per generare l'uscita del
sistema complessivo. Formalizzando si ha:
\begin{equation}
  Y(s) = Y_a(s) + Y_b(s) = G_a(s)U_a(s) + G_b(s)U_b(s) = (G_a(s) + G_b(s))U(s)
\end{equation}
quindi la funzione di trasferimento \`e:
\begin{equation}
  G(s) = \dfrac{Y(s)}{U(s)} = G_a(s) + G_b(s)
\end{equation}
ovvero \emph{la funzione di trasferimento complessiva di un sistema
  composto dal parallelo di due sottosistemi \`e pari alla somma
  delle singole funzioni di trasferimento}.
\begin{figure}[!hbp]
  \begin{center}
    \includegraphics[scale=0.5]{./figures/parallelo.png}
    \caption{Sistemi connessi in parallelo}\label{fig:sysparal}
  \end{center}
\end{figure} 

\section{Sistemi in retroazione}
\begin{figure}[!h]
  \begin{center}
    \includegraphics[scale=0.5]{./figures/feedbackneg.png}
    \caption{Sistemi con feedback negativo}\label{fig:sysnegfed}
  \end{center}
\end{figure}
\begin{figure}[!h]
  \begin{center}
    \includegraphics[scale=0.5]{./figures/feedbackpos.png}
    \caption{Sistemi con feedback positivo}\label{fig:sysposfed}
  \end{center}
\end{figure} 
Nelle figure \ref{fig:sysposfed} e \ref{fig:sysnegfed} sono mostrati
dei sistemi aventi due sottosistemi collegati in retroazione\index{Retroazione} o
feedback\index{Feedback} o in anello chiuso\index{Anello chiuso}.
Si ricava che:
\begin{equation}
  Y(s) = G_a(s)(U(s) - Y_b(s)) = G_a(s)(U(s) - G_b(s)Y(s))
\end{equation}
pertanto la funzione di trasferimento complessiva per la
\emph{retroazione negativa} \`e:
\begin{equation}
  G(s) = \dfrac{Y(s)}{U(s)} = \dfrac{G_a(s)}{1 + G_a(s)G_b(s)}
\end{equation}
mentre quella in \emph{retroazione positiva} \`e
\begin{equation}
  G(s)=\dfrac{Y(s)}{U(s)} = \dfrac{G_a(s)}{1 - G_a(s)G_b(s)}
\end{equation}
ovvero \emph{la funzione di trasferimento di un sistema avente due
  sottosistemi retroazionati negativamente (o positivamente) \`e pari al
  rapporto tra la funzione di trasferimento del sottosistema che
  appare lungo la linea di andata tra $u$ e $y$ e la somma (o
  differenza) tra $1$ e il prodotto delle singole funzione di
  trasferimento, detto in questo caso funzione di trasferimento
  d'anello $L(s)$} 
\begin{equation}
  L(s)=G_a(s)G_b(s)
\end{equation}

\subsection{Semplificazione di schemi a blocchi}
Quando lo schema a blocchi  di un sistema, presenta un numero
abbastanza elevato di ``sotto-blocchi'' (ovvero funzioni di
trasferimento), \`e necessario effettuare delle operazioni di riduzione
dello stesso in modo da semplificare l'analisi ed i calcoli. L'operazione
di riduzione e lo spostamento dei blocchi sono rese possibili grazie
alla propriet\`a di \emph{linearit\`a }. Si possono applicare, a tale
scopo, semplici manipolazioni utilizzando le regole di serie,
parallelo e retroazione. Si possono, poi, applicare le seguenti
ulteriori regole: 
\begin{itemize}
\item Per spostare una variabile ``a valle'' di un blocco, \`e necessario
  moltiplicarla per la funzione di trasferimento del blocco;
\item Per spostare una variabile ``a monte'' di un blocco, \`e necessario
  dividerla per la funzione di trasferimento del blocco;
\item Per spostare un blocco ``a monte'' di un nodo sommatore, bisogna
  moltiplicare la funzione di trasferimento del blocco per tutte le
  altre variabili entranti nel nodo;
\item Per spostare un blocco ``a valle'' di un nodo sommatore, bisogna
  dividere la funzione di trasferimento del blocco per tutte le altre
  variabili entranti nel nodo.
\end{itemize}
Per quel che riguarda la stabilit\`a dei sistemi in serie, parallelo e
in retroazione possiamo affermare che:
\begin{itemize}
\item La connessione in serie di sottosistemi asintoticamente stabili
  genera {\em sempre} un sistema asintoticamente stabile;
\item La presenza di un sottosistema non asintoticamente stabile in un
  collegamento in serie rende il sistema complessivo anch'esso non
  asintoticamente stabile;
\item La connessione in parallelo di sottosistemi asintoticamente
  stabili genera {\em sempre} un sistema asintoticamente stabile;
\item La presenza di un sottosistema non asintoticamente stabile in un
  collegamento in parallelo rende non asintoticamente stabile il
  sistema complessivo;
\item La connessione in retroazione di sistemi asintoticamente stabili
  pu\`o generare un sistema {\em non} asintoticamente stabile;
\item Un sistema retroazionato pu\`o essere asintoticamente stabile
  anche se alcuni dei sottosistemi non sono asintoticamente stabili;
\end{itemize}
Le figure presenti in figura \ref{fig:blockex} aiutano a capire le
possibili riduzioni che si possono effettuare sugli schemi a blocchi: 
\begin{figure}[!hbp]
  \begin{center}
    \includegraphics[scale=0.5]{./figures/block_example.png}
    \caption{Esempio di riduzione di schemi a blocchi}
    \label{fig:blockex}
  \end{center}
\end{figure} 

\chapter{Modelli matematici}
Il primo passo per la costruzione di un sistema di controllo \`e lo
sviluppo di una descrizione matematica del processo da
controllare. L'insieme delle equazioni differenziali che descrivono il
comportamento dinamico del processo \`e detto {\bf modello}.

\section{Sistemi Meccanici}
\begin{figure}[!b]
\centering
\includegraphics[width=0.5\textwidth]{./images/carrello.png}
\caption{Carrellino\label{fig:carrello}}
\end{figure}
\subsection{Carrello}\label{carrello}
Il carrello di figura \ref{fig:carrello} \`e modellabile come una massa $m$ che si muove spinta da
un ingresso $u$ fino ad un punto $y$. L'equazione del moto del
sistema, stando alla Legge di Newton (\ref{leggedinewton}), 
\`e quindi:
\begin{equation}
  F = m \cdot a \Rightarrow u = m \cdot \ddot{y}
\end{equation}
Integrando due volte si otttiene:
$$y(t) = y(0) + \dot{y}(0) + \int_0^t \left ( \int_o^{\theta} u(\tau)d\tau
\right ) d \theta$$
La soluzione dell'equazione differenziale dipende dallo stato iniziale
del carrello. Se ``sostituiamo'' i differenziali con le $s$ otteniamo
la funzione di trasferimento:
$$y = \frac{1}{ms^2} \cdot u$$
Volendo ottenere la rappresentazione in forma di stato poniamo $x_1 =
y$ e $x_2 = \dot{y}$ e riscriviamo il tutto come:
\begin{eqnarray*}
  \left\{ \begin{array}{l}
    \dot{x_1} = x_2\\
    \dot{x_2} = \frac{1}{m} \cdot u\\
    y = x_1
    \end{array}\right .
\end{eqnarray*}
Per i sistemi \`e, inoltre, possibile riscrivere il tutto in forma
matriciale. Il carrello \`e un sistema lineare e quindi:
\begin{eqnarray*}
  \begin{array}{l}
    \dot{x} = 
    \begin{bmatrix}
      0 & 1\\
      0 & 0
    \end{bmatrix}
    x + 
    \begin{bmatrix}
      0\\
      \frac{1}{m}
    \end{bmatrix}u
    \\
    y = \begin{bmatrix}1 & 0 \end{bmatrix}x
    \end{array}
\end{eqnarray*}
Nota: possiamo considerare il sistema come una serie di due
``blocchetti''. Un primo che ne specifica i comportamenti dinamici,
fornendo come risultato lo stato del sistema, ed un secondo blocchetto
che specifica il comportamento statico, che riceve in ingresso lo
stato e fornisce l'uscita totale del sistema.

\begin{figure}[!b]
\centering
\includegraphics[width=0.5\textwidth]{./images/massa-molla-smorzatore.png}
\caption{Massa-molla-smorzatore\label{fig:massa-molla-smorzatore}}
\end{figure}

\subsubsection{Legge di Newton}\label{leggedinewton}
Per ottenere un modello matematico per qualsiasi sistema meccanico \`e
fondamentale la Legge di Newton, che per il moto traslatorio \`e:
\begin{equation}
  F = ma = m \cdot \dot{v} = m \cdot \ddot{p}
\end{equation}
dove $v$ e $p$ sono rispettivamente ``velocit\`a'' e ``posizione'',
$F$ \`e la somma vettoriale delle forze applicate al sistema (misurata
in Newton: una forza di 1 newton imporr\`a una accelerazione di 1
$\dfrac{m}{s^2}$ ad una massa di un kg), $m$ \`e la massa
(kg) e $a$ \`e l'accelerazione inerziale $\left(\frac{m}{s^2}\right)$.
Il metodo per risolvere questo tipo di problema utilizzando la Legge
di Newton \`e definito dal seguente procedimento:

\begin{itemize}
  \item assegnare delle variabili necessarie e sufficienti per
    descrivere una posizione arbitraria dell'oggetto rispetto ad un
    sistema inerziale
  \item disegnare lo schema di ogni componente indicando le forze
    agenti
  \item applicare la Legge di Newton
  \item combinare le equazioni per eliminare le forze interne: il
    numero delle equazioni indipendenti deve essere uguale al numero
    delle incognite
  \item valutare accuratamente la scelta delle coordinate
\end{itemize}

\subsection{Massa-molla-attrito}
In figura \ref{fig:massa-molla-smorzatore} abbiamo le seguenti variabili:
$k$ \`e il coeffiente elastico della molla, $b$ \`e il coeffiente di
attrito dello smorzatore, $u$ \`e la forza applicata, $y$ \`e lo
spostamento. Dalla formula di Newton (\ref{leggedinewton}) si arriva rapidamente
all'equazione del moto del sistema:
\begin{equation}\label{massa-molla-attrito}
u -ky -b\dot{y} = m \ddot{y}
\end{equation}
Notiamo come l'attrito sia proporzionale alla posizione $y$, mentre lo
smorzamento sia proporzionale alla velocit\`a $\dot{y}$. Sfruttando le
``sostituzioni di Laplace'' ($\dot{y} \rightarrow sy$, $\ddot{y}
\rightarrow s^2y$), possiamo riscrivere la funzione di trasferimento come:
$$m s^2 y + b s y + k y = u \Rightarrow y = \left ( \frac{1}{m s^2 +
  bs + k} \right )u$$
La rappresentazione di stato permette di scrivere l'equazione della
funzione di trasferimento come sistema di equazioni del primo
ordine. Posti $x_1 = y$ e $x_2 = \dot{y}$ si ha:
\begin{eqnarray*}
  \left\{ \begin{array}{l}
    \dot{x}_1 = x_2\\
    \dot{x}_2 = -\left(\dfrac{k}{m}\right)x_1 - \left(\dfrac{b}{m}\right)x_2 + \dfrac{u}{m}\\
    y = x_1
    \end{array}\right .
\end{eqnarray*}
La rappresentazione di stato in forma matriciale:
\begin{eqnarray*}
  \left\{ \begin{array}{lr}
    \dot{x} = \begin{bmatrix}0 & 1\\-\frac{k}{m} &
      -\frac{b}{m}\end{bmatrix}x
    + \begin{bmatrix}0\\ \frac{1}{m}\end{bmatrix}u & \textrm{Come
      l'ingresso modifica lo stato}\\
    y = \begin{bmatrix}1 & 0\end{bmatrix}x & \textrm{Come lo stato
        influisce sull'uscita}
    \end{array}\right .
\end{eqnarray*}
\subsubsection{Stato e uscita di equilibrio}
Supponiamo un ingresso $u = \overline{u}$ costante. \`E sufficiente
ora porre le derivate dello stato uguali a zero:
\begin{eqnarray*}
  \left\{ \begin{array}{l}
    \overline{x_2} = 0\\
    \overline{u} - k \overline{x_1} = 0
    \end{array}\right .
  \Rightarrow
  \left\{ \begin{array}{l}
    \overline{x_2} = 0\\
    \overline{x_1} = \dfrac{\overline{u}}{k}
  \end{array}\right .
  \Rightarrow
  \overline{y} = \dfrac{1}{k} \overline{u} \;\; \textrm{che \`e l'uscita di equilibrio}
\end{eqnarray*}
Il valore $\frac{1}{k} = \frac{\overline{y}}{\overline{u}}$ \`e detto
{\em guadagno statico}\index{Guadagno statico} e per ottenerlo \`e
sufficiente porre $s = 0$ nella funzione di trasferimento. Non sempre
un sistema presenta un guadagno statico. Un sistema senza punti di
equilibrio \`e un sistema senza guadagno statico:
$$\textrm{Punto di equilibrio} \Leftrightarrow \textrm{Guadagno statico}$$

\subsection{Sospensioni}
\begin{figure}[!b]
\centering
\includegraphics[width=0.4\textwidth]{./images/sospensioni.png}
\caption{Sospensioni\label{fig:sospensioni}}
\end{figure}
Assumiamo il moto della massa dell'automobile su una ruota come
monodimensionale, cio\`e solo verticale. $k_s$ \`e il coeffiente di
elasticit\`a delle sospensioni, $b$ \`e il coeffiente di smorzamento
delle sospensioni, $k_w$ \`e il coeffiente di elasticit\`a del
pneumatico, $m_1$ \`e la massa della ruota, $m_2$ \`e la massa
dell'auto, $u$ \`e la superficie stradale. Il modello tralascia
volutamente la forza di gravit\`a. Lo smorzamento introdotto dalla
sospensione \`e considerato proporzionale alla velocit\`a di
variazione dello spostamento relativo tra le due masse, cio\`e a
$b(\dot{y} - \dot{x})$. Per comodit\`a consideriamo un modello ad
elementi separati, separando le due masse ed analizzandole singolarmente.


Dal punto di vista della della ruota ($m_1$), si hanno tre contributi:
il contributo della molla $k_w$, che rappresenta l'elasticit\`a del
pneumatico, \`e diretto verso il suolo; il contributo della molla
$k_s$ e dello smorzatore $b$ che rappresentano la sospensione e sono
diretti verso l'automobile.

Dal punto di vista dell'automobile ($m_2$) abbiamo solo i contributi
della molla $k_s$ e dello smorzatore $b$, entrambi rivolti verso la ruota.
Il modello complessivo \`e:
\begin{equation}\label{sospensionem1}
  k_s(y-x) + b(\dot{y} - \dot{x}) - k_w(x-r) = m_1\ddot{x}
\end{equation}

\begin{equation}\label{sospensionem2}
  -k_s(y-x) -b(\dot{y} - \dot{x}) = m_2 \ddot{y}
\end{equation}

Cerchiamo la funzione di trasferimento del sistema considerando come
ingresso $r$ e come uscita la sola $y$:
$$G(s) = \frac{Y(s)}{R(s)}$$
Dalla \ref{sospensionem1} otteniamo:
\begin{eqnarray*}
  \begin{array}{l}
    k_s(y-x) + bs(y-x) - k_w(x-r) = m_1s^2x\\
    k_sy - k_sx + bsy - bsx - k_wx + k_wr - m_1s^2x = 0\\
    k_wr = (k_s + bs + k_w + m_1s^2)x - (k_s +bs)y
  \end{array}
\end{eqnarray*}
Dalla \ref{sospensionem2} otteniamo:
\begin{eqnarray*}
  \begin{array}{l}
    -k_s(y-x) -  bs(\dot{y} - \dot{x}) = m_2s^2y\\
    (m_2 s^2 +k_s +bs)y - (k_s + bs)x = 0
  \end{array}
\end{eqnarray*}
\begin{eqnarray*}
  \left\{ \begin{array}{l}
    k_wr = (k_s + bs + k_w + m_1s^2)x - (k_s +bs)y\\
    (m_2 s^2 +k_s +bs)y - (k_s + bs)x = 0
    \end{array}\right .
\end{eqnarray*}
La funzione di trasferimento che si ottiene \`e:
$$\dfrac{Y(s)}{R(s)} = \dfrac{\dfrac{k_wb}{m_1m_2} \left( s +
  \dfrac{k_s}{b}\right)}{s^4 + \left( \dfrac{b}{m_1} +
  \dfrac{b}{m_2}\right)s^3 + \left( \dfrac{k_s}{m_1} +
  \dfrac{k_s}{m_2} + \dfrac{k_w}{m_1}\right)s^2 + \left( \dfrac{k_w
  b}{m_1 m_2}\right)s + \dfrac{k_w k_s}{m_1 m_2}}$$

Valutiamo ora la rappresentazione in termini di variabili di stato,
ponendo $x_1 = x$, $x_2 = \dot{x}$, $x_3 = y$, $x_4 = \dot{y}$:
\begin{eqnarray*}
  \left\{ \begin{array}{l}
    \dot{x_1} = x_2\\
    \dot{x_2} = \frac{k_s}{m_1}(x_3 - x_1) + \frac{b}{m_1}(x_4 - x_2)
    - \frac{k_w}{m_1}(x_1 - r)\\
    \dot{x_3} = x_4\\
    \dot{x_4} = \frac{k_s}{m_2}(x_3 - x_1) + \frac{b}{m_2}(x_4 -
    x_2)\\
    x = x_1\\
    Y = x_3
    \end{array}\right .
\end{eqnarray*}
Mentre in termini matriciali, posto:
\[
  x = 
  \begin{bmatrix}
    x_1\\
    x_2\\
    x_3\\
    x_4
  \end{bmatrix}
\]
possiamo scrivere:
\[
  \dot{x} = 
  \begin{bmatrix}
    0 & 1 & 0 & 0\\
    -\frac{k_s - k_w}{m_1} & -\frac{b}{m_1} & \frac{k_s}{m_1} &
    \frac{b}{m_1}\\
    0 & 0 & 0 & 1\\
    -\frac{k_s}{m_2} & \frac{b}{m_2} & -\frac{k_s}{m_2} &
    -\frac{b}{m_2}
  \end{bmatrix}x +
  \begin{bmatrix}
    0\\
    \frac{k_w}{m_1}\\
    0\\
    0
  \end{bmatrix}r
\]

\[
  \begin{bmatrix}
    y\\x
  \end{bmatrix} = 
  \begin{bmatrix}
    0 & 0 & 1 & 0\\
    1 & 0 & 0 & 0
  \end{bmatrix}x
\]
All'equilibrio le derivate sono nulle e si trova che lo stato di
equilibrio del sistema \`e:

\[
  \left\{
  \begin{array}{l}
    \overline{x_2} = \overline{x_4} = 0\\
    \overline{x_1} = \overline{x_3} = r
  \end{array} \right .
\]
A corredo del precedente esempio, consigliamo l'esercizio 2.1 di
pagina 78 del Franklin Powell e relativa soluzione presente nel file
\url{http://ur1.ca/9fzq} . Un dato importante che emerge dall'analisi
di questo tipo di sistemi \`e la necessit\`a di valutare singolarmente
le diverse masse e scegliere accuratamente i sistemi di
riferimento. Osservando con attenzione la soluzione dell'esercizio del
Franklin Powell si nota un differente approccio rispetto a quello
mostrato in questo paragrafo. Ad un'analisi piu' approfondita si
noter\`a che le soluzioni sono equivalenti. \`E la scelta dei sistemi
di riferimento che \`e differente.
\subsubsection{Errori di segno}
La principale fonte di errori sono i ``segni''. Una volta ottenute le
equazioni di un sistema stabile non ci resta che controllare i
segni delle varie variabili. Tutti i segni devono essere
concordi. Considerando il predente esempio, tutte le variabili
$\ddot{x}$, $\dot{x}$ ed $x$ hanno segno concorde. Stesso discorso per
le $\ddot{y}$, $\dot{y}$ e $y$.

\subsection{Moto rotatorio}
Per il moto rotatorio la Legge di Newton si modifica nel seguente modo:

\begin{equation}\label{momentodelleforze}
  M = I \alpha
\end{equation}
dove $M$ \`e il {\em momento delle forze}\index{Momento delle forze} applicate al
sistema (misurato in $N \cdot m$ e spesso indicato alternativamente
con $\tau$), $I$ \`e il {\em momento di inerzia}\index{Momento di
  inerzia} del corpo rispetto all'asse di rotazione ($I = mr^2$) ed
$\alpha$ \`e l'{\em accelerazione
  angolare}\index{Accelerazione angolare} (misurata in $\frac{rad}{s^2}$).
% IMMAGINE DI PAGINA 14
Supponiamo di avere una massa $m$ che si muova nello spazio con
velocit\`a $\vec{v}$. Definiamo la {\em quantit\`a di
  moto}\index{Quantit\`a di moto} come:
\begin{equation}
  \vec{p} = m \vec{v}
\end{equation}
e definiamo la forza come variazione della quantit\`a di moto
$\Rightarrow \vec{F} = \dfrac{d\vec{p}}{dt}$.
Si definisce {\em Momento della quantit\`a di moto}\index{Momento
  della quantit\`a di moto} del punto materiale $m$ rispetto ad un
riferimento fissato $O$ il vettore $\vec{e}$:
\begin{equation}
  \vec{e} \equiv \vec{r^{'}} \times \vec{p}
\end{equation}
Supponiamo che su $m$ sia applicata una forza $\vec{F}$; allora
definiamo il {\em Momento delle forza applicate}\index{Momento delle
  forza} al punto materiale $m$ come:
\begin{equation}
  \vec{\tau} = \vec{r^{'}} \times \vec{F}
\end{equation}
Calcoliamo la derivata temporale di $\vec{e}$:
$$\frac{d \vec{e}}{dt} = \frac{d \vec{r^{'}}}{dt} \times \vec{p} +
\vec{r^{'}} \times \frac{d \vec{p}}{dt} = \frac{d \vec{r^{'}}}{dt}
\times \vec{p} = \vec{\tau}$$
Ma \`e anche vero che:
$$\vec{r^{'}} = \vec{r} - \vec{r_0} \Rightarrow \frac{d
  \vec{r^{'}}}{dt} = \frac{d (\vec{r} - \vec{r_0})}{dt} =
\frac{d\vec{r}}{dt} - \frac{d \vec{r^{'}}}{dt} = \vec{v} -
\xout{\vec{v_0}} = \vec{v}$$
$$\Rightarrow \frac{d \vec{e}}{dt} = \xout{\vec{v} \times \vec{p}} +
\vec{\tau} \Rightarrow \frac{d \vec{e}}{dt} = \vec{\tau}$$

% IMMAGINI DI PAGINA 15

Se invece di un punto materiale, consideriamo un insieme di punti
materiali ognuno con una sua massa e velocit\`a e su cui agiscono
delle forze. Detto $i$ il generico punto materiale, supponiamo che
$m_i$ si muova con velocit\`a $v_i$ e che sia sottoposto ad una forza
$\vec{F_i}$. Il momento della quantit\`a di moto del punto $i$ sar\`a
(per ogni $i$):
$$\frac{d \vec{e_i}}{dt} = \vec{\tau_i}$$
Sommiamo tutte le equazioni degli $N$ punti materiali:
$$\sum_{i=1}^{N} \frac{d \vec{e_i}}{dt} = \sum_{i=1}^{N}
\vec{\tau_i}$$
La derivazione \`e indipendente dalla operazione di somma, per cui
``posso invertire e ottengo di nuovo'':
$$\frac{d \vec{L}}{dt} = \vec{\tau}$$
Nota: se il numero di punti \`e infinito, si effettua l'integrale
piuttosto che la somma.

Condideriamo ora un corpo, all'interno di esso consideriamo un
volumetto infinitesimo $dv$ la cui posizione \`e approssimata a quella
di $P$, punto interno a $dv$. Nel volumetto $dv$ c'\`e una massa pari
a: $dm = \mu(p) dv$ dove $\mu(p)$ \`e la densit\`a del corpo. Il
momento della quantit\`a di moto in questo caso \`e:
\begin{equation}\label{L}
\vec{L} = \int_{v} \vec{r_p} \times \mu(p) dv \vec{v}(p)
\end{equation}
Supponiamo che il corpo stia ruotando. Se conosciamo l'asse su cui ruota
possiamo calcolare le componenti del vettore posizione rispetto a
quell'asse. Per semplicit\`a supponiamo che sia l'asse $y$. Ci sono
due componenti, una ortogonale e l'altra parallela all'asse:
$$\vec{v}(p) = \vec{\omega} \times \vec{r_p} = \vec{\omega} \cdot
(\vec{a_p} + \vec{R_p}) = \xout{\vec{\omega} \times \vec{a_p}} +
\vec{\omega} \times \vec{R_p}$$
Nota: dobbiamo considerare solo il contributo ortogonale
all'asse. Sostituiamo $\vec{v}(p)$ nella \ref{L}:
$$\vec{L} = \int_v \vec{r_p} \times \mu(p) (\vec{\omega} \times
\vec{R_p}) dv = \underbrace{\int_v \mu(p) R_p^2 dv}_\text{I} \cdot
\vec{\omega}$$
Ma $I = \int_v \mu(p) R_p^2 dv$ \`e il momento di inerzia e quindi
$\vec{L} = I \vec{omega}$. Derivando, infine, membro a membro
otteniamo:
\begin{equation}
  \frac{d \vec{L}}{dt} = I \frac{d \vec{\omega}}{dt} = \vec{\tau}
  \Rightarrow \vec{\tau} = I \vec{\alpha}
\end{equation}
ottenendo finalmente il principio $F = m \cdot a$ per i moti rotatori
della \ref{momentodelleforze}.
\begin{figure}[!t]
  \centering
  \includegraphics[width=1.0\textwidth]{./images/mototraslatorio-motorotatorio.png}
  \label{fig:mototraslatorio-motorotatorio}
  \caption{Moto traslatorio - Moto rotatorio\label{fig:mototraslatorio-motorotatorio}}
\end{figure}

\subsection{Controllo di un satellite}
\begin{figure}[!h]
  \centering
  \includegraphics[width=0.3\textwidth]{./images/satellite.png}
  \label{fig:satellite}
  \caption{Schema di controllo di un satellite\label{fig:satellite}}
\end{figure}

Le variabili che considereremo sono la propulsione $F_c$, il momento
delle forze di disturbo $M_D$, la distanza $d$ tra la retta su $F_C$ e
la retta parallela e passante per il centro di massa e infine $y =
\theta$, l'uscita.
La Legge di Newton per il moto
rotatorio\label{leggedinewtonmotorotatorio} \`e:
$$M = I \alpha$$
con $M$ pari alla somma di tutti i momenti esterni, $I$ pari al
momento di inerzia del corpo e $\alpha$ pari al momento angolare.
Applicando la legge sul moto rotatorio e considerando
che sul satellite agisce una forza provocata dalla propulsione che \`e
una coppia di momento $F_c \cdot d$ e un momento $M_D$ dovuto a forze
di disturbo, per lo pi\`u la pressione solare sulle superfici
asimmetriche dei pannelli solari:
$$F_C \cdot d + M_D = I \ddot{\theta}$$
Le ipotesi semplificative sono quindi due: il motore che agisce come
una coppia e il moto in un piano ortogonale all'asse di
rotazione. L'uscita di questo sistema si ottiene per doppia
integrazione della somma della coppie di ingresso. Per questa ragione
questo sistema viene spesso detto {\em doppio
  integratore}\index{Doppio integratore}. La funzione di trasferimento
partendo dall'equazione del moto \`e:

\[
  F_c \cdot M_D = I s^2 \theta \Rightarrow \frac{\theta(s)}{U(s)} =
  \frac{1}{Is^2} \binom{\textrm{2 ingressi}}{\textrm{1 uscita}}
\]
La rappresentazione di stato, posto $x_1 \equiv \theta$ e $x_2 \equiv
\dot{\theta}$ \`e:
\[
  \left\{
  \begin{array}{l}
    \dot{x_1} = x_2\\
    \dot{x_2} = \frac{M_D}{I} + \frac{(F_C \cdot d)}{I}\\
    y = \theta = x_1
  \end{array}\right .
  \Rightarrow
  \begin{array}{l}
    \dot{x} = 
    \begin{bmatrix}
      0 & 1\\
      0 & 0
    \end{bmatrix}x +
    \begin{bmatrix}
      0\\
      \frac{1}{I}
    \end{bmatrix}u\\
    y =
    \begin{bmatrix}
      1 & 0
    \end{bmatrix}x
  \end{array}
\]
Per questo sistema non esiste alcun punto di equilibrio. \'E
deducibile anche dal fatto che manca una qualsiasi forza che si
opponga ad $F_C$.

\subsection{Disco rotante intorno ad un asse con attrico}\label{par:discorotanteattrito}
\begin{figure}[!b]
  \centering
  \includegraphics[width=0.2\textwidth]{./images/discorotanteattrito.png}
  \label{fig:discorotanteattrito}
  \caption{Schema di disco rotante con attrito\label{fig:discorotanteattrito}}
\end{figure}
Le variabili del sistema sono: la coppia motrice in ingresso $u$, il
momento inerziale $I$, lo spostamento angolare $\theta$ e il coeffiente
di attrito $B$. L'equazione del moto \`e:
$$u - B \dot{\theta} = I \ddot{\theta} \;\;\;\textrm{con}\;\;\; I =
\frac{1}{2} m_D R^2$$
La rappresentazione di stato \`e:
\[
  \left\{
  \begin{array}{l}
    \dot{x_1} = x_2 = \dot{\theta}\\
    \dot{x_2} = -\frac{B}{I}x_2 + \frac{u}{I}\\
    y = x_1 = \theta
  \end{array}\right .
\]
La funzione di trasferimento \`e:
\[
  \begin{array}{l}
    \ddot{\theta} = -(\frac{B}{I})\dot{\theta} + \frac{u}{y}\\
    s^2 y = -\frac{B}{I} \cdot sy + \frac{u}{I}\\
    s^2 y + \frac{B}{I} sy = \frac{u}{I}\\
    \frac{y}{u}(s^2 + \frac{B}{I}s) = \frac{u}{I} \cdot \frac{1}{u}
  \end{array}
\]
$$G(s) = \frac{1}{I(s^2 + \frac{B}{I}s)} = \frac{1}{s^2 I +sB}$$

\subsection{Disco rotante intorno ad un asse con attrico ed
  elasticit\`a}
\begin{figure}[!b]
  \centering
  \includegraphics[width=0.2\textwidth]{./images/discorotanteattritoelasticita.png}
  \label{fig:discorotanteattritoelasticita}
  \caption{Schema di disco rotante con attrito ed elasticit\`a\label{fig:discorotanteattritoelasticita}}
\end{figure}
Consideriamo lo stestto esempio. In questo caso, per\`o, \`e presente
anche una certa elasticit\`a dell'asse di rotazione, con $k$ costante
elastica. L'equazione del moto \`e:
$$u - B\dot{\theta} - k \theta = I \ddot{\theta}$$
La funzione di trasferimento \`e:
$$s^2 I \theta = u - s B \theta - k \theta \Rightarrow
\frac{\theta}{u} = \frac{1}{s^2 I + s B  + k}$$
Si nota che l'equilibrio \`e del tutto simile a quella del caso
massa-molla-attrito. Essendo la stessa funzione di trasferimento del
caso massa-molla-attrito (eq. \ref{massa-molla-attrito}) non \`e
necessario procedere con le considerazioni sullo stato, l'equilibrio e
la rappresentazione matriciale.

\subsection{Satellite-Terra}
\begin{figure}[!b]
  \centering
  \includegraphics[width=0.5\textwidth]{./images/terrasatellite.png}
  \label{fig:terrasatellite}
  \caption{Schema di un satellite che ruota intorno alla Terra\label{fig:terrasatellite}}
\end{figure}
Le variabili del sistema sono: la Terra $T$, il satellite $S$,
il versore della direzione tangenziale $i_{\theta}$, il versore
della direzione radiale $i_r$. Modelliamo le interazioni tra due corpi
quando uno ruota intorno all'altro (Satellite-Terra). Per semplicit\`a
supporremo che il satellite si muova sempre lungo un'orbita circolare,
sempre sullo stesso piano perpendicolare all'asse di rotazione e le
dimensioni di Terra e satellite siano trascurabili. Questo tipo di
problema si risolve bene in coordinate cilindriche dove $i_r$
(direzione radiale) e $i_{\theta}$ (direzione tangenziale) ruotano
anch'essi. Da ricordare, la {\em Legge di gravitazione
  universale}\index{Legge di gravitazione universale}:
$$-k \frac{M_T M_S}{r^2}$$
e le {\em Relazioni di Poisson}\index{Poisson}:
\[
  \left\{
  \begin{array}{l}
    \dfrac{di_r}{dt} = \dot{\theta}i_{\theta}\\
    \dfrac{di_{\theta}}{dt} = - \dot{\theta} i_r
  \end{array}\right .
\]
Detta $P$ la posizione del satellite: $\vec{P} = r i_r$, ricordando
che $\dot{P} = r \dot{\theta} i_{\theta} + \dot{r}i_r$, derivando due
volte si ottiene l'accelerazione del satellite:
$$\ddot{P} = (\ddot{r} - r \dot{\theta}^2)i_r + (r \ddot{\theta} + 2r \dot{\theta})i_{\theta}$$
Le forze agenti sul satellite sono:
$$F = \left( -k \dfrac{M_T M_S}{r^2} + u_1 \right)i_r + u_2
i_{\theta}$$
Le equazioni del moto lungo i versori $i_r$ e $i_{\theta}$:
\[
  M_S (\ddot{r} - r \dot{\theta}^2) = -k \dfrac{M_T M_S}{r^2} + u_1
\]
\[
  M_S (r \ddot{\theta} + 2r \dot{\theta}) = u_2
\]
Il modello in forma di stato prevede $x_1 = r$, $x_2 = \dot{r}$, $x_3
= \theta$ e $x_4 = \dot{\theta}$:
\[
  \left\{
  \begin{array}{l}
    \dot{x}_1 = x_2\\
    \dot{x}_2 = - \dfrac{k M_T}{x_1^2} + x_1 x_4^2 +
    \dfrac{u_1}{M_S}\\
    \dot{x}_3 = x_4\\
    \dot{x}_4 = -2 x_4 + \dfrac{u_2}{x_1}\\
    y_1 = x_1\\
    y_2 = x_3
  \end{array}
  \right .
\]
ANDREBBE INTEGRATO, MA NON RIESCO A TROVARE MATERIALE

\subsection{Pendolo}\label{pendolo}
\begin{figure}[!h]
  \centering
  \includegraphics[width=0.3\textwidth]{./images/pendolo.png}
  \label{fig:pendolo}
  \caption{Schema di un pendolo\label{fig:pendolo}}
\end{figure}
Supponiamo di avere un pendolo di lunghezza $l$. L'asta del pendolo
\`e rigida. Alla baste dell'asta c'\`e una massa $m$. \`E presente un
attrito $B$. Le forze agenti
sono la forza applicata e la forza peso. Considereremo le componenti
tangenziali al moto e la componente dovuta all'attrito. Abbiamo che
l'ascissa curvilinea $s$ \`e pari a $s = l \theta$ e l'accelerazione
tangenziale \`e pari a $\ddot{s} = l \ddot{\theta}$. L'equazione del
moto \`e:
\begin{equation}
  u cos\theta - mg sin\theta - B \dot{\theta} = m l \ddot{\theta}
\end{equation}
cio\`e alla forza $u$ in ingresso si oppongono la gravit\`a (lungo
l'asse verticale) e l'attrito $B$.
Scriviamo la rappresentazione di stato ponendo $x_1 = \theta$ e $x_2 =
\dot{\theta}$:
\[
  \left\{
  \begin{array}{l}
    \dot{x_1} = x_2\\
    \dot{x_2} = \dfrac{1}{ml}\;u\;cos{x_1} - \dfrac{B}{ml}\;x_2 -
    \dfrac{g}{l}\;sin{x_1}
  \end{array}\right .
\]
Ponendo le derivate pari a zero, $x_2 = 0$ e, quindi, i punti di
equilibrio del sistema sono:
$$mg\sin{\overline{\theta}} = \overline{u}cos{\overline{\theta}}
\Rightarrow \overline{\theta} \;arctg
\left(\frac{\overline{u}}{mg}\right)$$
Se l'ingresso $\overline{u}$ di equilibrio \`e nullo si ottengono due
punti di equilibrio:
$\overline{\theta_1} = 0$ e $\overline{\theta_2} = \pi$.

\subsection{Carro-Ponte}
\begin{figure}[!h]
  \centering
  \includegraphics[width=0.5\textwidth]{./images/carroponte.png}
  \label{fig:carroponte}
  \caption{Schema di un carro-ponte\label{fig:carroponte}}
\end{figure}
Il Carro-Ponte \`e un sistema complesso che, per\`o, pu\`o essere diviso in due
sottosistemi che gi\`a abbiamo studiato: il carrello (\ref{carrello})
ed il pendolo (\ref{pendolo}).
\begin{figure}[!b]
  \centering
  \includegraphics[width=0.5\textwidth]{./images/carroponte-carrello.png}
  \label{fig:carroponte-carrello}
  \caption{Schema di un carro-ponte: dettaglio del carrello\label{fig:carroponte-carrello}}
\end{figure}
Per il sottosistema ``carrello'', le equazioni sono quelle gi\`a
ampiamente discusse:
\begin{equation}\label{eq:carroponte-carrello}
  m_t \ddot{x} = u - N - b \dot{x}
\end{equation}
con lo spostamento $x$, l'attrito $b$ ed una sconosciuta forza di
reazione $N$ applicata dal pendolo.
Per il sottosistema del pendolo, le considerazioni sono leggermente diverse da
quelle fatte in precedenza poich\`e il fulcro del pendolo non \`e
fisso rispetto al sistema di riferimento inerziale: vanno considerate,
quindi, anche la rotazione del pendolo e lo spostamento del suo centro
di massa.
\begin{figure}[!h]
  \centering
  \includegraphics[width=0.3\textwidth]{./images/carroponte-pendolo-a.png}
  \label{fig:carroponte-pendolo-a}
  \caption{Schema di un carro-ponte: dettaglio del pendolo\label{fig:carroponte-pendolo-a}}
\end{figure}
La figura \ref{fig:carroponte-pendolo-a} mostra alcune delle
caratteristiche di questo sottosistema:
\begin{itemize}
\item $l \dot{\theta}^2$ \`e la componente accelerazione lungo il
  pendolo ed \`e detta {\em accelerazione
    centripeta}\index{Accelerazione centripeta} ed \`e presente in
  ogni oggetto la cui velocit\`a cambi direzione;
\item $\ddot{x}$ \`e una componente dell'accelerazione ed \`e una
  conseguenza del fulcro del pendolo che accelera a causa
  dell'accelerazione del carrello. Avr\`a sempre la stessa direzione e
  modulo di quella del carrello;
\item $l \ddot{\theta}$ \`e il risultato dell'accelerazione angolare
  del pendolo ed \`e sempre perpendicolare al pendolo stesso.
\end{itemize}
Questi risultati possono essere confermati considerando il centro di
massa del pendolo come un vettore, in riferimento ad un sistema di
riferimento inerziale, come mostrato in figura \ref{fig:carroponte-pendolo-b}.
\begin{figure}[!h]
  \centering
  \includegraphics[width=0.3\textwidth]{./images/carroponte-pendolo-b.png}
  \label{fig:carroponte-pendolo-b}
  \caption{Schema di un carro-ponte: dettaglio del pendolo\label{fig:carroponte-pendolo-b}}
\end{figure}
La figura \ref{fig:carroponte-pendolo-b} mostra gli assi
$\hat{i}$ e $\hat{j}$, inerzialmente fissi e il vettore $\vec{r}$ che
descrive la posizione del centro di massa del pendolo. Il vettore
$\vec{r}$ pu\`o essere espresso come:
\[
  \vec{r} = x \hat{i} + l (\hat{i} sin \theta - \hat{j} cos \theta)
\]
Derivando otteniamo:
\[
\begin{array}{l}
  \dot{\vec{r}} = \dot{x} \hat{i} + l \dot{\theta} (\hat{i} cos \theta
  + \hat{j} sin \theta)\\
  \ddot{\vec{r}} = \ddot{x} \hat{i} + l \ddot{\theta} (\hat{i} cos
  \theta + \hat{j} sin \theta) - l \dot{\theta}^2 ( \hat{i} sin \theta
  - \hat{j} cos \theta)
\end{array}
\]
Abbiamo ottenuto tutte le equazioni del sistema. In teoria potremmo
applicare le equazioni per il moto traslatorio e rotatorio fino ad
ottenere tre equazioni in tre incognite: $N$, $P$ e $\theta$. Questo
sistema di equazioni pu\`o per\`o essere manipolato fino ad arrivare
ad una sola equazione in $\theta$:
\begin{equation}\label{eq:carroponte-N}
  N = m_p \ddot{x} + m_p l \ddot{\theta} cos \theta - m_p l
  \dot{\theta}^2 sin \theta
\end{equation}
Tuttavia possiamo limitare notevolmente i calcoli se applichiamo le
equazioni perpendicolarmete al pendolo:
\begin{equation}\label{eq:carroponte-P}
P sin \theta + N cos \theta - m_p g sin \theta = m_p l \ddot{\theta} +
m_p \ddot{x} cos \theta
\end{equation}
Applicando le equazioni intorno al centro di massa del pendolo
otteniamo:
\begin{equation}\label{eq:carroponte-I}
  - P l sin \theta - N l cos \theta = I \ddot{\theta}
\end{equation}
Combinando la \ref{eq:carroponte-N} e la \ref{eq:carroponte-carrello} otteniamo:
\begin{equation}
  (m_t + m_p) \ddot{x} + b \dot{x} + m_p l \ddot{\theta} cos \theta -
  m_p l \dot{\theta}^2 sin \theta = u
\end{equation}
Combinando la \ref{eq:carroponte-P} e la \ref{eq:carroponte-I}
otteniamo:
\begin{equation}
  (I + m_p l^2) \ddot{x} + m_p g l sin \theta = - m_p l \ddot{x} cos \theta
\end{equation}
Entrambe le equazioni sono non-lineari e vanno linearizzate per
piccoli spostamenti ($\theta = 0$). Supponiamo che $cos \theta
\cong 1$, $sin \theta \cong 0$ e $\dot{\theta}^2 \cong
0$. In questo modo le equazioni diventano:
\begin{equation}\label{eq:carroponte-nonlineare}
  \left\{
  \begin{array}{l}
    ( I + m_p l^2) \ddot{\theta} + m_p g l \theta = - m_p l \ddot{x}\\
    (m_t + m_p) \ddot{x} + b \dot{x} + m_p l \ddot{\theta} = u
  \end{array}
  \right .
\end{equation}
Trascurando l'attrito otteniamo la funzione di trasfermimento:
\begin{equation}
  \dfrac{\Theta(s)}{U(s)} = \dfrac{- m_p l}{((I + m_p l^2)(m_t + m_p)
    - m_p^2 l^2)s^2 + m_p g l (m_t + m_p)}
\end{equation}

\subsubsection{Pendolo inverso}\index{Pendolo inverso}
Nel caso del pendolo inverso, cio\`e considerando un carrello che si
muove su un piano e il fulcro del pendolo posto sul carrello le
considerazioni da fare sono diverse. Quando, in precedenza, abbiamo
assunto che $\theta \cong \pi$ assumiamo ora $\theta \cong \pi +
\theta'$, con $\theta'$ pari al movimento verso l'alto. In questo
caso, $cos \theta \cong -1$ e $sin \theta \cong - \theta'$ trasformano
la \ref{eq:carroponte-nonlineare} in:
\begin{equation}\label{eq:carroponte-pendoloinverso}
  \left\{
  \begin{array}{l}
    ( I + m_p l^2) \ddot{\theta'} - m_p g l \theta' = m_p l \ddot{x}\\
    (m_t + m_p) \ddot{x} + b \dot{x} - m_p l \ddot{\theta'} = u
  \end{array}
  \right .
\end{equation}
Come detto in precedenza, un sistema stabile ha sempre segni concordi
per le stesse variabili. Nelle equazioni precedenti notiamo che
$\theta'$ e $\ddot{\theta'}$ hanno segno opposto; ci\`o indica
``instabilit\`a'', che \`e la caratteristica principale del pendolo
inverso. La funzione di trasferimento, nuovamente ignorando l'attrito,
\`e: 
\begin{equation}
   \dfrac{\Theta'(s)}{U(s)} = \dfrac{m_p l}{((I + m_p l^2) - m_p^2
     l^2) s^2 - m_p g l (m_t + m_p)}
\end{equation}

\section{Sistemi elettrici}

\subsection{Legge di Kirchhoff ai nodi}
\begin{equation}\label{eq:kirchhoff-nodi}
  \sum_{i=1}^{N} I_k = 0
\end{equation}
La sommatoria delle correnti afferenti ad un nodo \`e nulla

\subsection{Legge di Kirchhoff alle tensioni}
\begin{equation}\label{eq:kirchhoff-tensioni}
  \sum v_{ij} = 0
\end{equation}
La sommatoria delle tensioni appartenenti ad una maglia \`e nulla.

\subsection{I principali elementi elettrici}

\begin{itemize}
  \item Il resistore
    $$ V_R = R i_R \Rightarrow V_R = R I_R$$
  \item Il condensatore
    $$ i_C = C \frac{dV_c}{dt} \Rightarrow V_C = \frac{1}{sC} I_C$$
  \item L'induttore
    $$V_L = L \frac{di_l}{dt} \Rightarrow V_L = sL I_L$$
\end{itemize}

\subsection{Sistemi elettromagnetici}

\begin{itemize}
  \item Una carica elettrica\index{Carica elettrica} $q$, in moto in un campo di induzione
    magnetica $B$ con velocit\`a $\vec{v}$, \`e soggetta ad una forza
    magnetica $$ \vec{F} = q \vec{v} \times \vec{B}$$
  \item Dato un filo rettilineo\index{Filo} di lunghezza $l$, percorso da corrente
    di intensit\`a $I$, immerso in un campo di induzione magnetica
    $B$, la forza magnetica agente sul filo \`e $$\vec{F} = I \vec{l}
    \times \vec{B}$$
  \item Data una spira\index{Spira} immersa in un campo di induzione
    magnetica $\vec{B}$ entrante, il flusso magnetico concatenato con
    la spira \`e $$\Phi_B = Blx$$ con $x$ pari alla distanza tra il
    lato sinistro della spira ed il limite del campo magnetico. Quando
    la spira si muove con velocit\`a $\vec{v}$ il flusso varia:
    $$\dot{\Phi}_B = Bl \dot{x} = -Blv$$
    Tale variazione di flusso produce una {\em forza
      elettromotrice}\index{Forza elettromotrice}
    $$e = Blv$$ sulla spira, che fa fluire nella spira stessa una
    corrente $I$.
\end{itemize}

\subsection{Circuito RLC}
\begin{figure}[!b]
\centering
\includegraphics[width=0.5\textwidth]{./images/circuitorlc.png}
\caption{Circuito RLC\label{fig:circuitorlc}}
\end{figure}
Applicando le leggi di Kirchhoff (\ref{eq:kirchhoff-nodi} e
\ref{eq:kirchhoff-tensioni}) otteniamo le seguenti equazioni:
\[
  \left\{
  \begin{array}{l}
    i_L + i_R + i_C = r\\
    v_R = v_L = v_C = y
  \end{array}
  \right .
\]
Sostituendo le caratteristiche tensione-corrente per i singoli
elementi elettrici, si ottiene:
\[
  \left\{
  \begin{array}{l}
   \dfrac{y}{R} + i_L + C \dfrac{dv_C}{dt} = r\\
   y = L \dfrac{di_L}{dt}
  \end{array}
  \right .
\]
Derivando la prima equazione e sostituendo alla derivata di $i_L$ la
seconda equazione, se ne ricava una finale pari a:
\[
  \ddot{y} + \dfrac{\dot{y}}{RC} + \dfrac{y}{LC} = \dfrac{\dot{r}}{C}
\]
Sostituendo $s$ a $\dfrac{d}{dt}$ possiamo ottenere la funzione di
trasferimento: 
\[
  \begin{array}{l}
    \ddot{y} + \dfrac{\dot{y}}{RC} + \dfrac{y}{LC} =
    \dfrac{\dot{r}}{C}\\
    s^2 Y + \dfrac{sY}{RC} + \dfrac{Y}{LC} = \dfrac{sr}{C}\\
    Y(s^2 + \dfrac{s}{RC} + \dfrac{1}{LC}) = \dfrac{sr}{C}\\
  \end{array}
\]
\begin{equation}\label{eq:fdt-circuitorlc}
  G(s) = \dfrac{1}{sC + \dfrac{1}{R} + \dfrac{1}{sL}}
\end{equation}
Per ottenere la rappresentazione in forma di stato, poniamo $i_L =
x_1$, $v_C = x_2$:
\[
  \left\{
  \begin{array}{l}
    \dot{x}_1 = \dfrac{x_2}{L}\\
    \dot{x}_2 = - \dfrac{x_1}{C} - \dfrac{x_2}{RC} + \dfrac{r}{C}\\
    y = x_2
  \end{array}
  \right .
\]


\subsection{Amplificatore operazionale}
\begin{figure}[!b]
\centering
\includegraphics[width=0.8\textwidth]{./images/opamp.png}
\caption{Amplificatore operazionale\label{fig:opamp}}
\end{figure}
\`E un elemento attivo e fornisce un alto guadagno nella regione di
funzionamento lineare. L'amplificatore ideale ha le seguenti principali
propriet\`a:
\begin{itemize}
\item $i_1 = i_2 = 0$ cio\`e la corrente entrante nell'amplificatore
  \`e nulla, quindi si ha una impedenza d'ingresso infinita;
\item $v_2 - v_1 = 0$ cio\`e il corto circuito virtuale tra i due
  morsetti d'ingresso;
\item $R_1 = \infty$, $R_O = 0$ e $K = \infty$;
\end{itemize}
Il legame ingresso-uscita \`e quindi:
\[
  v_O = - K (v_1 - v_2)
\]
\subsubsection{Configurazione invertente}
\begin{figure}[!t]
\centering
\includegraphics[width=0.5\textwidth]{./images/opamp02.png}
\caption{Amplificatore operazionale in configurazione invertente\label{fig:opamp-inv}}
\end{figure}
Il generatore \`e collegato al morsetto ``-'' e il morsetto ``+'' \`e
posto a massa:
\[
  \begin{array}{c}
    \dfrac{v_1 - v_{in}}{R_1} + \dfrac{v_1 - v_o}{R_2} = 0\\
    \textrm{ che con } v_1 - v_2 = 0 \textrm{ e } v_2 \textrm{ a massa
    ci porta a }\\
    -\dfrac{v_{in}}{R_1} = \dfrac{v_o}{R_2}\\
    \Downarrow\\
    \dfrac{v_o}{v_{in}} = -\dfrac{R_2}{R_1}
  \end{array}
\]

\subsubsection{Integratore di Miller}\index{Integratore di Miller}
\begin{figure}[!h]
\centering
\includegraphics[width=0.5\textwidth]{./images/opamp03.png}
\caption{Amplificatore operazionale - Integratore di Miller\label{fig:opamp-mil}}
\end{figure}
Date le propriet\`a dell'amplificatore ideale, si ha:
\[
  \left\{\begin{array}{l}
    i_c = C \dfrac{d(v_1 - v_o)}{dt}\\
    i_R = \dfrac{v_1 - v_{in}}{R}
  \end{array}\right .
  \Rightarrow - \dfrac{v_{in}}{R} - C \dfrac{dv_o}{dt} = 0
\]
\[
  - \int\dfrac{v_{in}}{R} = \int C \dfrac{dv_o}{dt} \Rightarrow
\]
\[
  - \dfrac{1}{RC}\int\limits_0^t v_{in}(\tau)d\tau = v_o(t) - v_o(0)
\]
Ecco l'integratore:
\[
  v_o(t) = - \dfrac{1}{RC}\int\limits_0^t v_{in}(\tau)d\tau + v_o(0)
\]
La funzione di trasferimento \`e:
\[
  \dfrac{V_O (s)}{V_{in} (s)} = G (s) = - \dfrac{1}{sRC}
\]

\subsection{Forza magnetica}
\begin{figure}[!h]
\centering
\includegraphics[width=0.2\textwidth]{./images/forza-magnetica.png}
\caption{Forza magnetica\label{fig:forza-magnetica}}
\end{figure}
Una carica elettrica $q$, in moto in un campo di induzione magnetica $B$ con
velocit\`a $v$, \`e soggetta ad una forza magnetica
\begin{equation}\label{eq:forza-magnetica}
  \vec{F} = q \vec{v} \times \vec{B}
\end{equation}
Il modulo di $F$ \`e $q v B sin \theta$, il verso \`e perpendicolare a
$v$ e $B$ e si calcola con la regola della mano destra.

\subsubsection{Forza magnetica su un filo conduttore}
\begin{figure}[!h]
\centering
\includegraphics[width=0.2\textwidth]{./images/forza-magnetica02.png}
\caption{Forza magnetica su un filo conduttore\label{fig:forza-magnetica02}}
\end{figure}
Dato un filo rettilineo di lunghezza $L$, percorso da corrente di
intensit\`a $I$, immerso in un campo di induzione magnetica $B$, la
forza magnetica agente sul filo \`e:
\begin{equation}\label{eq:forza-magnetica-filo}
  \vec{F} = I \vec{L} \times \vec{B}
\end{equation}

\subsubsection{Forza elettromotrice indotta}
\begin{figure}[!h]
\centering
\includegraphics[width=0.3\textwidth]{./images/forza-magnetica03.png}
\caption{Forza elettromotrice indotta\label{fig:forza-magnetica03}}
\end{figure}
Data una spira immersa in un campo di induzione magnetica $B$
entrante, il flusso magnetico concatenato con la spira
\[
  \Phi_B = B l x
\]
dove $x$ \`e la distanza tra il lato sinistro della spira e il limite
destro del campo magnetico. Quando la spira si muove con velocit\`a
$v$, il flusso varia:
\[
  \dot{\Phi}_B = B l \dot{x} = - B l v
\]
Tale variazione di flusso produce una forza elettromotrice 
\[
  e(t) = B l v
\]
sulla spira, che  fa fluire nella spira stessa una corrente $I$.
\subsubsection{Forza contro-elettromotrice}
\begin{figure}[!h]
\centering
\includegraphics[width=0.3\textwidth]{./images/forza-magnetica04.png}
\caption{Forza contro-elettromotrice\label{fig:forza-magnetica04}}
\end{figure}
Una spira percorsa da corrente $I$, che ruota in un campo di induzione
magnetica $B$ con velocit\` angolare $\omega$ il flusso magnetico
concatenato con la spira \`e
\[
  \Phi_B = B l sin \alpha
\]
con $\alpha$ pari all'angolo formato dalla spira con il campo $B$. Al
ruotare della spira, il flusso varia:
\[
  \dot{\Phi}_B = B l x \dot{\alpha} cos \alpha = - B l x \omega cos \alpha
\]
La forza elettromotrice indotta, pari a
\[
  e = B l x \omega cos \alpha
\]
si oppone alla tensione d'alimentazione della spira ed \`e detta {\em
  forza contro-elettromotrice}.

\subsection{Altoparlante}
\begin{figure}[!h]
\centering
\includegraphics[width=0.5\textwidth]{./images/altoparlante.png}
\caption{Altoparlante\label{fig:altoparlante}}
\end{figure}
L'altoparlante \`e composto da $N$ spire di lunghezza $l$ avvolte
intorno al polo $N$ dell'elemento ferromagnetico. Le spire sono
attraversate dalla corrente $i$. Il campo di induzione magnetica \`e
$B$. La forza magnetica che agisce sulle spire \`e:
\[
  F = N l i B
\]
Questa forza induce le spire ad un movimento orizzontale. Durante il
loro movimento, le spire, di massa $M$, incontrano un attrico viscoso $b$ imposto
dall'ambiente. Applicando la Legge di Newton (\ref{leggedinewton})
abbiamo:
\begin{equation}\label{eq:amplificatore}
  M \ddot{x} + b \dot{x} = F
\end{equation}
\begin{figure}[!h]
\centering
\includegraphics[width=0.5\textwidth]{./images/altoparlante02.png}
\caption{Altoparlante e circuito di alimentazione\label{fig:altoparlante02}}
\end{figure}
Consideriamo il circuito con cui sono alimentate le spire (figura
\ref{fig:altoparlante02}). Questo circuito avr\`a una sua resistenza
$R$ ed una induttanza $L$. \`E presente anche un generatore di
tensione $v_a$. Lo spostamento delle spire nel campo $B$ produce una
forza contro-elettromotrice
\[
  e = B l v
\]
dove $v = \dot{x}$. L'equazione alla maglia di alimentazione \`e:
\begin{equation}\label{eq:Altoparlante-circuito}
  L \dfrac{di}{dt} + Ri = v_a - e
\end{equation}

\subsection{Motore in corrente continua}
\begin{figure}[!t]
\centering
\includegraphics[width=0.5\textwidth]{./images/motoreDC.png}
\caption{Motore in corrente continua\label{fig:motoreDC}}
\end{figure}
Lo statore di figura \ref{fig:motoreDC} pu\`o essere di materiale ferromagnetico, oppure un magnete
permanente. Il rotore \`e avvolto, parallelamente al suo asse di
rotazione, da $N$ bobine. Le bobine sono alimentate a turno da un
commutatore e due spazzole, alle quali arriva la corrente $i$ dal
circuito di alimentazione. All'albero motore si collega un carico, che
viene messo in rotazione dal motore.
\begin{figure}[!t]
\centering
\includegraphics[width=0.2\textwidth]{./images/motoreDC02.png}
\caption{Motore in corrente continua - Vista frontale\label{fig:motoreDC02}}
\end{figure}
La corrente entra in ogni bobina nella parte superiore del rotore ed
esce da quella inferiore. Su ogni bobina agisce la  forza magnetica
\[
F=Bli
\]
dal lato in ingresso della corrente e dal lato in uscita. La coppia
prodotta su ciascuna bobina \`e:
\[
  T = F r sin \alpha
\]
\begin{figure}[!t]
  \centering
  \includegraphics[width=0.3\textwidth]{./images/motoreDC03.png}
  \caption{Motore in corrente continua - Vista frontale dettagliata
    \label{fig:motoreDC03}}
\end{figure}
La coppia prodotta sul rotore dipende dall'angolo $\alpha$ (figura
\ref{fig:motoreDC03}): usando $N$ 
bobine avvolte al rotore, la coppia totale sar\`a una media di tutte
le coppie applicate alle singole bobine e sar\`a eliminata la dipendenza da
$\alpha$. La coppia complessiva sar\`a
\[
  T = K_t i_a
\]
con $K_t$ costante di coppia ed $i_a$ corrente nelle
armature. 

Analogamente si pu\`o vedere che ogni bobina alimentata subisce una
forza contro-elettromotrice dipendente dalla velocit\`a angolare
$\dot{\theta}_m$ del motore e da $\alpha$. La forza
contro-elettromotrice complessiva \`e
\[
  e = K_e \dot{\theta}_m
\]
con $K_e$ equivalene elettrica della costante di coppia $K_t$ e
$\dot{\theta}_m$ velocit\`a di rotazione dell'albero motore.
\begin{figure}[!t]
\centering
\includegraphics[width=0.5\textwidth]{./images/motoreDC04.png}
\caption{Circuito di alimentazione del motore DC\label{fig:motoreDC04}}
\end{figure}
Consideriamo il circuito di alimentazione del motore di figura
\ref{fig:motoreDC04}: esso \`e costituito da un generatore di tensione
$v_a$, una resistenza $R_a$ ed un'induttanza $L_a$. L'equazione di
tale circuito \`e:
\[
  L_a \dfrac{di_a}{d_t} + R_a i_a + K_e \dot{\theta} = v_a
\]
\begin{figure}[!b]
\centering
\includegraphics[width=0.3\textwidth]{./images/motoreDC05.png}
\caption{Motore DC - Parte meccanica\label{fig:motoreDC05}}
\end{figure}
Per quanto riguarda la parte meccanica del motore (figura
\ref{fig:motoreDC05}), se sull'asse del rotore si pone un carico di
inerzia $J_l$, la Legge di Newton (\ref{leggedinewton}) ci porta alle equazioni:
\[
  \begin{array}{l}
    J_m \ddot{\theta}_m + b( \dot{\theta}_m - \dot{\theta}_l) + k
    (\theta_m - \theta_l) = K_t i_a\\
    J_l \ddot{\theta}_l + b( \dot{\theta}_l - \dot{\theta}_m) + k
    (\theta_l - \theta_m) = 0
  \end{array}
\]
Per qualche approfonfimento sul moto rotatorio fate riferimento al
paragrafo \ref{par:discorotanteattrito}.



\section{Dinamica dei fluidi}
Le relazioni fisiche che governano i flussi di fluidi sono la
continuit\`a, l'equilibrio tra le forze e la resistenza. La relazione
di continuit\`a \`e semplicemente una dichiarazione di conservazione
della materia:
\begin{equation}\label{eq:conservazione-massa}
  \dot{m} = \omega_{in} - \omega_{out}
\end{equation}
dove
\begin{itemize}
\item $m$ = massa del fluido
\item $\omega_{in}$ = portata dell'ingresso
\item $\omega_{out}$ = portata dell'uscita
\end{itemize}

\subsection{Serbatoio}
\begin{figure}[!h]
\centering
\includegraphics[width=0.5\textwidth]{./images/serbatoio.png}
\caption{Serbatoio\label{fig:serbatoio}}
\end{figure}
Nel caso di un semplice contenitore, applicando la
\ref{eq:conservazione-massa} otteniamo l'equazione del {\em moto
  fluidi per i serbatoi}\index{Serbatoio}\index{Serbatoio}:
\begin{equation}\label{eq:fluidi-serbatoio}
  \dot{h} = \frac{\omega_{in} - \omega_{out}}{A \rho}
\end{equation}
dove
\begin{itemize}
\item $A$ \`e l'area del serbatoio;
\item $\rho$ \`e la densit\`a del fluido;
\item $h = \dfrac{m}{A \rho}$ \`e l'altezza dell'acqua;
\item $A \rho$ definisce la quantit\`a di fluido, in litri, che
  attraversa la sezione;
\item $m$ \`e la massa di acqua nel serbatoio.
\end{itemize}

\subsection{Pistone idraulico}
\begin{figure}[!h]
\centering
\includegraphics[width=0.5\textwidth]{./images/pistone.png}
\caption{Pistone\label{fig:pistone}}
\end{figure}
Considerata una forza $F_D$ che aziona un pistone idraulico ed una
pressione $p$ nella camera del pistone, possiamo applicare la
\ref{leggedinewton} e la sua equivalente per i fluidi:
\begin{equation}\label{eq:newton-fluidi}\index{Legge di Newton per i fluidi}
  f = p A
\end{equation}
dove
\begin{itemize}
\item $f$ \`e la forza;
\item $p$ \`e la pressione;
\item $A$ \`e l'area della superficie contro cui il fluido preme
\end{itemize}
Ne consegue l'equazione del moto del pistone:
\begin{equation}\label{eq:pistone}
  M\ddot{x} = A \cdot p - F_D
\end{equation}
dove
\begin{itemize}
\item $A$ \`e l'area del pistone;
\item $p$ \`e la pressione della camera;
\item $M$ \`e la massa del pistone;
\item $x$ \`e la posizione del pistone.
\end{itemize}

\subsection{Flusso attraverso un orifizio}\index{Orifizio}
Se nel corso del suo flusso, il liquido incontra una restrizione
(pu\`o essere rappresentata da un orifizio o da una valvola, figura \ref{fig:orifizio}), la
pressione varia e quindi anche il flusso:
\begin{equation}\label{eq:orifizio}
  \omega = \frac{1}{R} (p_1 - p_2)^{\frac{1}{\alpha}}
\end{equation}
dove
\begin{itemize}
\item $p_1$ \`e la pressione prima della costrizione;
\item $p_2$ \`e la pressione dopo la costrizione;
\item $R$ \`e la resistenza idrica;
\item $\omega$ \`e la portata di fluido che passa per la costrizione.
\end{itemize}
Tipicamente si pone $\alpha = 1$ se il condotto \`e lungo e il flusso
\`e laminare e lento. Diversamente $\alpha = 2$ se il condotto \`e
corto e il flusso \`e turbolento. Noi supporremo sempre $\alpha = 2$.

\subsection{Attuatore idraulico}
\begin{figure}[!b]
\centering
\includegraphics[width=0.9\textwidth]{./images/attuatoreidraulico.png}
\caption{Attuatore idraulico\label{fig:attuatoreidraulico}}
\end{figure}
``In senso lato, un attuatore \`e talvolta definito come un qualsiasi
dispositivo che converte dell'energia da una forma ad un'altra, in
modo che questa agisca nell'ambiente fisico al posto dell'uomo.'' -
Wikipedia 

L'ingresso di controllo \`e $x$, il segnale di attuazione \`e
$y$. Supponendo i flussi attraverso gli orifizi proporzionali ad $x$:
\[
  \omega_1 = \dfrac{1}{R_1} (p_s - p_1)^{1/2}x
\]
\[
  \omega_2 = \dfrac{1}{R_2} (p_2 - p_e)^{1/2}x
\]
Applicando la relazione di continuit\`a otteniamo:
\begin{equation}
  \rho A \dot{y} = \omega_1 = \omega_2
\end{equation}
dove $A$ \`e l'area del pistone e $\rho$ \`e la densit\`a del
liquido. In aggiunta definiamo il bilancio delle forze sul pistone
come:
\begin{equation}
  A (p_1 - p_2) - F = m \ddot{y}
\end{equation}
dove $F$ \`e la forza applicata all'asta del pistone dal punto di
aggancio del sistema controllato. L'equazione del moto del sistema
controllato \`e:
\begin{equation}
  I \ddot{\theta} = F l cos \theta - F_a d
\end{equation}
dove $F_a$ \`e la forza dovuta al carico aerodinamico.

\subsection{Esempio di serbatoio con costrizione}
\begin{figure}[!t]
\centering
\includegraphics[width=0.5\textwidth]{./images/orifizio.png}
\caption{Orifizio\label{fig:orifizio}}
\end{figure}
Abbiamo gi\`a visto che per l'altezza $h$ vale la legge:
\begin{equation}
  \dot{h} = \dfrac{\omega_{in} - \omega_{out}}{A \rho}
\end{equation}
In questo caso c'\`e per\`o una restrizione, come nel punto di uscita
in figura \ref{fig:serbatoio}, che ci porta a riscrivere
la relazione:
\begin{equation}
  \omega_{out} = \dfrac{1}{R} \left(p_i - p_a \right)^{\frac{1}{2}}
\end{equation}
con
\begin{equation}
  p_i = \rho g h + p_a
\end{equation}
con $p_i$ pressione dell'acqua e $p_a$ pressione
dell'ambiente. Sostituendo, si ottiene:
\begin{equation}
  \dot{h} = \dfrac{1}{A \rho} \left(\omega_{in} - \dfrac{1}{R}\sqrt{\rho g h}\right)
\end{equation}
\subsubsection{Punto di equilibrio}
Dato un $\overline{\omega}_{in}$ costante, se esiste un punto di
equilibrio deve essere $\overline{h}$ costante:
\[
  0 = \dfrac{1}{A \rho} \left( \overline{\omega}_{in} -
  \dfrac{1}{R}\sqrt{\rho g \overline{h}} \right) \Rightarrow
  \overline{\omega}_{in} = \dfrac{\sqrt{\rho g \overline{h}}}{R}
  \Rightarrow \overline{h} = \dfrac{R^2 \cdot \omega_{in}^2}{\rho g}
\]
\subsubsection{Linearizzazione intorno ad $\overline{h}$}
\[
  \begin{array}{l}
    \omega_{in} = \overline{\omega}_{in} + \delta \omega_{in}\\
    h = \overline{h} + \delta h\\
    \delta \dot{h} = \dfrac{1}{\rho A} (\overline{\omega}_{in} + \delta
    \omega_{in}) - \dfrac{1}{\rho AR}\sqrt{\rho g (\overline{h} +
      \delta h)}
  \end{array}
\]
Sviluppando in serie di $\sqrt{\overline{h} - \delta h}$ con $\delta h
\rightarrow 0$ si ha:
\[
  \sqrt{\overline{h}} + \left . \frac{1}{2} \cdot \dfrac{1}{\sqrt{\overline{h}
      + \delta h}}\right|_{\delta h \rightarrow 0} \cdot \delta h =
  \sqrt{\overline{h}} + \frac{1}{2} \dfrac{\delta h}{\sqrt{\overline{h}}}
\]
Sostituendo si ottiene l'equazione lineare in $\delta h$:
\[
  \delta \dot{h} = \dfrac{1}{\rho A} \delta \omega_{in} =
  \dfrac{\sqrt{g} \delta h}{\sqrt{\rho \overline{h}} \cdot 2 AR}
\]

\section{Scambio termico}
\begin{figure}[!h]
  \centering
  \includegraphics[width=0.4\textwidth]{./images/scambiotermico01.png}
  \caption{Scambio termico\label{fig:scambiotermico01}}
\end{figure}
Abbiamo due ambienti separati da una parete, la quale lascia passare
il calore. La quantit\`a di calore $q$ che viene scambiata attraverso
la parete \`e:
\begin{equation}
  q = \frac{1}{R} (T_1 - T_2)
\end{equation}
$R$ \`e la resistenza termica della parete, $T_1$ \`e la temperatura
dell'ambiente 1 e $T_2$ quella dell'ambiente 2. Se $T_1 > T_2$, il flusso
di calore si muove dall'ambiente $1$ all'ambiente $2$. In generale
questa relazione vale nel caso in cui il passaggio di calore non
modifichi in modo significativo la temperatura. Per la variazione di
temperatura $\Delta T$ si pu\`o fare riferimento ad un'altra relazione:

\begin{equation}
\dot{T} = \frac{1}{C}q
\end{equation}
con $C$ capaticit\`a termica. La capaticit\`a termica \`e quel flusso
di calore necessario da applicare in ingresso ad un sistema per
determinare una variazione unitaria della temperatura.

\subsection{Temperatura in una stanza}
Consideriamo una stanza con tutti i lati isolati tranne due, i quali
scambiano calore con l'esterno. Detta $T_i$ la temperatura interna,
$T_o$ quella esterna e $C$ la capaticit\`a termica dell'aria
all'interno della stanza, si ha:
\begin{equation}
  \dot{T} = \frac{1}{C} \left[ \frac{1}{R_1}(T_o - T_i) +
    \frac{1}{R_2}(T_o - T_i) \right] 
\end{equation}
dove $R_1$ ed $R_2$ sono pari alle resistenze delle pareti al passaggio del
calore, $q_{in}$ \`e la quantit\`a di calore che la stanza
``acquista'', $q_{out}$ \`e la quantit\`a di calore che la stanza ``cede''
ad un ambiente pi\`u freddo. L'esercizio 2.25 del Franklin-Powell offre un interessante
esempio di applicazione di questi concetti. Il cardine di tutta
la risoluzione \`e l'analisi del comportamento del calore in relazione
ad ogni singola parete. Il calore muove sempre dall'ambiente pi\`u caldo all'ambiente
pi\`u freddo. Va, quindi, valutata la temperatura interna della stanza
e valutata l'eventualit\`a che la stanza sia collegata ad una stanza
pi\`u fredda o pi\`u calda, cio\`e che ``ceda'' o ``acquisti'' calore.

\subsection{Fluidi che si mescolano}
Il calore pu\`o anche fluire quando una massa pi\`u calda si mescola
con una pi\`u fredda. In questo caso:
\begin{equation}
  q = W C_s (T_1 - T_2)
\end{equation}
con $C_s$ calore specifico a volume costante e $W$ portata ponderale a
temperatura $T_1$ che flusce nel serbatoio a $T_2$.

\section{Esempi dalle prove d'esame}
\subsection{Sistema di riscaldamento elettrico}
Si supponga che un sistema di riscaldamento elettrico sia
schematizzabile come in figura \ref{fig:esempio01}: la tensione $v$
alimenta il circuito di riscaldamento e la potenza dissipata sul
resistore $R_2$ \`e integralmente trasformata in flusso di calore
immesso nell'ambiente $A$, il quale, a sua volta, pu\`o scambiare
calore con l'ambiente esterno attraverso la parete $S$. Assunto che:
\begin{itemize}
  \item[a)] $T$ indichi la temperatura interna dell'ambiente $A$, $T_E$
  quella dell'ambiente esterno, $C_T$ sia la capacit\`a termica del
  flusso in $A$ ed $r$ la resistenza termica della parete $S$;
  \item[b)] il calore scambiato tra l'ambiente $A$ e l'ambiente
    esterno attraverso $S$ non modifichi sensibilmente $T_E$ (in altre
    termini, si consideri $T_E$ costante);
  \item[c)] il resistore $R_2$ abbia resistenza elettrica dipendente
    dalla temperatura secondo la legge: $R_2 = R_0 + \alpha \cdot T$;
  \item[d)] la relazione tra flusso di calore $q$ e potenza $p$ sia $q
    = b \cdot p$ con $b$ costante nota;
\end{itemize}

Si chiede di:
\begin{itemize}
\item fornire una rappresentazione i-s-u per il sistema assegnato;
\item determinare il valore della tensione di alimentazione $v$
  (supposto $> 0$) da assegnare affinch\`e la temperatura in $A$
  rimanga in equilibrio al valore $T = 10^{\circ}C$;
\item linearizzare il modello sopra determinato intorno al punto di
  equilibrio sopra calcolato;
\end{itemize}
$[R_0 = 1 k\Omega; R_1 = 9 k\Omega; \alpha = 2 kW/^{\circ}C; C = 1 mF; C_T = 1
  cal/^{\circ}C; r = 2 ^{\circ}C \cdot sec/cal; T_E= 4 ^{\circ}C; b = 1
  cal/J]$
\begin{figure}[!h]
  \centering
  \includegraphics[width=0.7\textwidth]{./images/esempio01.png}
  \label{fig:esempio01}
  \caption{Sistema di riscaldamento elettrico\label{fig:esempio01}}
\end{figure}

\subsubsection{Equazioni del circuito}
\[
v = v_1 + v_2 = R_1(i_C + i_2) + v_2 = R_1 \left(C \frac{dv_2}{dt} +
\frac{v_2}{R_2}\right) + v_2
\]
\[
  v = R_1C\dot{v_2} + \left( \frac{R_1}{R_2} + 1\right)v_2 \Rightarrow
  \dot{v_2} = - \left( \frac{1}{R_1C} + \frac{1}{R_2C}\right)v_2 + \frac{1}{R_1C}v
\]
Essendo $R_2 = R_0 + \alpha T$ si ha:
\[
  \dot{v_2} = - \left( \frac{1}{R_1C} + \frac{1}{C(R_0 + \alpha T)}\right)v_2 + \frac{1}{R_1C}v
\]

\subsubsection{Equazioni di scambio termico}
\[
  \begin{array}{ll}
    \dot{T} = \dfrac{1}{C_T} (q_{in} - q_{out}) &  \\
    q_{in} = b i_2 v_2 = b \dfrac{v_2^2}{R_2} = \dfrac{b v^2}{R_0 +
      \alpha T} & \textrm{Flusso di calore in ingresso}\\
    q_{out} = \dfrac{1}{r}(T - T_E) & \textrm{Flusso di calore in
      uscita}\\
     & \\
    \dot{T} = \dfrac{b}{C_T} \cdot \dfrac{v_2^2}{R_0 + \alpha T} -
    \dfrac{1}{C_T r}T + \dfrac{1}{C_T r}T_E & 
  \end{array}
\]
\\
Posto: $x = v_1$ ; $x_2 = T$ ; $u = v$ ; $y = T$ si ha:
\[
  \begin{array}{l}
    \dot{x_1} = - \left( \dfrac{1}{R_1C} + \dfrac{1}{C R_0 + \alpha C
      x_2}\right)x_1 + \dfrac{1}{R_1 C}u\\
    \dot{x_2} = \dfrac{b}{C_T} \dfrac{x_1^2}{R_0 + \alpha x_2} -
    \dfrac{1}{C_T r}x_2 + \dfrac{1}{C_T r}T_E\\
    y = x_2
  \end{array}
\]
Sostituendo ai parametri i valori numerici assegnati si ha:
\[
  (S)
  \left\{
  \begin{array}{l}
    \dot{x_1} = - \left( \dfrac{1}{9} + \dfrac{1}{1 + 2x_2}\right)x_1 + \dfrac{1}{9}u\\
    \dot{x_2} = \dfrac{x_1^2}{1 + 2x_2} - \dfrac{1}{2}x_2 + 2\\
    y = x_2
  \end{array}
  \right .
\]
\\
Affinch\`e la temperatura $T = x_2$ sia in equilibrio a $10 ^{\circ}C$
deve essere soddisfatto l'equilibrio:

\[
  \begin{array}{ll}
    (1) & 0 = - \left( \frac{1}{9} + \frac{1}{1 + 2x_2}\right)x_1 +
    \frac{1}{9}u\\
    (2) & 0 = \frac{x_1^2}{1 + 2x_2} - \frac{1}{2}x_2 + 2\\
  \end{array}
\]
Sostituendo $x_2 = 10 ^{\circ}C$ si ha dalla (2):
\[
  \dfrac{\overline{x_1}^2}{21} - 5 + 2 = 0 \Rightarrow \overline{x_1}^2
  = 63 \Rightarrow \overline{x_1} = 
  \left\{
  \begin{array}{l}
    -3 \sqrt{7}\\
    +3 \sqrt{7}
  \end{array} \right .
\]
Dalla (1) invece si ha: $$\overline{u} = \left(1 +
\frac{9}{21}\right)\overline{x_1}$$
Poich\`e deve essere $\overline{u} > 0$, si ha: $$ \overline{u} =
\frac{30}{21} \cdot (+3\sqrt{7}) = \frac{30}{\sqrt{7}}$$
Si procede quindi alla Linearizzazione del sistema (S) intorno al
punto di equilibrio sopra determinato $(\overline{x_1},
\overline{x_2}, \overline{x_3}) = \left(+3\sqrt{7}, +10, \frac{30}{\sqrt{7}}\right)$

\[
  \left\{
  \begin{array}{l}
    \delta \dot{x_1} = - \left( \frac{1}{9} + \frac{1}{1 +
      2\overline{x}_2}\right)\delta x_1 + \frac{1}{(1 +
      2\overline{x}_2)^2}\delta x_2 + \frac{1}{9} \delta u\\
    \delta \dot{x_2} = \frac{2 \overline{x}_1}{1 + 2 \overline{x}_2}
    \delta x_1 + \left( - \frac{2 \overline{x}_1^2}{(1 + 2
      \overline{x}_2)^2} - \frac{1}{2} \right) \delta x_2\\
    \delta y = \delta x_2
  \end{array}
  \right .
\]

\subsection{Serbatoio su carrello con molla e smorzatore}
\begin{figure}[!b]
  \centering
  \includegraphics[width=0.5\textwidth]{./images/esempio02.png}
  \caption{Serbatoio su carrello con molla e smorzatore\label{fig:esempio02}}
\end{figure}
Si fornisca una rappresentazione i-s-u per il sistema riportato in
figura \ref{fig:esempio02}. Esso \`e costituito da un serbatoio con area
di base $A$ posto su un carrello di massa trascurabile. Il
collegamento tra la parete ed il serbatoio avviene mediante una molla
lineare (di costante elastica $k_1$) ed un ammortizzatore lineare (di
costante $b_1$). Il serbatoio \`e sottoposto alla forza di trazione
$F$. Si supponga che:
\begin{itemize}
\item nel serbatoio sia immesso un fluido avente densit\`a $\rho$ con
  portata massica $\omega_{in}$. Lo stesso fluido fuoriesca in
  condizioni di moto turbolento dall'orifizio con resistenza idrica
  $R$;
\item la forza $F$ sia l'uscita del sistema rappresentato in
  figura \ref{fig:esempio02-2} mediante schema a blocchi;
\item l'effetto del moto traslatorio sia trascurabile sia sulla
  fuoriuscita del fluido che sulla sua distribuzione all'interno del
  serbatoio; 
\item nello schema di figura \ref{fig:esempio02-2}, $G_1$ e $G_2$ siano
  due costanti di guadagno;
\item l'uscita del sistema complessivo sia lo spostamento dell'insieme
  carrello+serbatoio.
\end{itemize}
\begin{figure}[!b]
  \centering
  \includegraphics[width=0.5\textwidth]{./images/esempio02-2.png}
  \caption{Serbatoio su carrello con molla e smorzatore\label{fig:esempio02-2}}
\end{figure}

\subsubsection{Soluzione}
\begin{itemize}
\item Equazioni del serbatoio
  \[
    \begin{array}{l}
      \dot{h} = \frac{1}{\rho A} \left( \omega_{in} -
      \frac{1}{R}\sqrt{\rho g h} \right)\\
      m = \rho A h
    \end{array}
    \]
  con $m$ pari alla massa del liquido
  nel serbatoio; la massa \`e uguale, per le ipotesi fatte, alla massa
  del sistema carrello+serbatoio.
\item Equazioni del moto del carrello
  \[
    \begin{array}{l}
      m \ddot{y} = F - k_1 y - b_1 \dot{y}\\
      m = \rho A h
    \end{array}
    \]
\item Equazioni del sistema generante la forza di trazione $F$
  \[
    \dot{F} = \sqrt[3]{G_1 h - y} -
    G_2 \dot{y}
  \]
\end{itemize}
Poniamo come variabili di stato $x_1 = h$; $x_2 = y$; $x_3 = \dot{y}$;
$x_4 = F$. Scegliamo come ingresso $u = \omega_{in}$. Scegliamo come
uscita $w = y$. Otteniamo la seguente rappresentazione I-S-U:
{\Large\[
  \left\{
  \begin{array}{l}
    \dot{x_1} = \frac{1}{\rho A} \left( -\frac{1}{R} \sqrt{\rho g x_1}
    + u\right)\\
    \dot{x_2} = x_3\\
    \dot{x_3} = - \frac{k_1}{\rho A} \cdot \frac{x_2}{x_1} -
    \frac{b_1}{\rho A} \cdot \frac{x_3}{x_1} + \frac{x_4}{\rho A
      x_1}\\
    \dot{x_4} = \sqrt[3]{G_1 x_1 - x_2} - G_2 x_3\\
    w = x_2
  \end{array}
  \right .
\]
}

\subsubsection{Esempio}
Dato il sistema avente rappresentazione di stato:
{\Large
  \[
    \left\{
      \begin{array}{l}
        \dot{x_1} = -3x_2 + x_1x_3\\
        \dot{x_2} = lnx_1 + 5u\\
        \dot{x_3} = -4x_3 + \frac{x_1}{x_2} - u
      \end{array}
    \right .
    \]
}
Si determinano i punti di equilibrio del sistema per $ u =
\overline{u}$:
{\large
  \[
    \left\{
      \begin{array}{l}
        -3\overline{x}_2 + \overline{x}_1\overline{x}_3 = 0\\
        ln\overline{x}_1 + 5\overline{u} = 0\\
        -4\overline{x}_3 + \frac{\overline{x}_1}{\overline{x}_2} - \overline{u}
      \end{array}
    \right .
    \Leftrightarrow
    \left\{
    \begin{array}{l}
      \overline{x}_1 = e^{-5\overline{u}}\\
      \overline{x}_2 = \frac{1}{3}\overline{x}_3 e^{-5\overline{u}}\\
      -4\overline{x}_3 + \frac{3}{\overline{x}_3} - \overline{u} = 0
    \end{array}
    \right .
    \begin{array}{l}
      \\
      \Leftrightarrow\\
      \textrm{assumendo}\\
       \overline{x}_3 = 0
    \end{array}
    \left\{
    \begin{array}{l}
      \overline{x}_1 = e^{-5\overline{u}}\\
      \overline{x}_2 = \frac{1}{3}\overline{x}_3 e^{-5\overline{u}}\\
      4\overline{x}_3^2 + \overline{x}_3 \overline{u} - 3 = 0
    \end{array}
    \right .
    \]
}
Si calcolano le radici di $\overline{x}_3$ e sostituendo $\overline{u}
= 1$ si hanno i due punti di equilibrio:
\[
  P_1 = \begin{pmatrix}
    e^{-5}\\
    -\frac{1}{3} e^{-5}\\
    -1
  \end{pmatrix}
  \;\;\;\;
  P_2 = \begin{pmatrix}
    e^{-5}\\
    \frac{1}{4} e^{-5}\\
    \frac{3}{4}
  \end{pmatrix}
\]
Si linearizza intorno al punto di equilibrio $P_2$ e per ingresso
$\overline{u} = 1$:
{\Large
\[
  \left\{
  \begin{array}{l}
    \delta \dot{x_1} = \overline{x}_3 \cdot \delta x_1 - 3 \delta x_2
    + \overline{x}_1 \delta x_3\\
    \delta \dot{x_2} = \frac{1}{\overline{x}_1}\delta x_1 + 5 \delta
    u\\
    \delta \dot{x_3} = \frac{1}{\overline{x}_2} \delta x_1 -
    \frac{\overline{x}_1}{\overline{x}_2^2} \delta x_2 - 4 \delta x_3
    - \delta u
  \end{array}
  \right .
\]
}
dove si \`e posto:
\[
  \left\{
  \begin{array}{l}
    \delta x_1 = x_1 - \overline{x}_1\\
    \delta x_2 = x_2 - \overline{x}_2\\
    \delta x_3 = x_3 - \overline{x}_3\\
    \delta u = u - \overline{u}
  \end{array}
  \right .
\]

\subsection{Circuito elettrico con componente non-lineare}
Si fornisca una rappresentazione i-s-u per il sistema riportato in
Fig. \ref{fig:esempio03}, nell'ipotesi che la tensione ai capi
$1 \rightarrow 2$ sia scelta dall'utente e quella ai capi $3
\rightarrow 4$ debba essere
valutata. Si supponga che il componente non-lineare $NL$ abbia la
rappresentazione ingresso-uscita rappresentata in Fig. \ref{fig:esempio03-2}.
\begin{figure}[!b]
  \centering
  \includegraphics[width=0.5\textwidth]{./images/esempio03.png}
  \caption{Circuito elettrico con componente non-lineare\label{fig:esempio03}}
\end{figure}
\begin{figure}[!t]
  \centering
  \includegraphics[width=0.5\textwidth]{./images/esempio03-2.png}
  \caption{Circuito elettrico con componente non-lineare\label{fig:esempio03-2}}
\end{figure}

\subsubsection{Soluzione}
\begin{figure}[!t]
  \centering
  \includegraphics[width=0.7\textwidth]{./images/esempio03-3.png}
  \caption{Circuito elettrico con componente non-lineare - Soluzione\label{fig:esempio03-3}}
\end{figure}
\[
  \begin{array}{l}
    v_c = v_2\\
    v_L = L \dfrac{di_l}{dt}\\
    i_2 = \dfrac{v_C}{R_2}\\
    i_1 = \dfrac{v_1}{R_1}\\
    i_1 = i_c + i_2 + i_L
  \end{array}
\]
Ecco le equazioni di Kirchhoff alla prima maglia:
\[
  u = v_1 + v_C = R_1i_1 + v_c = R_1 (i_c + i_2 + i_L) + v_C = R_1C
  \dfrac{dv_C}{dt} + \dfrac{R_1}{R_2}v_C + R_1i_L + v_C
\]
Le equazioni di Kirchhoff alla seconda maglia:
\[
v_c = v_L + y = L \dfrac{di_L}{dt} + y
\]
\begin{figure}[!t]
  \centering
  \includegraphics[width=0.7\textwidth]{./images/esempio03-4.png}
  \caption{Circuito elettrico con componente non-lineare - Soluzione\label{fig:esempio03-4}}
\end{figure}
Lo schema di figura \ref{fig:esempio03-4} ci fornisce la seguente
equazione:
\[
  \dfrac{dy}{dt} = e^{i_L} + \alpha \sqrt[3]{y - K \sqrt{i_L^3}} - 3y^2
\]
Ponendo $x_1 = v_c$ , $x_2 = i_L$ , $x_3 = y$ si perviene ad una
rappresentazione I-S-U.

\subsection{Circuito elettrico con componente non-lineare}
\begin{figure}[!t]
\centering
\includegraphics[width=0.8\textwidth]{./images/esempio04.png}
\caption{Circuito elettrico con componente non-lineare\label{fig:esempio04}}
\end{figure}
Dato il circuito in figura \ref{fig:esempio04} con $L = 10^{-4}H$, $C
= 10^{-3}F$, $R = 104\Omega$ . L'impedenza $Z$ \`e non lineare. La
corrente $i_z$ \`e in funzione della tensione $v_z = y$ secondo la
seguente legge: $$i_z = G (v_z^3 - 5v_z )$$ con $G = 10^{-4}$. \\
Determinare:
\begin{itemize}
\item una rappresentazione i-s-u del sistema.
\item gli stati di equilibrio per ingresso nullo $u = 0$
\item il tipo di stabilit\`a degli stati di equilibrio.
\end{itemize}

\subsubsection{Soluzione}
\[
  \begin{array}{l}
    x_1 = i_L\\
    x_2 = v_C = v_Z\\
    Y = x_2
  \end{array}
\]
\[
  \begin{array}{l}
    x_1 - C\dot{x}_2 - G(x_2^3 - 5 x_2) = 0\\
    u = R x_1 + L \dot{x}_1 + x_2
  \end{array}
  \Rightarrow
  \begin{array}{l}
    \dot{x}_1 = - \dfrac{R}{L}x_1 - \dfrac{1}{L}x_2 + \dfrac{1}{L}u\\
    \dot{x}_2 = \dfrac{1}{C}x_1 - \dfrac{G}{C}(x^3_2 - 5x_2)\\
    y = x_2
  \end{array}
\]
Tre stati di equilibrio:
\[
  \begin{array}{l}
    0 = - \dfrac{R}{L}x_1 - \dfrac{1}{L}x_2\\
    0 = \dfrac{1}{C}x_1 - \dfrac{G}{C}(x^3_2 - 5x_2)\\
    y = x_2
  \end{array}
  \Rightarrow
  \begin{array}{l}
    0 = Rx_1 - x_2\\
    0 = x_1 - G(x^3_2 - 5x_2)\\
    y = x_2
  \end{array}
  \Rightarrow
  \begin{array}{l}
    x_1 = - \dfrac{1}{R}x_2
    0 = - \dfrac{1}{R}x_2 - \dfrac{G}{C}(x^3_2 - 5x_2)\\
    y = x_2
  \end{array}
\]
\[
  \begin{array}{l}
    x_1 = - 10^{-4} x_2
    0 = x_2 - (x^3_2 - 5x_2) = x^3_2 - 4x_2\\
    y = x_2
  \end{array}
  \Rightarrow
  \begin{array}{l}
    \overline{x_1} = 
        \begin{bmatrix}
          -2 \cdot 10^{-4}\\ 2
        \end{bmatrix}\\
    \overline{x_2} =
        \begin{bmatrix}
          2 \cdot 10^{-4}\\ -2
        \end{bmatrix}\\
    \overline{x_3} =
    \begin{bmatrix}
      0\\
      0
    \end{bmatrix}
  \end{array}
  \begin{array}{l}
  \overline{y}_1 = 2\\
  \overline{y}_2 = -2\\
  \overline{y}_3 = 0
  \end{array}
\]
\[
  \delta\dot{x} =
  \left .
  \begin{bmatrix}
    - \dfrac{R}{L} & - \dfrac{1}{L}\\ \dfrac{1}{C} & -
    \dfrac{G}{C}\left(3 x_2^2 - 5\right)
  \end{bmatrix}
  \right |_{x = \overline{x}} \delta x + \begin{bmatrix} \dfrac{1}{L}
    \\ 0 \end{bmatrix} \delta u
\]

\[
  \begin{bmatrix}
    \lambda + \dfrac{R}{L} & \dfrac{1}{L}\\
    - \dfrac{1}{C} & \lambda + \dfrac{G}{C}\left(3 x_2^2 - 5\right)
  \end{bmatrix}
\]
Si calcola il determinante della matrice e i relativi autovalori per i
diversi valori di $x_2$. Per $x_2 = 0$ si hanno un polo positivo ed
uno negativo: ``il punto di equilibrio \`e instabile''. Sostituendo,
invece, $x_2 \pm 2$ si hanno due poli negativi che ci portano ad un
``sistema asintoticamente stabile''.

\subsection{Forza elettromotrice - Coppia - Pendolo}
Linearizzare il sistema intorno al punto di equilibrio trovato per $u
= V = 10$ con i seguenti valori dei parametri: $R=10\Omega$, $L=0.2H$,
$k=9.8\dfrac{N \cdot m}{A}$, $b~=~0.1\dfrac{N \cdot m \cdot s}{rad}$,
$m=1kg$, $l=1m$, $g = 9.8\dfrac{m}{s^2}$ .
Si commenti in poche righe il significato fisico del punto di
equilibrio trovato. (Si ricordi che la costante di coppia, $k$ , lega
la forza contro-elettromotrice $e$ alla velocit\`a angolare del motore
e la coppia motrice $C_m$ alla corrente di alimentazione).

\subsubsection{Soluzione qualitativa}
\[
  \begin{array}{l}
    L \dfrac{di}{dl} = v - Ri - k \dot{\theta}\\
    ki - b \dot{\theta} - mgl~sin{\theta} = m l^2 \theta
  \end{array}
\]
\[
  \left\{
  \begin{array}{l}
    x_1 = i\\
    x_2 = \theta\\
    x_3 = \dot{\theta}
  \end{array}
  \right .
\]
La rappresentazione in forma di stato \`e: 
\[
  \left\{
  \begin{array}{l}
    L \dot{x}_1 = v - Rx_1 - kx_3\\
    m l^2 x_3 = kx_1 - bx_3 - mgl~sinx_2\\
    \dot{x}_2 = x_3\\
    y = x_2\\
    (u = v)
  \end{array}
  \right .
\]
Punto di equilibrio:
\[
  \left\{
  \begin{array}{l}
    \overline{x}_1 = \dfrac{\overline{u}}{R}\\
    sin(\overline{x}_2) = \dfrac{k \overline{u}}{mglR}\\
    \overline{x}_3 = 0
  \end{array}
  \right .
  \Rightarrow
  \overline{x}_e = 
        \begin{pmatrix}
        1\\
        \dfrac{\pi}{2}\\
        0
        \end{pmatrix}
\]
\[
  A_{linearizzato} = 
  \begin{pmatrix}
    -\dfrac{R}{L} & 0 & \dfrac{k}{L}\\
    0 & 0 & 1\\
  \dfrac{k}{ml^2} & -\dfrac{g}{l}~cos\overline{x}_2 & -\dfrac{b}{ml^2}
  \end{pmatrix}
\]
\[
  B_{linearizzato} =
  \begin{pmatrix}
    \dfrac{1}{L}\\
    0\\
    0
  \end{pmatrix}
  C_{linearizzato} =
  \begin{pmatrix}
    0 & 1 & 0
  \end{pmatrix}
\]

\subsection{Scambio termico}
Si consideri un ambiente suddiviso in 4 aree (stanze), come riportato
in Fig. \ref{fig:esempio06}, ciascuna a temperatura $T_i$ e con
capacit\`a termica $C_i$, $i=1,2,3,4$. Sia, invece, $T_0$ la
temperatura ed infinita la capacit\`a termica all'esterno. Lo scambio
termico tra i vari ambienti e l'esterno avvenga lungo le pareti
tratteggiate secondo le resistenze termiche $R_i$, $i=0,1,2,3,4$. Si
supponga che all'interno del primo ambiente sia posizionata una stufa
$S$ che eroga un flusso di calore $q$. Assumendo di schematizzare la
stufa come il circuito in Fig. \ref{fig:esempio06-2}, sia $q$
proporzionale alla potenza dissipata sulla resistenza $R_e$.
Nell'ipotesi che $T_4$ sia l'uscita e $V$ l'ingresso, si richiede una
rappresentazione i-s-u per il sistema complessivo in
Fig. \ref{fig:esempio06} e \ref{fig:esempio06-2}.
\begin{figure}[!t]
  \centering
  \includegraphics[width=0.6\textwidth]{./images/esempio06.png}
  \caption{Scambio termico\label{fig:esempio06}}
\end{figure}
\begin{figure}[!t]
  \centering
  \includegraphics[width=0.6\textwidth]{./images/esempio06-2.png}
  \caption{Scambio termico\label{fig:esempio06-2}}
\end{figure}
\subsubsection{Soluzione}
\begin{figure}[!t]
  \centering
  \includegraphics[width=0.6\textwidth]{./images/esempio06-3.png}
  \caption{Scambio termico - Soluzione\label{fig:esempio06-3}}
\end{figure}
Parte elettrica:
\[
  \begin{array}{l}
    v = v_{R_S} + v_C = R_s i_{R_s} + v_c\\
    i_{R_s} = i_c + i_e = C \dfrac{dv_c}{dt} + \dfrac{v_e}{R_e}\\
    v_c = v_e\\
    v = R_s \left( C \dfrac{dv_c}{dt} + \dfrac{v_c}{R_e}\right) + v_c
  \end{array}
\]
Parte termica:
\[
  q = b \cdot \dfrac{v_e^2}{R_e^2}
\]
con $b>0$: costante di proporzionalit\`a.

\[
  \begin{array}{l}
    \dot{T}_1 = \dfrac{1}{C_1} \left[ q + \dfrac{1}{R_4}(T_4 - T_1) +
      \dfrac{1}{R_1}(T_2 - T_1)  \right]\\
    \dot{T}_2 = \dfrac{1}{C_2} \left[ \dfrac{1}{R_1}(T_1 - T_2) +
      \dfrac{1}{R_2}(T_3 - T_2) + \dfrac{1}{R_0}(T_0 - T_2) \right]\\
    \dot{T}_3 = \dfrac{1}{C_3} \left[ \dfrac{1}{R_3}(T_4 - T_3) +
      \dfrac{1}{R_2}(T_3 - T_2)  \right]\\
    \dot{T}_4 = \dfrac{1}{C_4} \left[ \dfrac{1}{R_3}(T_4 - T_3) +
      \dfrac{1}{R_4}(T_4 - T_1)  \right]\\
  \end{array}\\
\]
Posto:
$x_1 = T_1$, $x_2 = T_2$, $x_3 = T_3$, $x_4 = T_4$, $x_5 = v_c$, $u =
v$, $y = T_4$ si ottiene la rappresentazione I-S-U del sistema
considerato:
\[
  \left\{
  \begin{array}{l}
    \dot{x}_1 = \dfrac{1}{C_1} \left[ b \cdot \dfrac{x_5^2}{R_e^2} +
      \dfrac{1}{R_4}(x_4 - x_1) + \dfrac{1}{R_1}(x_2 - x_1) \right]\\
    \dot{x}_2 = \dfrac{1}{C_2} \left[ \dfrac{1}{R_1}(x_1 - x_2) +
      \dfrac{1}{R_2}(x_3 -x_2) + \dfrac{1}{R_0} (T_0 - x_2)  \right]\\
    \dot{x}_3 = \dfrac{1}{C_3} \left[ \dfrac{1}{R_3}(x_4 - x_3) -
      \dfrac{1}{R_2}(x_3 - x_2) \right]\\
    \dot{x}_4 = \dfrac{1}{C_4} \left[ \dfrac{1}{R_3}(x_4 - x_3) +
      \dfrac{1}{R_4}(x_4 - x_1) \right]\\
    \dot{x}_5 = \dfrac{u}{R_s C} - \dfrac{R_s + R_e}{R_s R_e C}x_5\\
    y = x_4
  \end{array}
  \right .
\]
La capacit\`a termica all'esterno si pu\`o supporre infinita,
quindi $T_0$ pu\`o considerarsi costante.

\subsection{Amplificatore}
Determinare il modello in forma di stato del sistema complessivo
formato dalla serie del Sistema $1$ e del Sistema $2$ rappresentati in
figura ($V_{out}=V_{1_{in}}$).
\begin{figure}[!t]
\centering
\includegraphics[width=0.8\textwidth]{./images/esempio07.png}
\caption{Amplificatore\label{fig:esempio07}}
\end{figure}
\[
  \begin{array}{ll}
    \textrm{Sistema 1} & \dot{V}_{out} = - \dfrac{1}{RC} V_{in}\\
    \textrm{Sistema 2} & \left\{
            \begin{array}{l}
              R_1C_1\dot{V}_c = V_{1_{in}} - R_1 i_{L_{1}} - V_c\\
              L \dfrac{d i_{L_{i}}}{dt} = V_c
            \end{array} \right .
  \end{array}
\]
Poste $x_1 = V_{1_{in}}$, $x_2 = V_c$, $x_3 = i_{L_{1}}$, $V_{in} =
u$, $V_c = y$
\[
  \left\{
  \begin{array}{l}
    \dot{x}_1 = - \dfrac{u}{RC}\\
    \dot{x}_2 = \dfrac{x_1}{R_1 C_1} - \dfrac{1}{C_1}x_3 -
    \dfrac{x_2}{R_1 C_1}\\
    \dot{x}_3 = \dfrac{x_2}{L_1}\\
    y = x_2
  \end{array}
  \right .
\]

\subsection{Amplificatore}
\begin{figure}[!b]
  \centering
  \includegraphics[width=0.9\textwidth]{./images/esempio08.png}
  \caption{Amplificatore\label{fig:esempio08}}
\end{figure}
Si fornisca una rappresentazione i-s-u del sistema riportato in figura
\ref{fig:esempio08}. Si supponga che la temperatura esterna $T_e$ non
sia influenzabile dal sistema ($T_e$ \`e costante) e la resistenza $R$
non vari con la temperatura; si linearizzi in un intorno del punto di
equilibrio che soddisfa la condizione $x_2>0$, con ingresso costante $VR=10$;
Parametri elettrici: $R_1=250$ ; $R_2=1k\Omega$; $R_3=250k\Omega$;
$C=1 \mu F$; $R=1$ ; Parametri termici: $R_T=350 k/W$; $C_T=1 J/k$.

\subsubsection{Soluzione}
\begin{figure}[!b]
  \centering
  \includegraphics[width=0.9\textwidth]{./images/esempio08-2.png}
  \caption{Amplificatore\label{fig:esempio08-2}}
\end{figure}
Equazioni del circuito elettrico:
\[
  \begin{array}{l}
    \textrm{in A: } i_{R_{i}} = i_{R_{2}} + i_{R_{3}}\\
    V_{in} = i_{R_{1}} + i_{R_{2}}R_2 = (i_{R_{2}} + i_{R_{3}})R_1 +
    i_{R_{2}}R_2\\
    R_2 i_{R_{2}} = V_{R_{3}} + V_C \Rightarrow i_{R_{2}} =
    \dfrac{V_{R_{3}} + V_C}{R_2}\\
    i_{R_{3}} = i_C = C \dot{V}_C; V_{R_{3}} = i_{R_{3}}R_3 = i_C R_3
    = R_3 C \dot{V}_C
  \end{array}
\]
Possiamo scrivere:
\[
  \begin{array}{l}
    V_{in} = \dfrac{R_3 C \dot{V}_C + V_C}{R_2} (R_1 + R_2) + C R_1
    \dot{V}_C\\
    \dot{V}_C \left( \dfrac{R_3 C}{R_2} (R_1 + R_2) + R_1 C  \right) =
    V_{in} - V_C \dfrac{R_1 + R_2}{R_2}\\
    \dot{V}_C \left( \dfrac{R_3 (R_1 + R_2) + R_1R_2}{R_2} \right)C =
    - \dfrac{R_1 + R_2}{R_1}V_C + V_{in}\\
    \dot{V}_C = - \dfrac{R_2}{R_1 R_2 + R_3(R_1 + R_2)} \cdot
    \dfrac{R_1 + R_2}{C}V_C + \dfrac{R_2}{CR_1 R_2 + CR_3(R_1 + R_2)}V_{in}
  \end{array}
\]
La potenza dissipata sulla resistenza R \`e:
\[
  P = \dfrac{V_0^2}{R} = \dfrac{V_C^2}{R}
\]
Equazioni di scambio termico:
\[
  \dot{T}_i = \dfrac{1}{C_T} (q_{in} - q_{out}) \textrm{ dove }
  \left\{
  \begin{array}{l} 
    q_{in} = P = \dfrac{V_c^2}{R}\\
    q_{out} =  \dfrac{1}{R_T} (T_i - T_E)
  \end{array}
  \right .
\]
\[
  \dot{T}_i = \dfrac{1}{C_T} \dfrac{V_c^2}{R} - \dfrac{1}{R_T C_T}(T_i
  - T_E)
\]
Posto $x_1 = V_C$, $x_2 = T_i$, $u_i = V_{in}$, $u_2 = T_E$, $y =
T_i - T_e$ si ha:
\[
  \left\{
  \begin{array}{l}
    \dot{x}_1 = - \dfrac{R_2}{R_1R_2 + R_3(R_1 + R_2)} \cdot
    \dfrac{R_1 + R_2}{R_2}x_1 + \dfrac{R_2}{R_1 R_2 + R_3(R_1 +
      R_2)}u_1\\
    \dot{x}_2 = - \dfrac{1}{R_TC_T}x_2 + \dfrac{x_1^2}{R C_T} +
    \dfrac{1}{R_T C_T}u_2\\
    y = x_2 - u_2
  \end{array}
  \right .
\]
Sostituendo i valori numerici e ponendo le derivate a ``zero''
abbiamo:
\[
  \left\{
  \begin{array}{l}
    \overline{x}_1 = \dfrac{1}{5} \overline{u}_1 = 2\\
    \overline{x}_2 = 1400 - T_E
  \end{array}
  \right .
\]
La linearizzazione prevede il calcolo della matrice Jacobiana e si
conclude con:
\[
  \left\{
  \begin{array}{l}
    \delta \dot{x}_1 = - \dfrac{5}{312750} \delta x_1 +
    \dfrac{1}{312750} u_1\\
    \delta x_2 = 2 \overline{x}_1 \delta x_1 - \dfrac{1}{350} \delta x_2 +
    \dfrac{1}{350} u_2\\
    Y = x_2 - u_2
  \end{array}
  \right .
\]
\[
  \left\{
  \begin{array}{l}
    \delta \dot{x}_1 = - \dfrac{5}{312750} \delta x_1 +
    \dfrac{1}{312750} u_1\\
    \delta x_2 = 4 \delta x_1 - \dfrac{1}{350} \delta x_2 +
    \dfrac{1}{350} u_2\\
    Y = x_2 - u_2
  \end{array}
  \right .
\]


\chapter{Analisi in frequenza}
L'analisi in frequenza \`e lo studio del comportamento di un
sistema che viene sollecitato con un ingresso sinusoidale.

\section{Sviluppo in serie di Fourier}\label{apx:sdf}
Lo sviluppo in serie di Fourier (S.d.F.) \`e utilizzato per la
rappresentazione di funzioni periodiche come somma di un termine
costante e infiniti termini sinusoidali e cosinusoidali, aventi
pulsazioni multiple di quella fondamentale.

Si ricorda che una funzione periodica, di periodo $T$, \`e definita
come: 
\begin{eqnarray*}
  \begin{array}{l}
    f(t+T)=f(t)\qquad,\qquad \forall t\\
    \textrm{oppure}\\
    f(t+mT)=f(t)\qquad,\qquad \forall t,m \textrm{ con } m \textrm{
      intero} 
  \end{array}
\end{eqnarray*}
dove T \`e il periodo misurato in [s]. In particolare:
\begin{eqnarray*}
\textrm{PULSAZIONE: } \omega \triangleq \frac{2\pi}{T} \Longrightarrow
\omega = 2\pi f [rad/s]\\
\textrm{FREQUENZA: } f\triangleq \frac{1}{T} = \frac{\omega}{2\pi}
       [Hz] = [1/s]
\end{eqnarray*}

\subsection{Forma trigonometrica}
La Serie di Fourier della funzione periodica $f(t)$ \`e:
\begin{equation}\label{eq:serieDiFourier}
  f(t) = \dfrac{a_o}{2} + \sum_{n = 1}^{\infty} [ a_n cos(n \omega t)
    + b_n sin(n \omega t)]
\end{equation}
Per calcolare il coefficiente $a_0$:
\begin{equation}
  a_0 = \frac{2}{T}\int_0^T f(t) dt
\end{equation}
Esso \`e il valor medio del segnale su di un periodo $(<f(t)>)$. $a_0$
viene anche detta {\em componente a pulsazione nulla}\index{Componente
a pulsazione nulla}.
I coefficienti $a_n$ e $b_n$ sono calcolati come:
\[
  a_n = \dfrac{2}{T} \int_0^T f(t) cos(n \omega t) dt
\]
\[
  b_n = \dfrac{2}{T} \int_0^T f(t) sin(n \omega t) dt
\]

Le componenti cosinusoidali sono dette {\em armoniche}\index{Armonica}, di
pulsazione multipla di $\omega$. L'{\em armonica fondamentale} \`e
proprio quella di pulsazione $\omega$, mentre le armoniche di generica
pulsazione $n\omega$ sono dette {\em armoniche n-esime}.

La banda \`e l'intervallo di pulsazione compreso tra la minima $n_1
\omega$ e la massima $n_2 \omega$. Se $n_2 < \infty$ il segnale \`e a
      {\em banda limitata}\index{Banda limitata} con larghezza di
      banda $(n_2 - n_1)\omega$, altrimenti \`e a banda illimitata.
      
Per il calcolo dei coefficienti $a_n$ e $b_n$, tornano spesso utili le
seguenti identit\`a trigonometriche:
\begin{eqnarray*}
  \cos A \sin B = \dfrac{1}{2}\sin (A+B)-\dfrac{1}{2}\sin(A-B)\\
  \cos A \cos B = \dfrac{1}{2}\cos(A+B)+\dfrac{1}{2}\cos(A-B)\\
  \sin A \sin B = - \dfrac{1}{2} \cos (A + B) - \dfrac{1}{2} \cos(A - B)\\
  \sin A \cos B = \dfrac{1}{2} \sin (A + B) + \dfrac{1}{2} \sin (A - B)
\end{eqnarray*}

\subsection{Propriet\`a della serie di Fourier}
\begin{itemize}
\item Linearit\`a
  \subitem 
  \begin{displaymath}
    F[\alpha f + \beta g] = \alpha F_n + \beta G_n
  \end{displaymath}
\item Funzione Pari o Dispari
  \subitem 
  \begin{eqnarray*}
    f(t) = f(-t) \Longrightarrow \textrm{FUNZIONE PARI}\\
    -f(t) = f(-t)\Longrightarrow \textrm{FUNZIONE DISPARI}
\end{eqnarray*}
  Ricordiamo che una funzione {\em pari} \`e simmetrica rispetto
  all'asse delle ordinate; una funzione dispari \`e simmetrica
  rispetto all'origine degli assi.
\subitem 
\begin{eqnarray*}
  \textrm{if ($f(t)=$PARI)$\Longrightarrow b_n=0$ e si calcolano $a_n$ e $a_0$}\\
  \textrm{if ($f(t)=$DISPARI)$\Longrightarrow a_n=0$ e $a_0=0$ e si calcola $b_n$}
\end{eqnarray*}
\end{itemize}

\subsection{Trasformata di Fourier}
Data $f(t)$, funzione complessa della variabile reale tempo $t$, la
Trasformata di Fourier \`e definita come:
\begin{equation}\label{eq:tdf}
  F(j\omega) = \int_{-\infty}^{+\infty}f(t) e^{-j\omega t} dt
\end{equation}
Essa \`e chiamata anche \emph{spettro}\index{Spettro} di $f(t)$. In particolare
\begin{eqnarray*}
  |F(j\omega)| \triangleq \textrm{spettro di ampiezza}\index{Spettro
    di ampiezza}\\
  \arg F(j\omega)\triangleq \textrm{spettro di fase}\index{Spettro di fase}
\end{eqnarray*}
L'antitrasformata di Fourier (indicata con $F(j\omega)^{-1}$) \`e:
\begin{equation}\label{eq:antitrasfF}
  f(t) = \frac{1}{2\pi} \int_{-\infty}^{+\infty} F(j\omega)e^{j\omega t} d\omega
\end{equation}

\subsubsection{Relazione con la trasformata di Laplace}
La trasformata di Laplace e la trasformata di Fourier possono essere
messe in relazione se le funzioni $f(t)$ in esame sono nulle per $t <
0$ e se l'ascissa di convergenza \`e $\bar{\sigma} < 0$. In questo
caso abbiamo:

\begin{equation}
  F[f(t)] = \left . L[f(t)] \right |_{s = j\omega}
\end{equation}

\section{Risposta in frequenza}
Il movimento di un sistema lineare e stazionario sollecitato da un
ingresso di tipo sinusoidale \`e detto \emph{risposta alla sinusoide o
 risposta in frequenza}\index{Risposta alla sinusoide}\index{Risposta
  in frequenza}. Si considera il
sistema SISO caratterizzato dalle equazioni seguenti:
\begin{equation*}
  \dot{x}(t) = Ax(t) + Bu(t)
\end{equation*}
\begin{equation*}
  y(t) = Cx(t) + Du(t)
\end{equation*}
e dalla funzione di trasferimento associata:
\begin{displaymath}
  G(s) = C(sI-A)^{-1}B + D
\end{displaymath}
Si vuole determinare la risposta del sistema asintoticamente stabile
ad un ingresso  
\begin{equation}\label{eq:sininput}
  u(t) = U \sin (\omega t)\qquad, \qquad t\geq 0
\end{equation}
La trasformata di Laplace di $u(t)$ \`e (v. appendice
~\ref{apx:laplace}): 
\begin{equation}\label{eq:rispsfreq}
  U(s) = \dfrac{U\omega}{s^2 + \omega^2}
\end{equation}
\begin{equation}\label{eq:squadropiuomegaquadro}
  s^2 + \omega^2 = (s + j \omega)(s - j \omega) = s^2 +
  \xout{sj\omega} - \xout{sj\omega} - j^2 \omega^2
\end{equation}
dove $-j^2 = 1$.
L'uscita $y(t)$, calcolata antitrasformando
\begin{displaymath}
  Y(s) = G(s)\dfrac{U\omega}{s^2 + \omega^2}
\end{displaymath}
\`e pari a~\footnote{Si scompone la \ref{eq:rispsfreq} in fratti
  semplici (ad esempio mediante lo sviluppo di Heaviside).}
\begin{equation}\label{eq:risptfreq}
  y(t)=\mathfrak{L}^{-1}\left [ \sum_{i=1}^n
    \underbrace{\frac{P_i}{s+p_i}}_{Y_1(s)} +
    \underbrace{\frac{Q}{s-j\omega} + \frac{\bar
        Q}{s+j\omega}}_{Y_2(s)} \right ] = y_1(t) + y_2(t)
\end{equation}
dove $P_i$ e $Q$ sono costanti e $\bar{Q}$ \`e il complesso coniugato
di $Q$. Valutiamo $Q$ e $Y(s)$ e applichiamo lo sviluppo di
Heaviside:
\[
  G(s) U \dfrac{\omega}{s^2 + \omega^2} = \dfrac{P_i}{s + p_i} +
  \dfrac{Q}{s - j\omega} + \dfrac{\bar{Q}}{s + j \omega}
\]
Ricordiamo la \ref{eq:squadropiuomegaquadro} e moltiplichiamo entrambi
i membri per $(s - j\omega)$: 
\[
  G(s) U \dfrac{\omega}{(s + j \omega)(s - j \omega)} (s - j \omega)=
  \dfrac{P_i (s - j \omega)}{(s + p_i)} + 
  \dfrac{Q\xout{(s - j \omega)}}{\xout{(s - j\omega)}} +
  \dfrac{\bar{Q}(s - j \omega)}{(s + j \omega)} 
\]
Facendo tendere $s \rightarrow j \omega$ otteniamo:
\[
  G(j\omega) U \dfrac{\omega}{(j\omega + j \omega)\xout{(s - j \omega)}} \xout{(s
    - j \omega)} =
  \dfrac{\xout{P_i (s - j \omega)}}{\xout{(s + p_i)}} + 
  Q + \dfrac{\xout{\bar{Q}(s - j \omega)}}{\xout{(s + j \omega)}}
\]

\begin{displaymath}
  Q = G(j\omega)\dfrac{U}{2j}\qquad,\qquad
\bar{Q} = -\bar{G}(j\omega)\dfrac{U}{2j}
\end{displaymath}
Da notare che per $t \to \infty, ~y_1(t)$ tende asintoticamente a zero
e quindi $y(t)$ tende asintoticamente a $y_2(t)$
\begin{displaymath}
  y_2(t)=\mathfrak{L}^{-1}\{Y_2(s)\} = \mathfrak{L}^{-1} \left[ \dfrac{Q}{s
      - j\omega} + \dfrac{\bar{Q}}{s + j\omega} \right] = Q e^{j\omega
    t}+\bar Q e^{-j\omega t}=
\end{displaymath}
\begin{displaymath}
  = G(j\omega)\dfrac{U}{2j} e^{j\omega t} - \bar
  G(j\omega)\dfrac{U}{2j} e^{-j\omega t} =
\end{displaymath}
Ricordando la formula di Eulero\label{formulaDiEulero}\index{Formula
  di Eulero}:
\[
  e^{j \omega t} = cos(\omega t) + j sin{\omega t}
\]
\[
  e^{-j \omega t} = cos(\omega t) - j sin{\omega t}
\]
possiamo riscrivere come:
\[
  \dfrac{U}{2j} \left\{G(j \omega) cos(\omega t) + j G(j \omega)
  sin(\omega t) - [\bar{G}(j \omega) cos(\omega t) - j\bar{G}(j
    \omega)sin(\omega t)] \right\}
\]
\begin{displaymath}
  =\dfrac{U}{2j}\left[\left(G(j\omega)-\bar G(j\omega)\right)\cos (\omega
    t) + j\left(G(j\omega)+\bar G(j\omega)\right)\sin (\omega t)\right]=
\end{displaymath}
A questo punto, possiamo effettuare alcune considerazioni:
\[
  G(j \omega) - \bar{G}(j \omega) = \Re e\{G(j \omega)\} + j \Im m\{G(j \omega)\} -
  \Re e\{G(j \omega)\} + j \Im m\{G(j \omega)\}
\]
\[
  G(j \omega) + \bar{G}(j \omega) = \Re e\{G(j \omega)\} + j \Im m\{G(j \omega)\} +
  \Re e\{G(j \omega)\} - j \Im m\{G(j \omega)\}
\]
Sostituendo e semplificando, otteniamo:
\begin{displaymath}
  =\dfrac{U}{2j}[2j~\Im m\{ G(j\omega)\}\cos (\omega t) + 2j~\Re e
    \{G(j\omega)\}\sin(\omega t)]
\end{displaymath}

\begin{equation*}
  \begin{array}{l}
    \Im m[G(j\omega))] = |G(j\omega)| sin(arg(G(j\omega)))\\
    \Re e[G(j\omega))] = |G(j\omega)| cos(arg(G(j\omega)))
  \end{array}
\end{equation*}

\begin{displaymath}
  =U\left [  |G(j\omega)|\sin(\arg G(j\omega))\cos(\omega t) +
    |G(j\omega)|\cos(\arg(G(j\omega))\sin(\omega t)\right ] 
\end{displaymath}
Se consideriamo:
\[
  \arg G(j\omega) = a
\]
e
\[
  \omega t = b
\]
possiamo sfruttare:
\[
  sin(a)cos(b) = \dfrac{sin(a + b) + sin(a - b)}{2}
\]
\[
  cos(a)sin(b) = \dfrac{sin(a + b) - sin(a - b)}{2}
\]
Sostituendo e semplificando, otteniamo:
\begin{equation}\label{eq:rispfreqfdt}
  =|G(j\omega)| U \sin (\omega t+\arg G(j\omega))
\end{equation}
In definitiva, l'uscita $y(t)$ converge verso una sinusoide avente la
stessa pulsazione di quella in ingresso e ampiezza pari a
$|G(j\omega)|U$ e fase $\arg G(j\omega)$.\footnote{/!$\backslash$
  Quando manca l'ipotesi di asintotica stabilit\`a, non \`e detto che
  se si applica un ingresso sinusoidale il sistema risponda con una
  sinusoide, per cui \`e necessario agire scegliendo valori opportuni
  dello stato iniziale, in modo tale da ottenere la risposta sinusoidale attesa.}
Si enuncia pertanto il \emph{teorema fondamentale della risposta in
  frequenza}\index{Teorema fondamentale della risposta in
  frequenza}. La funzione di trasferimento in frequenza,
  assume la forma $G(j\omega)=C(j\omega I - A)^{-1}B+D$.
\newtheorem{rispinfreq}{Theorem}[chapter]
\begin{rispinfreq}
  Se si applica ad un sistema LTI asintoticamente stabile con funzione
  di trasferimento $G(s)$ l'ingresso sinusoidale
\begin{displaymath}
  u(t) = U \sin (\omega_0 t)
\end{displaymath}
l'uscita a regime, quindi a transitorio esaurito, assume la
forma
\begin{equation}\label{eq:genrispfreq} 
  \tilde{y}(t) = |G(j\omega_0)| U \sin(\omega_0 t +\arg G(j\omega_0))
\end{equation}
indipendentemente dallo stato iniziale.
\end{rispinfreq}



% DIAGRAMMA I BODE
\section{Diagrammi di Bode}
Per rappresentare la risposta in frequenza $G(j\omega)$ di sistemi
SISO, si usano i \emph{diagrammi di Bode (o diagrammi cartesiani)}. Si
parla di risposta in frequenza quando la funzione di trasferimento di
un sistema lineare tempo invariante viene sollecitata da un ingresso
di tipo sinusoidale con pulsazione $\omega$ al variare di questa. I
diagrammi di Bode sono costituiti da una coppia di curve che
rappresentano il modulo e la fase di $G(j\omega)$ in funzione della
pulsazione  $\omega$, ascissa comune ad entrambi i diagrammi.  Le due
curve sono dette  
\emph {diagramma di Bode del modulo} e \emph{diagramma di Bode della
  fase}.

\subsubsection{Scala logaritmica}
Convenzionalmente si usa una scala logaritmica in base dieci
per l'ascissa (viene rappresentato $\log_{10}\omega_n$ con $\omega_n
\neq 0$) in modo tale che la distanza tra due pulsazioni  $\omega_1$ e
$\omega_2 > \omega_1$ sia proporzionale alla differenza dei loro
logaritmi, ovvero al rapporto $\dfrac{\omega_2}{\omega_1}$ per ogni
coppia di pulsazioni.

Si definisce \emph{decade}\index{Decade}  l'intervallo tra due
pulsazioni che sono tra loro in rapporto pari a dieci.

I vantaggi nell'uso di diagrammi logaritmici sono sostanzialmente la
possibilit\`a di rappresentare col dovuto dettaglio grandezze che
variano in campi notevolmente estesi e la possibilit\`a di semplificare
i calcoli di moltiplicazione che nel caso di logaritmi si riconducono
semplicemente a somme.

\subsubsection{Bode-form o forma canonica}
Nel tracciare i diagrammi, \`e conveniente trasformare la
funzione di trasferimento nella cosiddetta
\emph{Bode-form}~\footnote{Viene trasformata la forma fattorizzata
  rappresentata dall'eq. \ref{eq:secformfdt}, ponendo $s=j\omega$}:

\begin{equation}\label{eq:bodeform}
  G(j\omega) = \dfrac{\mu \prod_i \left( 1 + j\omega \tau_i \right)
    \prod_i \left( 1 +\dfrac{2 j\omega \zeta_i}{\alpha_{ni}} -
    \dfrac{\omega^2}{\alpha^{2}_{ni}}\right)} {(j\omega)^g \prod_i( 1 +
    j\omega T_i ) \prod_i\left( 1 + \dfrac{2 j\omega \xi_i }{\omega_{ni}} -
    \dfrac{\omega^2}{\omega^{2}_{ni}}\right)}
\end{equation}

\section{Diagrammi dei moduli}
Nel diagramma del modulo, l'asse delle ordinate riporta in scala
lineare il $|G(j\omega)|_{dB}$ espresso in decibel (dB)~\footnote{Il
  valore in decibel di $x$ \`e pari a $20\log x$.}:
\begin{equation}\label{eq:modfdtindb}
  |G(j\omega)|_{dB} = 20\log|G(j\omega)|~\footnote{Valori positivi,
    negativi o nulli di $|G(j\omega)|_{dB}$, corrispondono a  valori
    maggiori, minori o pari a 1 di $|G(j\omega|$.} 
\end{equation}
mentre l'asse delle ascisse rappresenta la pulsazione $\omega$.
Effettuando quindi il modulo della risposta in frequenza in $dB$ si ha:
\begin{equation}\label{eq:modrispfreq}
  \begin{array}{l}
  |G(j\omega)|_{dB} = 20\log|\mu| - 20g\log|j\omega| + \sum_i
  20\log|1+j\omega \tau_i|+ \\
  +\sum_i 20\log \left|1 + 2j\zeta_i
  \dfrac{\omega}{\alpha_{ni}} - \dfrac{\omega^2}{\alpha^2_{ni}}\right|
  + \\
  - \sum_i 20\log |1+j\omega T_i| - \sum_i 20\log \left|1 + 2j\xi_i
  \dfrac{\omega}{\omega_{ni}} - \dfrac{\omega^2}{\omega^2_{ni}}\right| 
  \end{array}
\end{equation}
Per tracciare il diagramma di Bode del modulo in $dB$ della risposta
in frequenza \`e sufficiente tracciare i diagrammi dei singoli termini
che compaiono nella \ref{eq:modrispfreq}.

Ricordando che per
ogni numero complesso $s\neq 0$ vale $|\dfrac{1}{s}|_{dB} = -|s|_{dB}$, il
diagramma di Bode relativo agli zeri della funzione di trasferimento
si ricava a partire da quello relativo ai poli, cambiato di segno.
I termini che ci interessano sono quindi:
\begin{eqnarray}
  G_a(s)=\mu\\
  G_b(s)=\frac{1}{s}\\
  G_c(s)=\frac{1}{1+sT}\\
  G_d(s)=\frac{1}{1+2\xi \dfrac{s}{\omega_n} + \dfrac{s^2}{\omega_n^2}}
\end{eqnarray}
\`E importante far notare che i diagrammi che verranno mostrati sono i
cosiddetti \emph{diagrammi asintotici} di Bode, i quali sono diagrammi
approssimati in grado di dare informazioni qualitativamente
accettabili. In ogni caso \`e possibile stimare l'errore che
si commette nell'approssimazione ed apportare le opportune modifiche.

\subsubsection{Diagramma del modulo di $G_a(j\omega)$}
\[
  G_a(s)=\mu
\]
\begin{displaymath}
  |G_a(j\omega)|_{dB} = 20\log|\mu|
\end{displaymath}
Il diagramma corrisponde ad una retta parallela all'asse delle
$\omega$ con ordinata maggiore di zero, minore di zero o pari a zero a
seconda che $|\mu|$ sia maggiore di uno, minore di uno o unitario:
\[
\begin{array}{l}
  ordinata > 0 \;\; se \;\; |\mu| > 1\\
  ordinata < 0 \;\; se \;\; |\mu| < 1\\
  ordinata = 0 \;\; se \;\; |\mu| = 1
\end{array}
\]

\subsubsection{Diagramma del modulo di $G_b(j \omega)$}
\[
  G_b(s)=\frac{1}{s}
\]
\begin{displaymath}
  |G_b(j\omega)|_{dB} = 20\log\left | \frac{1}{j\omega}\right |  = 20
  (\log |1| - \log |j\omega|)
\end{displaymath}
Il modulo \`e pari a:
\begin{equation}\label{eq:modulo}
  | | =  \sqrt{\Re e^2 + \Im m^2}
\end{equation}
Quindi il modulo di $j \omega$ \`e $\omega$:
\[
  |G_b(j\omega)|_{dB} = -20 \log \omega
\]
Il diagramma \`e una retta poich\`e sia sull'asse delle ordinate che
sull'asse delle ascisse abbiamo un valore logaritmico.
Per essere tracciata necessita della conoscenza di due punti:
convenzionalmente, osservando che 
\[
|G_b(j1)|_{dB} = 0
\]
e
\[
|G_b(j10)|_{dB}=-20
\]
si usa indicare come pendenza unitaria il valore \textbf{20dB/dec}. Si
dice che la retta ha pendenza $-1$ o che ``perde 20 dB/decade''.

In generale il diagramma del $|G(s)| = \dfrac{1}{s^g}$ \`e una retta con
ordinata pari a zero in $\omega = 1$ e pendenza pari a  $-g$: ovvero perde $20g$
dB/dec per ogni azione integrale ($g > 0$) e guadagna $20|g|$ dB/dec
per ogni azione derivativa ($g > 0$).
\begin{figure}[!t]
  \begin{center}
    \includegraphics[scale=0.5]{./figures/diagmod2.png}
    \caption{Diagramma di Bode di $|G_b(j\omega)|_{dB}$}
    \label{fig:bode2}
  \end{center}
\end{figure}
 
\subsubsection{Diagramma del modulo di $G_c(j\omega)$}
\begin{figure}[!t]
  \begin{center}
    \includegraphics[scale=0.5]{./figures/diagmod3.png}
    \caption{Diagramma di Bode di $|G_c(j\omega)|_{dB}$}
    \label{fig:bode3}
  \end{center}
\end{figure} 
\[
  G_c(s)=\frac{1}{1+sT}
\]
\begin{displaymath}
  |G_c(j\omega)|_{dB} = 20\log\left | \dfrac{1}{1 + j\omega T}\right |
  = 20 ( \log 1 - \log | 1 + j \omega T |)
\end{displaymath}
Ricordando l'equazione \ref{eq:modulo}:
\[
  |G_c(j\omega)|_{dB} = - 20\log \sqrt {1 + \omega^2T^2}
\]
Il suo grafico \`e riportato in figura \ref{fig:bode3}. In particolare
il suo valore \`e:
\begin{displaymath}
  |G_c(j\omega)|_{dB}\simeq \left\{ 
  \begin{array}{l}
    -20\log 1 = 0\qquad,\qquad \omega \ll \frac{1}{|T|} \\ 
    -20\log \omega |T| \qquad , \qquad \omega \gg \frac{1}{|T|}
  \end{array}
  \right.
\end{displaymath}
Sostituendo il diagramma esatto con quello asintotico si commette un
errore $E_c(\omega)$ pari $20\log\sqrt{2} \simeq -3dB$, nei cosiddetti
\emph{punti di rottura}\index{Punto di rottura}: $\omega =
\dfrac{1}{|T|}$. 

\subsubsection{Diagramma del modulo di $G_d{(j\omega)}$}
\begin{figure}[!b]
  \begin{center}
    \includegraphics[scale=0.5]{./figures/diagmod4.png}
    \caption{Diagramma di Bode di $|G_d(j\omega)|_{dB}$}
    \label{fig:bode4}
  \end{center}
\end{figure}
\[
  G_d(s)=\dfrac{1}{1+2\xi \dfrac{s}{\omega_n} + \dfrac{s^2}{\omega_n^2}}
\]
\begin{eqnarray*}
  \lefteqn{|G_d(j\omega)|_{dB}=20\log \left| \dfrac{1}{1 +
      2j\xi\dfrac{\omega}{\omega_n} -
      \dfrac{\omega^2}{\omega_n^2}}\right| = {} } \\
  & & {}=-20\log\sqrt{\left(1 - \dfrac{\omega^2}{\omega_n^2}\right)^2
    + 4\dfrac{\xi^2\omega^2}{\omega_n^2}}
\end{eqnarray*}
Il diagramma di questa funzione non dipende dal segno di $\xi$ ed in
particolare il suo massimo si ha per $|\xi| < \dfrac{1}{\sqrt{2}}
\simeq 0.707$. Tale massimo \`e chiamato \emph{picco di
  risonanza}\index{Picco di risonanza} ed \`e in corrispondenza della
\emph{pulsazione di risonanza}\index{Pulsazione di risonanza} che
vale
\begin{equation}\label{eq:pulsrison}
  \omega_r=\omega_n\sqrt{1-2\xi^2}
\end{equation}
mentre il picco di risonanza risulta
\begin{equation}\label{eq:piccodirison}
  |G_d(j\omega_r)|_{dB} = \dfrac{1}{2|\xi|\sqrt{1-2\xi^2}}
\end{equation}
ovvero
\begin{equation}
  |G_d(j\omega_n)|_{dB} = \dfrac{1}{2|\xi|}
\end{equation}
Il valore del $|G_d(j\omega)|_{dB}$ \`e
\begin{displaymath}
  |G_d(j\omega)|_{dB}\simeq \left\{ 
  \begin{array}{l}
    -20\log 1 = 0\qquad,\qquad \omega \ll \omega_n\\ 
    -40\log \left( \dfrac{\omega}{\omega_n}\right) \qquad , \qquad \omega \gg  \omega_n
  \end{array}
  \right.
\end{displaymath}

\subsection{Diagrammi delle fasi}
Nel diagramma della fase, si riporta sulle ordinate, in scala lineare,
il valore di $\arg{G(j\omega)}$ in radianti o
gradi~\footnote{Trasformazione gradi in radianti
  \framebox{$180[\circ]:\pi[rad]=angolo[\circ]:x [rad]$}}. Il tracciamento del
diagramma delle fasi degli zeri di $G(s)$ si ricava a partire da
quello dei poli cambiato di segno. Per ogni numero complesso
$s\neq0$ vale che $\arg{1/s} = -\arg{s}$. Si ha quindi:
\begin{eqnarray*}
  \lefteqn{\arg G(j\omega) = \underbrace{\arg
      \mu}_{G_a(j\omega)}\underbrace{-g\arg(j\omega)}_{G_b(j\omega)} +
    \sum_i \arg(1+j\omega \tau_i)+{} }\\
  & & {}+\sum_i \arg \left(1 + 2j\zeta_i
  \dfrac{\omega}{\alpha_{ni}} - \dfrac{\omega^2}{\alpha^2_{ni}}
  \right) \underbrace{-\sum_i
    \arg(1 + j\omega T_i)}_{G_c(j\omega)}+
\end{eqnarray*}
\begin{equation}\label{eq:phaserispfreq}
  \underbrace{-\sum_i \arg \left(1 + 2j\xi_i
    \dfrac{\omega}{\omega_{ni}} - \dfrac{\omega^2}{\omega^2_{ni}}
    \right)}_{G_d(j\omega)} 
\end{equation}
Il diagramma della fase di $G(j\omega)$ si pu\`o quindi calcolare
tracciando i diagrammi delle singole componenti della
\ref{eq:phaserispfreq} e sommandoli.

\subsubsection{Diagramma della fase di $G_a(j\omega)$}
\begin{displaymath}
  \arg G_a(j\omega)= \arg \mu = \left
  \{ \begin{array}{c}0^{\circ}\qquad,\qquad \mu >0
      \\ -180^{\circ}\qquad,\qquad \mu < 0\end{array} \right. 
\end{displaymath}
E' una retta parallela all'asse delle $\omega$~\footnote{La scelta di
  uno sfasamento di $-180^{\circ}$ \`e puramente convenzionale}

\subsubsection{Diagramma della fase di $G_b(j\omega)$}
\begin{equation}\label{fase1/s}
  \arg G_b(j\omega) = \arg \left ( \frac{1}{j\omega}\right )=-90^{\circ}
\end{equation}
Questo risultato \`e ottenuto considerando che:
\[
arg \left( \dfrac{x}{y} \right) = arg(x) - arg(y)
\]
Se condideriamo:
\[
x = a + jb
\]
possiamo continuare con:
\[
arg(a + jb) = arctan \left( \dfrac{b}{a} \right)
\]
Ricordano che:
\[
arctan(\infty) = \dfrac{\pi}{2}
\]
otteniamo il risultato \ref{fase1/s}.

Dato che la fase risulta negativa, si dice che il polo nell'origine in
questo caso produce un \emph{ritardo di fase}.

In generale, il diagramma di Bode della fase di $G(s) =
\dfrac{1}{s^g}$ \`e una retta parallela all'asse delle $\omega$ e di
ordinata $-g \cdot 90^{\circ}$. Nel caso di azioni derivative $(g~<~0)$
questo contributo \`e positivo e si usa dire che gli zeri nell'origine
producono un \emph{anticipo di fase}.

\subsubsection{Diagramma della fase di $G_c(j\omega)$}
\begin{displaymath}
  \arg G_c(j\omega)=-arg(1 + j\omega T)= -\arctan (\omega T)
\end{displaymath}
In figura \ref{fig:fasi3} \`e riportato il grafico di $\arg
G_c(j\omega)$. La fase \`e negativa se il polo $s= -\dfrac{1}{T}$ \`e
negativo (il polo negativo ritarda), viceversa \`e positiva (il polo
positivo anticipa). Si noti che:
\begin{displaymath}
  \arg G_c(j\omega) \simeq
  \left\{
  \begin{array}{l}
    -\arg(1)=0^{\circ},\qquad \omega \ll1/|T| \\
    -\arg(j\omega T) = \left\{\begin{array}{l}-90^{\circ} \textrm{ per } T>0 \\
    +90^{\circ} \textrm{ per }  T<0
    \end{array}\right\},\qquad \omega \gg1/|T|
  \end{array}\right.
\end{displaymath}
\begin{figure}[!hbp]
  \begin{center}
    \includegraphics[scale=0.5]{./figures/diagfas3.png}
    \caption{Diagramma di Bode di $\arg G_c(j\omega)$}
    \label{fig:fasi3}
  \end{center}
\end{figure} 
Il diagramma associato al termine $G(s)=1 + sT$, corrispondente ad uno
zero reale \`e simmetrico rispetto a quello di $G_c(s)$, per cui si
dice che lo zero negativo ``anticipa'', mentre lo zero positivo
``ritarda''.

\subsubsection{Diagramma della fase di $G_d(j\omega)$}
\begin{displaymath}
  \arg G_d(j\omega)=-\arg \left ( 1 + 2j\xi \dfrac{\omega}{\omega_n} -
  \dfrac{\omega^2}{\omega_n^2} \right)
\end{displaymath}
\begin{figure}[!hbp]
  \begin{center}
    \includegraphics[scale=0.5]{./figures/diagfas4.png}
    \caption{Diagramma di Bode di $\arg G_d(j\omega)$}\label{fig:fasi4}
  \end{center}
\end{figure} 

Il grafico di questa funzione, come mostrato in figura
\ref{fig:fasi4}, dipende dal valore (modulo e segno) dello smorzamento
$\xi$. Per $\xi > 0$, cio\`e poli a parte reale negativa, si ha $\arg
G_d(j\omega_n) = -90^{\circ}$, ovvero i poli danno un contributo di
ritardo. Per $\xi < 0$, cio\`e con poli a parte reale positiva, si ha
$\arg G_d(j\omega_n)= + 90^{\circ}$, ovvero i poli danno un contributo
di anticipo. Per $\xi = 0$ invece, si ha:
\begin{displaymath}
  G_d(j\omega)=\dfrac{1}{1-\frac{\omega^2}{\omega_n}}
\end{displaymath}
Quindi $G_d(j\omega)$ \`e un numero reale positivo (con sfasamento
nullo) per $\omega < \omega_n$ e negativo (con un convenzionale
sfasamento di $-180^{\circ}$) per $\omega > \omega_n$.

\section{Tracciamento dei diagrammi dei moduli}
\subsection{Calcolo di $g_0$}\label{g0}
$g_0$ \`e la differenza tra il numero di poli nello zero e gli zeri
nello zero.
\begin{equation}
  g_0 = m_0 - n_0
\end{equation}

\subsection{Calcolo del guadagno generalizzato}\label{guadagnogeneralizzato}
\begin{equation}
  k = \lim_{s \to 0} G(s) \cdot s^{g_0}
\end{equation}
Nota: spesso il guadagno generalizzato\index{Guadagno generalizzato}
\`e erroneamento confuso col guadagno statico $\mu$. A volte coincidono, ma
sono comunque due parametri ben distinti.

\subsection{Pendenza iniziale}
\begin{equation}\label{pendezainiziale}
  - g_0 \cdot 20dB/dec
\end{equation}

\subsection{Punti di rottura}
I punti di rottura si ricavano calcolando i poli e gli zeri della
funzione di trasferimento. \`E bene considerare il seguente caso
generale:
{\Large\begin{equation}
  \frac{s^n (sT + 1)\left(\frac{s^2}{\omega_n^2} +
    2\frac{\zeta}{\omega_n}s + 1\right)}{s^m (sT + 1) \left(
    \frac{1}{\omega_n^2}s^2 + \frac{2}{\omega_n}\zeta s + 1\right)}
\end{equation}}
Consideriamo adesso un comodo esempio:
\[
  \frac{s^2 (1 + 0.01S)}{(s + 1)(100 s^2 + 14s + 1)}
\]
Nel nostro esempio abbiamo:
\begin{itemize}
  \item Zeri:
    \begin{itemize}
    \item[*] $0$ (x2)
    \item[*] $-100$
    \end{itemize}
  \item Poli:
    \begin{itemize}
      \item[*] $-1$
      \item[*] $-0.07 \pm 0.071j$
    \end{itemize}
\end{itemize}
Tipicamente i punti di rottura sono i valori dei poli e degli zeri,
presi in modulo. Naturalmente vanno escluse le radici pari a $0$ ;-)
Nel caso si abbiamo delle radici immaginarie e coincidenti si procede
individuando $\omega_n$ e $\zeta$. Considerando il nostro esempio
abbiamo che $\frac{1}{\omega_{n^2}} s^2$ della formula generale \`e pari
a $100 s^2$. Una rapida manipolazione matematica ed otteniamo
che $$\frac{1}{\omega_n^2} = 100 \Rightarrow \omega_n = 0.1$$
Stesso discorso per $\zeta$, che nel nostro caso
vale $$\frac{2}{\omega_n}\zeta = 14 \Rightarrow \zeta = 0.7$$
In definitiva, abbiamo che in nostri punti di rottura sono:
\[
\left\{
\begin{array}{l}
  0.1\\
  1\\
  100
\end{array}
\right .
\]
Nota: Dobbiamo considerare anche i tipi di poli e di zeri. $-100$ \`e
uno zero negativo. $-1$ \`e un polo negativo. Non ci sono n\`e poli
positivi n\`e zeri positivi. I {\em poli complessi e coniugati} vanno
valutati con attenzione:
\begin{itemize}
\item $\zeta < 0 \Rightarrow$ il polo \`e positivo
\item $\zeta \geq 0 \Rightarrow$ il polo \`e negativo
\end{itemize}
Nel caso degli {\em zeri complessi e coniugati} abbiamo che:
\begin{itemize}
  \item $\zeta < 0 \Rightarrow$ lo zero \`e positivo
  \item $\zeta \geq 0 \Rightarrow$ lo zero \`e negativo
\end{itemize}
In conclusione aggiungiamo che per il diagramma dei moduli vale la
seguente dichiarazione: {\em I poli fanno scendere. Gli zeri fanno salire}.

\subsection{Punto di partenza}\index{Punto di partenza}
Il punto di partenza ha tipicamente ascissa pari al valore del punto
di rottura pi\`u piccolo ``-2 decadi''. Nel nostro caso
$$\omega_0 = 10^{-3}$$
Per ottendere l'ordinata del punto di partenza calcoliamo:
\[
  20 log (|k|) - \left[ g_0 \cdot 20 log (\omega_0)\right]
\]

\subsection{Pendenza finale}\index{Pendenza finale}
Calcoliamo prima $g_{_{TOT}}$:
\begin{equation}\label{gtotale}
  g_{_{TOT}} = poli - zeri
\end{equation}
Nel nostro caso $g_{_{TOT}} = 3 - 3 = 0$. La pendenza finale \`e
dunque:
\begin{equation}\label{pendenzafinale}
  - g_{_{TOT}} \cdot 20\;dB/dec
\end{equation}

\section{Tracciamento dei diagrammi delle fasi}
\subsection{Fase iniziale}
Abbiamo bisogno di $g_0 = -2$. La fase iniziale \`e:
\[
  \phi_0 = -g_0 \cdot 90^{\circ}
\]
Nel nostro caso \`e $\phi_0 = -g_0 \cdot 90^{\circ} = 180^{\circ}$

\subsection{Fase finale}
Considerando che:
\[
  g_{_{TOT}} = (P_0 + P_{neg} + Z_{pos}) - (Z_0 + Z_{neg} + P_{pos})
\]
la fase finale \`e:
\begin{equation}\label{fasefinale}
  -g_{_{TOT}} \cdot 90^{\circ}
\end{equation}

Nota: Per il diagramma delle fasi vale la seguente dichiarazione:
{\em I poli fanno scendere e gli zeri fanno salire solo se sono
  negativi. Nel caso di zeri e poli positivi, i poli fanno salire e
                     gli zeri fanno scendere} ;-)


% SISTEMI A TEMPO DISCRETO - CORSO DI CONTROLLI
\chapter{Sistemi ad eventi discreti}
Quando lo spazio di stato di un sistema \`e descritto da un insieme
discreto di tipo $\{0, 1, 2, ...\}$ e le transizioni di stato si
verificano solo ad instanti discreti nel tempo, associamo queste
transizioni di stato ad {\em eventi}\index{Evento} e parliamo di
sistemi a tempo discreto.

\begin{definizione}\label{def:des}
  Un sistema ad eventi discreti \`e un sistema dinamico il cui
  comportamento \`e caratterizzato dal verificarsi asincrono di eventi
  che individuano lo svolgimento di attivit\`a di durata non sempre nota.
\end{definizione}

\section{Il concetto di evento}
Ecco le principali considerazioni da fare sul concetto di evento:
\begin{itemize}
\item \`e istantaneo
\item causa la transizione da uno stato ed un altro
\end{itemize}
Nel nostro studio, ci riferiremo al singolo evento con la lettera $e$
ed all'insieme di eventi con la lettera $E$.
\begin{definizione}
  Un evento $e$ si definisce abilitato (o attivo) nello stato $x$ se
  \`e definita una funzione di transizione $\delta (x,e)$.
\end{definizione}

\section{DES logici e temporizzati}
Esistono due principali tipi di sistemi ad eventi discreti (DES):
\begin{description}
\item[Temporizzati]:
  Le transizioni di stato possono verificarsi sia a causa di eventi
  che a causa di determinate condizioni temporali: es. si verifica
  l'evento $e$ o trascorrono $n$ secondi;
\item [Logici]:
  Le transizioni di stato sono determinate unicamente dal verificarsi
  di specifici e determinati eventi $e$, appartenenti ad $E$;
\end{description}
I DES (Discrete Events Systems) Logici sono anche detti {\em
  Event-driven DES}\index{Event-driven Discrete Events
  Systems}. Questo tipo di sistema \`e particolarmente complicato da
modellare ed analizzare a causa della natura asincrona delle
transizioni di stato.

\section{Gli automi a stati finiti}
Un automa a stati finiti (ASF) \`e un sistema dinamico, tempo invariante,
discreto nell'avanzamento e nelle interazioni nel quale gli insiemi
dei possibili valori di ingresso, uscita e stato sono insiemi finiti.
Nel dettaglio, un ASF \`e:
\begin{itemize}
\item dinamico: evolve nel tempo passando da uno stato all'altro in
  funzione dei segnali d'ingresso e dello stato precedente;
\item tempo invariante: a parit\`a di condizioni iniziali il
  comportamento del sistema \`e sempre lo stesso;
\item discreto: le variabili d'ingresso, di stato e d'uscita possono
  assumere solo valori discreti.
\end{itemize}

\subsection{Automi a stati finiti deterministici}
Un automa a stati finiti deterministico (ASFD) \`e un automa a stati
finiti in cui per ogni coppia di stato e simbolo in ingresso c'\`e una
ed una sola transizione allo stato successivo.

Un ASFD \`e costituito da una quintupla:
\begin{equation}
  A = \{ E, \overline{\underline{X}}, \overline{\underline{X}}_m, x_0,
  \delta \}
\end{equation}
\begin{itemize}
\item $E$ \`e l'insieme degli eventi: $\{ e_1, e_2, e_3, ..., e_n\}$
\item $\overline{\underline{X}}$ \`e l'insieme degli stati: $\{ x_0, x_1,
  x_2, ..., x_n\}$
\item $\overline{\underline{X}}_m$ \`e l'insieme degli stati finali o {\em
  marcati}
\item $x_0$ \`e lo stato iniziale
\item $\delta$ \`e la funzione di transizione: $\overline{\underline{X}}
  \times E$
\end{itemize}

\subsubsection{Macchina}\index{Macchina ASFD}
La figura \ref{fig:macchina} mostra l'ASFD di una generica
macchina. L'evoluzione della macchina \`e la seguente:
\begin{itemize}
\item La macchina \`e pronta a ricevere un pezzo. Passa cos\`i dallo
  stato ``Idle'' allo stato ``Busy''.
\item Conclusa la lavorazione, il pezzo viene depositato e si passa
  allo stato ``Blocked''.
\item A questo punto, il pezzo pu\`o essere prelevato e la macchina
  diventa nuovamente ``Idle''.
\end{itemize}
\input{./tex/macchinaASFD}
Gli eventi e gli stati sono:
\begin{itemize}
\item $E = \{ task, end, free \}$
\item $\overline{\underline{X}} = \{ Idle, Busy, Blocked\}$
\item $x_0 = \{ Idle\}$
\end{itemize}

La funzione di transizione \`e:
\begin{itemize}
\item $\delta$(Idle, task) = Busy
\item $\delta$(Busy, end ) = Blocked
\item $\delta$(Blocked, free) = Idle
\end{itemize}
Nota: l'evento ``end'' deve indicare la fine di tutti i task, poich\`e
\`e impossibile trovarsi contemporaneamente in due stati.

\subsubsection{Buffer / Coda / Magazzino}\index{Buffer
  ASFD}\index{Coda AFSD}\index{Magazzino ASFD}
La figura \ref{fig:coda} mostra l'ASFD di una generica coda.
\input{./tex/magazzinoASFD}
La coda o buffer o magazzino della figura \ref{fig:coda} ha capacit\`a
2. \`E costituito da tre stati:
\[
\overline{\underline{X}} = \{ x_0, x_1, x_2\}
\]
Lo stato iniziale \`e $x_1$. Gli eventi sono due:
\begin{itemize}
\item $a$ indica l'arrivo di un nuovo pezzo
\item $p$ indica il prelievo di un pezzo
\end{itemize}
La funzione di transizione \`e:
\[
\begin{array}{l}
  \delta(x_0, a) = x_1\\
  \delta(x_1, a) = x_2\\
  \delta(x_1, p) = x_0\\
  \delta(x_2, p) = x_1
\end{array}
\]

\subsubsection{Magazzino multiclasse}\index{Magazzino multiclasse ASFD}
Un magazzino multiclasse \`e un magazzino che pu\`o contenere pezzi di
cardinalit\`a differente. La figura \ref{fig:magazzinoMulticlasse} mostra
un ASFD di un magazzino di capacit\`a 4 e che,quindi, pu\`o contenere
quattro elementi di tipo 1 o due elementi di tipo 2. Gli stati
``doppio cerchio'' sono detti stati finali.

\begin{itemize}
\item L'evento $d_1$ indica il deposito di un pezzo di tipo 1
\item L'evento $d_2$ indica il deposito di un pezzo di tipo 2
\item L'evento $p_1$ indica il prelievo di un pezzo di tipo 1
\item L'evento $p_2$ indica il prelievo di un pezzo di tipo 2
\end{itemize}
\input{./tex/magazzinoMulticlasseASFD}

\subsection{Automi composizione concorrente}
Si possono unire pi\`u automi deterministici per formare un automa
pi\`u complesso, detto tipicamente ``automa composizione
concorrente''. I due automi originali vengono ``collegati'' tramite un
evento comune. 

Dati $k$ automi da $N$ stati, l'automa a composizione concorrente avr\`a
$k^N$ stati. \`E palese la difficolt\`a di utilizzare questo genere di
strumento per l'analisi di sistemi complessi.

Supponendo due automi a composizione concorrente $G'$ e $G''$ e i loro
insiemi di eventi $E'$ ed $E''$, gli eventi appartenenti ad $E' \cap
E''$ si definiscono ``eventi sincronizzati''\index{Eventi
  sincronizzati}. Tali eventi possono verificarsi solo se attivi negli
stati di entrambi gli automi.
%%%%%%%%%%%%%%%%%%%%%%%
\chapter{Reti di Petri}
%%%%%%%%%%%%%%%%%%%%%%%
\begin{figure}[!h]
  \begin{center}
    \includegraphics[scale=0.5]{./figures/petri.png}
    \caption{Esempio di una rete di Petri}\label{fig:petri01}
  \end{center}
\end{figure} 
\begin{definizione}
  Una rete di Petri, dal nome del matematico ed informatico tedesco Carl
  Adam Petri (Lipsia, 12 luglio 1926 - 2 luglio 2010), conosciuta anche
  come rete posto/transizione o rete P/T, \`e un grafo bipartito
  orientato e pesato di un sistema ad eventi discreti. Una rete di Petri
  ha dei {\bo nodi posti}, dei  {\bo nodi transizioni} e degli {\bo
    archi diretti} che connettono posti e transizioni. Possono esserci
  archi tra posti e transizioni, ma non tra posti e posti o tra
  transizioni e transizioni.
\end{definizione}
\section{Definizione formale}
Una rete di Petri pu\`o essere una tupla $\{ P, T, M, Post, Pre \}$ dove:
\begin{itemize}
\item $P$ \`e l'insieme dei posti
\item $T$ \`e l'insieme delle transizioni
\item $M$ \`e il vettore marcatura
\item $Post$ \`e la matrice di Post-incidenza\index{Matrice di
  Post-incidenza} 
\item $Pre$ \`e la matrice di Pre-incidenza\index{Matrice di
  Pre-incidenza} 
\end{itemize}

\subsection{Posti}
I posti possono contenere un certo numero di {\em
  token}\index{Token}\index{Gettone} o gettoni. Una distribuzione di
token sull'insieme dei posti della rete \`e detta {\em
  marcatura}\index{Marcatura}. 
Il numero totale di token
{\em non \`e conservativo}: una transizione $t_x$ pu\`o portare un generico
posto $p_n$ a perdere $k$ token e un generico posto $p_m$ a guadagnare
$z$ token.
\subsection{Transizioni}
Le transizioni agiscono sui token in ingresso secondo una regola, detta
{\bo regola di scatto}\index{Regola di scatto} (in inglese
{\em firing}\index{Firing}). Una transizione \`e {\em 
  abilitata} se pu\`o scattare, cio\`e se ci sono sufficienti token in
ogni posto di input, cio\`e se il vettore di marcatura
(\ref{vettoreDiMarcatura}) \`e ``maggiore o uguale'' della colonna
associata alla transizione nella matrice di Pre-incidenza
(\ref{matricePreincidenza}): 
\begin{equation}\label{eq:transizioneAbilitata}
M \geq Pre(\cdot,t)
\end{equation}
Quando una transizione scatta, essa consuma token dai suoi
posti di input, esegue dei task e posiziona un numero specificato di
token in ognuno dei suoi posti di uscita. Pi\`u formalmente, lo scatto
di $t$ rimuove $Pre(p_n,t)$ token da ogni posto $p_n$ ad essa connesso
e aggiunge $Post(p_n,t)$ in ogni posto $p_n$ ad essa connesso. Si
arriva, quindi, ad una nuova marcatura $M_r$, detta ``marcatura
raggiunta'':
\begin{equation}\label{eq:marcaturaPostScatto}
  M_r = M - Pre(\cdot,t) + Post(\cdot,t) = M + C(\cdot,t)
\end{equation}
dove $C$ \`e la matrice di incidenza\index{Matrice di incidenza}:
\[
C = Post(\cdot, t) - Pre(\cdot, t)
\]

\subsubsection{Transizioni sempre abilitate}
Le transizioni sempre abilitate o transizioni ``sorgente'' non
hanno archi in entrata e possono scattare quando necessario, senza
le limitazioni imposte dai token:
\[
Pre(\cdot,t) = 0
\]
e l'equazione \ref{eq:transizioneAbilitata} \`e sempre verificata.
Questo genere di transizioni porta la rete di Petri ad avere un
vettore di marcatura potenzialmente sempre diverso:
\begin{definizione}
  Una rete di Petri che contiene una transizione sorgente ha un numero
  potenzialmente illimitato di stati.
\end{definizione}

\subsubsection{Transizioni in conflitto}
Le transizioni in conflitto sono transizioni abilitate che in caso di
``scatto'' si disabilitano l'un l'altra.
\begin{definizione}
 Due transizioni si dicono in conflitto se sono verificate
 contemporaneamente le seguenti tre condizioni: 
 \[
 \left \{
 \begin{array}{l}
   M \geq Pre(\cdot, t_i)\\
   M \geq Pre(\cdot, t_j)\\
   M \ngeq Pre(\cdot, t_i) + Pre(\cdot, t_j)
 \end{array}
 \right .
 \]
cio\`e il vettore di marcatura \`e maggiore del numero di token nella
colonna $t_i$ (o $t_j$) della matrice di pre-incidenza.
\end{definizione}
Per ``maggiore'' si intende un confronto elemento per
elemento, tra il vettore marcatura (una colonna) e la colonna $t_i$ (o
$t_j$) della matrice di pre-incidenza. Il vettore
marcatura \`e maggiore solo se tutti i suoi elementi confrontati sono
maggiori o uguali (AND logico). In altri termini, la marcatura $M$
abilita entrambe le transizioni, ma tale marcatura non contiene un
numero sufficiente di token per consentire lo scatto di entrambe le
transizioni. 

\subsection{Vettore marcatura}\index{Vettore
  marcatura}\label{vettoreDiMarcatura} 
Il vettore marcatura definisce lo {\em stato} della rete di
Petri. Indica quanti token sono contenuti in ogni posto della
rete. \`E un vettore colonna di interi non negativi:
\[
M = 
 \begin{bmatrix}
  k\\
  ...\\
  n
 \end{bmatrix}
 \Leftrightarrow
 M = [ k \; ... \; n]^T
\]
Una marcatura \`e una funzione $M : P \rightarrow N$ che assegna ad
ogni posto un numero intero non negativo di gettoni. Una marcatura
$M_0$ indica tipicamente la marcatura iniziale della rete. 

\subsection{Matrice di Pre-incidenza}\label{matricePreincidenza}
\`E una matrice $n \times m$, con $n$ pari al numero di posti ed $m$
pari al numero di transizioni. Indica il peso degli archi che
collegano posti e transizioni. Dal punto di vista grafico, la matrice
di pre-incidenza ``muove'' dal posto alla transizione.

\[
Pre =
\begin{array}{c}
  P_1\\
  P_2\\
  ...\\
  P_n\\
  
\end{array}
\begin{array}{cc}
  \\
 \begin{bmatrix}
   ... & ... & ... & ... \\
   ... & ... & ... & ... \\
   ... & ... & ... & ... \\
   ... & ... & ... & ... \\
 \end{bmatrix}\\
  t_1\;\;t_2\;\;...\;\;\;t_m
\end{array}
\]

\subsection{Matrice di Post-incidenza}
\`E una matrice $n \times m$, con $n$ pari al numero di posti ed $m$
pari al numero di transizioni. Indica la quantit\`a di token che il
posto $p_n$ guadagna allo ``scattare'' della transizioni $t_m$. Dal
punto di vista grafico, la matrice di post-incidenza ``muove'' dalla
transizione al posto. 
\[
Post =
\begin{array}{c}
  P_1\\
  P_2\\
  ...\\
  P_n\\
  
\end{array}
\begin{array}{cc}
  \\
 \begin{bmatrix}
   ... & ... & ... & ... \\
   ... & ... & ... & ... \\
   ... & ... & ... & ... \\
   ... & ... & ... & ... \\
 \end{bmatrix}\\
  t_1\;\;t_2\;\;...\;\;\;t_m
\end{array}
\]

\subsection{Sequenza di scatto e vettore di scatto}
\begin{definizione}
  La sequenza di scatto abilitata $\sigma$ \`e una sequenza di
  transizioni $t_l, t_m, t_n, ..., t_z$ tali che ad ogni scatto si
  giunga ad una marcatura che abilita la successiva transizione della
  sequenza. 
\end{definizione}
L'esistenza di una sequenza di scatto che da $M_0$ ci porti ad una
marcatura $M_r$ rende $M_r$ una {\em marcatura
  raggiungibile}\index{Marcatura raggiungibile}. L'insieme di
raggiungibilit\`a di una rete \`e l'insieme delle marcature che si
possono raggiungere, partendo da $M_0$. L'insieme delle sequenze di
scatto abilitate da $M_0$ \`e detto {\em
  comportamento}\index{Comportamento} (o linguaggio). 

Il vettore di scatto $\bar{\sigma}$ associato a $\sigma$ rappresenta
il numero di occorrenze di ogni transizione in una specifica sequenza
di scatto $\sigma$. Tipicamente \`e un vettore colonna, di $m$
elementi quante sono le transizioni $t$. 

Il vettore di scatto ci porta all'{\em equazione di stato delle reti
  di Petri}\index{Equazione dei stato dell reti di Petri}:
\begin{equation}
  M_r = M_0 + C \cdot \bar{\sigma}
\end{equation}
dove
\begin{itemize}
\item $M_r$ \`e la marcatura che si vuole raggiungere
\item $M_0$ \`e la marcatura iniziale
\item $C$ \`e la matrice di incidenza
\item $\bar{\sigma}$ \`e il vettore di scatto
\item $C \cdot \bar{\sigma}$ \`e il prodotto riga x colonna
\end{itemize}
Questa relazione vale se $M_r$ \`e raggiungibile da $M_0$ allo
scattare della sequenza di transizioni $\sigma$.

\section{Reti di Petri elementari}
La figura \ref{fig:sequenzialitaPetri} mostra una rete di Petri in cui
gli eventi si succedono in un ben determinato ordine.
\input{./tex/sequenzialitaPetri}
La figura \ref{fig:parallelismoSincronizzazionePetri} mostra un
esempio di rete di Petri ``parallelo'' e una rete di Petri
``sincronizzazione''. 
\input{./tex/parallelismoSincronizzazionePetri}
Nel parallelismo, gli eventi possono verificarsi senza alcun ordine
prefissato; non sono in conflitto strutturale tra di loro, poich\`e il
verificarsi di un evento non pregiudica l'abilitazione di un altro
evento. Nella sincronizzazione, pi\`u eventi paralleli devono
verificarsi per proter proseguire.
\input{./tex/sceltaPetri}
La figura \ref{fig:sceltaPetri} mostra una ``scelta'': un solo evento
tra i tanti possibili pu\`o verificarsi, poich\`e lo scatto di una
transizione disabilita le altre. Il posto iniziale a pi\`u transizioni
in uscita determina il conflitto strutturale.

\section{Reti di Petri comuni}
\subsection{Magazzino multiclasse - Petri}\index{Magazzino
  multiclasse Petri}
\input{./tex/magazzinoMulticlassePetri}
La figura \ref{fig:magazzinoMulticlassePetri} mostra un magazzino
multiclasse rappresentato con una rete di Petri. Questo tipo di
magazzino gestisce due tipi diversi di pezzi; tiene traccia di quanti
pezzi sono contenuti nel magazzino e di che tipo di pezzi si tratta;
tiene traccia del numero di posti ancora disponibili nel magazzino. La
rete \`e costituita da 3 posti e 4 transitioni. Le marcature nei posti
sono le seguenti: 
\begin{itemize}
\item $M_{p_1}$ indica il numero di posti liberi nel magazzino
\item $M_{p_2}$ indica il numero di pezzi di tipo 2
\item $M_{p_3}$ indica il numero di pezzi di tipo 1
\end{itemize}
La transizioni sono le seguenti:
\begin{itemize}
\item $t_1$ indica il deposito di un pezzo di tipo 1
\item $t_2$ indica il prelievo di un pezzo di tipo 1
\item $t_3$ indica il deposito di un pezzo di tipo 2
\item $t_4$ indica il prelievo di un pezzo di tipo 2
\end{itemize}
La matrice di pre-incidenza \`e:
\[
Pre = 
\begin{bmatrix}
  1 & 0 & 2 & 0\\
  0 & 0 & 0 & 1\\
  0 & 1 & 0 & 0
\end{bmatrix}
\]
La matrice di post-incidenza \`e:
\[
Post =
\begin{bmatrix}
  0 & 1 & 0 & 2\\
  0 & 0 & 1 & 0\\
  1 & 0 & 0 & 0
\end{bmatrix}
\]

\subsection{Contatore o magazzino infinito}
La figura \ref{fig:contatorePetri} mostra un contatore ``a salire'' e
``a scendere'' di numeri interi non negativi oppure un magazzino di
capacit\`a infinita:
\begin{itemize}
\item $P_1$ indica il numero di pezzi nel magazzino
\item $t_1$ deposita un nuovo pezzo
\item $t_2$ preleva un nuovo pezzo
\end{itemize}
\input{./tex/contatorePetri}

\subsection{Magazzino finito}
La figura \ref{fig:magazzinoPetri} un magazzino di capacit\`a finita:
\begin{itemize}
\item $P_1$ indica il numero di pezzi nel magazzino
\item $P_2$ indica la dispoinibilit\`a nel magazzino
\item $t_1$ deposita un nuovo pezzo
\item $t_2$ preleva un nuovo pezzo
\end{itemize}
\input{./tex/magazzinoPetri}


\subsection{Macchina - Magazzino - Macchina}
\input{./tex/macchinaMagazzinoMacchinaPetri}
La figura \ref{fig:macchinaMagazzinoMacchinaPetri} mostra una rete
complessa, costituita da tre reti legate da due transizioni comuni. Un
possibile scenario \`e il seguente:
\begin{itemize}
\item $P_{i_1}$ la macchina 1 \`e libera
\item $P_{w_1}$ la macchina 1 passa in lavorazione
\item $P_{b_1}$ la macchina 1 \`e occupata
\item $t_{13}$ se la macchina 1 \`e occupata e c'\`e spazio in
  magazzino, un pezzo viene depositato in magazzino e la macchina 1
  torna libera
\item $P_{m_1}$ sono i pezzi presenti in magazzino
\item $P_{i_2}$ la macchina 2 \`e libera
\item $t_{21}$ se la macchina 2 \`e libera e nel magazzino c'\`e
  almeno un pezzo, la macchina 2 preleva un pezzo e passa in
  lavorazione
\item $P_{m_2}$ mostra i posti liberi nel magazzino: uno \`e stato
  appena liberato dalla transizione $t_{21}$ e parteciper\`a
  all'abilitazione della transizione $t_{13}$
\end{itemize}

\subsection{Macchina non affidabile}
\input{./tex/macchinaNonAffidabilePetri}
La figura \ref{fig:macchinaNonAffidabilePetri} mostra la rete di Petri di
una macchina non affidabile. La rete \`e pi\`u complessa di una macchina
normale:
\begin{itemize}
\item $P_1$: macchina ferma
\item $P_2$: macchina in lavorazione
\item $P_3$: macchina guasta
\item $t_1$: inizio lavorazione
\item $t_2$: fine lavorazione
\item $t_3$: macchina guasta
\item $t_4$: riparazione macchina
\end{itemize}

\subsection{Mittente - Destinatario}
\input{./tex/mittenteDestinatarioPetri}
La figura \ref{fig:mittenteDestinatarioPetri} mostra una rete di Petri
di un sistema Mittente-Destinatario: il mittente \`e pronto ad inviare
un messaggio. Inviato il messaggio, attende la ricevuta. Il ricevente
\`e in attesa di un messaggio. Ricevuto il messaggio, invia una
risposta. 

\subsection{Ponti di Konigsberg}
\begin{figure}[!h]
  \begin{center}
    \includegraphics[scale=0.5]{./figures/konigsberg_bridges.png}
    \caption{Ponti di Konigsberg}\label{fig:konigsberg_bridges}
  \end{center}
\end{figure} 
Il problema dei sette ponti di Konigsberg \`e un problema ispirato da
una citt\`a reale e da una situazione concreta.
Ci si pone la questione se sia possibile con una passeggiata seguire
un percorso che attraversa ogni ponte una e una volta sola e tornare
al punto di partenza.
\begin{figure}[!h]
  \begin{center}
    \includegraphics[scale=0.4]{./images/pontiKonigsberg00}
    \caption{Ponti di Konigsberg}\label{fig:konigsberg_bridges00}
  \end{center}
\end{figure}
\begin{figure}[!h]
  \begin{center}
    \includegraphics[scale=0.4]{./images/pontiKonigsberg01}
    \caption{Ponti di Konigsberg}\label{fig:pontiKonigsberg01}
  \end{center}
\end{figure}
Quindi, partendo da una qualsiasi delle quattro sezioni (quartieri)
$A$, $B$, $C$ e $D$ \`e possibile ritornarvi passando una e una sola
volta per ciascuno dei 7 ponti che collegano i diversi quartieri?

La figura~\ref{fig:pontiKonigsberg01} mostra la rete di Petri del
problema: ogni quartiere \`e indicato con un posto; se scatta la
transizione $t_{AB}$ significa che ho percorso uno dei due ponti che
collegano $A$ e $B$, nel verso che va da $A$ a $B$. I posti $P_{AB}$,
$P_{BC}$, $P_{AD}$, $P_{BD}$ e $P_{CD}$ sono posti monitor che servono
a limitare, con le rispettive marcature, il numero di ponti che
collegano le diverse sezioni.

La marcatura iniziale, assunto di essere in $A$, \`e:
\[
M_0^T = [ 1 0 0 0 2 2 1 1 1 ]
\]




\subsection{Mutua esclusione}
Una risorsa \`e disponibile solo ad una operazione delle $n$ presenti
nella rete.
\include{./tex/mutuaEsclusionePetri}
La figura \ref{fig:mutuaEsclusionePetri} mostra la marcatura del
robot: un token che abilita $t_1$ e $t_3$. Se scatta $t_1$, la prima
macchina inizia a lavorare, il posto robot perde il suo token e $t_3$
\`e disabilitato. Allo scatto di $t_2$, il posto robot acquista un
token che riabilita allo scatto $t_1$ e $t_3$. Nel caso scatti $t_3$,
il comportamento della rete \`e simmetrico allo scatto di $t_1$.

\subsection{Lettori - Scrittori}
Un problema comune in informatica \`e l'accesso concorrente ad una
risorsa. Si suppongano $l$ lettori ed $s$ scrittori. Un lettore pu\`o
essere ``inattivo'' o ``in lettura''. Uno scrittore pu\`o essere
``inattivo'' o ``in scrittura''. La fase di lettura pu\`o essere
concorrente: fino ad $n$ lettori possono leggere
contemporaneamente. L'accesso in scrittura \`e mutuamente esclusivo:
uno scrittore in scrittura disabilita l'accesso in scrittura ad un
secondo scrittore e in lettura a tutti i lettori.
La figura \ref{fig:lettoriScrittoriPetri} mostra una reti di Petri che
descrive la soluzione al problema.
\input{./tex/lettoriScrittoriPetri}
Il posto $S$ soddisfa le condizioni del problema. Quando uno scrittore
inizia a scrivere, il posto $S$ si svuota e nessun altro
lettore o scrittore pu\`o accedere.

Quando un lettore accede in lettura, il posto $S$ perde uno dei suoi
$n$ token: nessuno scrittore pu\`o accedere, ma possono accedere
ancora $n - 1$ lettori.

\subsection{Sequenze ripetute abilitanti}
Supponiamo di volere che una determinata operazione $op_2$ sia
abilitata solo dopo una sequenza di almeno $N$ operazioni di tipo
$op_1$.
\input{./tex/sequenzeRipetuteAbilitantiPetri}
Il posto $P_m$ rende mutuamente esclusive le operazioni $op_1$ e
$op_2$. Supponiamo $N = 3$. Grazie alla rete di Petri, la sequenza di
scatto seguente \`e possibile:
\[
\begin{array}{c c c c c c c c c}
  &
  \underbrace{t_{11} \; t_{12}}_\text{$op_1$}\; &
  \underbrace{t_{11} \; t_{12}}_\text{$op_1$}\; &
  \underbrace{t_{11} \; t_{12}}_\text{$op_1$}\; &
  \underbrace{t_{11} \; t_{12}}_\text{$op_1$}\; &
  \underbrace{t_{11} \; t_{12}}_\text{$op_1$}\; &
  \underbrace{t_{21} \; t_{22}}_\text{$op_2$}\; &
  \underbrace{t_{11} \; t_{12}}_\text{$op_1$}\; &
  \underbrace{t_{11} \; t_{12}}_\text{$op_1$}\; \\
  M(P_N) &
  1 &
  2 &
  3 &
  3 &
  3 &
  0 &
  1 &
  2
\end{array}
\]
Si noti che essendo $N = 3$, quando $M(P_N) < 3$ (cio\`e non si sono
avute almeno 3 $op_1$ consecutive) la $t_{21}$ (cio\`e l'inizio di
$op_2$) non \`e abilitata.

La rete si pu\`o completare in modo simmetrico supponendo di voler
abilitare le $op_1$ solo dopo aver avuto almeno $M$ volte $op_2$. La
figura \ref{fig:sequenzeRipetutePetri1} ne mostra la realizzazione.
\input{./tex/sequenzeRipetuteAbilitantiPetri02}

La transizione $t_{11}$ non \`e abilitata se $M(P_M) < M$.
Il ruolo dei posti $P_N$ e $P_M$ \`e di contatore da zero ad $N$ ed
$M$, rispettivamente. Per sequenze di $op_1$ (o $op_2$) superiori ad
$N$ (o $M$) si ha comunque $M(P_N) = N$ e $M(P_M) = M$, facendo
scattare $t_N$ e $t_M$.

\subsection{Ciclo for}
Vogliamo costruire una RP che descriva la ripetizione di una azione
$n$ volte consecutive prima di svolgere una successiva operazione. Una
possibile implementazione \`e mostrata in figura
\ref{fig:cicloForPetri}.
\input{./tex/cicloForPetri}
\begin{itemize}
\item $t_1$: pu\`o cominciare il ciclo
\item $t_2$: comincia una iterazione del ciclo
\item $t_3$: finisce una iterazione del ciclo
\item $t_4$: finisce il ciclo
\item $M(P_1)$: pu\`o cominciare una iterazione del ciclo
\item $M(P_2)$: \`e in corso una iterazione del ciclo (una sola
  iterazione per volta)
\item $M(P_3)$: numero di iterazioni del ciclo completate
\item $M(P_4)$: numero di iterazioni del ciclo ancora da avviare
\item $M(P_5)$: pu\`o cominciare un nuovo ciclo
\end{itemize}

Si noti che l'arco da $P_1$ a $t_4$ serve ad eliminare il token da
$P_1$ (disabilitare una nuova iterazione) quando il ciclo finisce.

La marcatura iniziale della RP \`e:
\[
M_0 = [ 0\; 0\; 0\; n\; 1]
\]
\subsection{Incrocio semaforico}
Si consideri un incrocio costituito da due flussi di attraversamento:
Nord-Sud ed Est-Ovest. Il semaforo consente un flusso per volta e un
numero massimo di due vetture che possono occupuare l'incrocio.
\input{./tex/incrocioPetri}
La figura \ref{fig:incrocioPetri} mostra la rete di Petri di questo
incrocio. Ecco nel dettaglio il significato di posti e transizioni:
\begin{itemize}
\item $P_1$: Coda N-S
\item $P_2 \; e \; P_6$: attraversamento incrocio
\item $P_3 \; e \; P_7$: attraversamento numero vetture
\item $P_5$: Coda E-O
\item $P_4 \; e \; P_8$: numero di posti liberi nell'incrocio
\item $P_9$: semaforo verde N-S
\item $P_{10}$: semaforo verde E-O
\end{itemize}

\begin{itemize}
\item $t_1$: arrivo nuova vettura al semaforo N-S
\item $t_2$: impegna l'incrocio N-S
\item $t_3$: fine attraversamento incrocio N-S
\item $t_4$: arrivo nuova vettura al semaforo E-O
\item $t_5$: impegna incrocio E-O
\item $t_6$: fine attraversamento incrocio E-O
\item $t_7$: scatta al verde per E-O
\item $t_8$: scatta al verde per N-S
\end{itemize}

\subsection{Ascensore semplice}
\input{./tex/ascensoreSemplicePetri}
La figura \ref{fig:ascensoreSemplicePetri} mostra un modello di Petri
di un ascensore semplice\index{Ascensore semplice}. Il comportamento
dell'ascensore \`e il segunte:
\begin{itemize}
\item Arriva una prenotazione:
  \begin{itemize}
  \item se \`e libero va al piano della prenotazione
  \item se \`e in movimento la prenotazione viene ignorata
  \end{itemize}
\item Un utente sale sull'ascensore ed effettua una prenotazione;
  questa non pu\`o essere annullata.
\end{itemize}
Due dati fondamentali sono:
\begin{itemize}
\item $\bar{c}$: piano corrispondente alla chiamata
\item $\pi$: piano in cui si trova l'ascensore
\end{itemize}
Questa \`e la descrizione dei posti e delle transizioni:
\begin{itemize}
\item $P_1$: Ascensore libero e fermo
\item $P_2$: Sceltra tra salita e discesa
\item $P_3$: Ascensore in salita
\item $P_4$: Ascensore in discesa
\item $t_1$: chiamata o prenotazione
\item $t_2$: chiamata in salita $\bar{c} > \pi$
\item $t_3$: chiamata in discesa $\bar{c} < \pi$
\item $t_4$: l'ascensore arriva ad un nuono piano $\pi = \bar{c}$
\item $t_5$: l'ascensore arriva ad un nuono piano $\pi = \bar{c}$
\item $t_6$: l'ascensore arriva ad un nuono piano, ma $\bar{c} > \pi$
\item $t_7$: l'ascensore arriva ad un nuono piano, ma $\bar{c} < \pi$
\end{itemize}

\subsection{Ascensore complesso}\index{Ascensore complesso}
\input{./tex/ascensoreComplessoPetri}
La figura \ref{fig:ascensoreComplessoPetri} mostra il dettaglio della
salita di una implementazione pi\`u elaborata dell'ascensore. In
questa implementazione assumiamo che sia possibile la prenotazione
anche quando l'ascensore \`e in movimento. Se, per\`o, l'ascensore \`e
in salita si accettano solo prenotazioni per i piani superiori. Se
l'ascensore \`e in discesa si accettano prenotazioni solo per i piani
inferiori. Considerando la figura \ref{fig:ascensoreSemplicePetri}, dobbiamo
sostituire la rete di Petri in figura
\ref{fig:ascensoreComplessoPetri} al posto $P_3$ e alla transizione
$t_6$.

I primi tre elementi da considerare sono:
\begin{itemize}
\item $\eta$: la lista delle chiamate
\item $P_{31}$: l'abilitazione a salire
\item $t_{61}$: mette in parallelo la salita $P_{32}$ e la
  prenotazione in salita $P_{33}$
\end{itemize}

Se durante la salita arriva una nuova chiamata $\neq \bar{c}$ e $>
\pi$, scatta $t_{62}$ ed in $P_{34}$ si ordinano le prenotazioni in un
vettore $\eta$ di elementi crescenti e si assegna $\bar{c} = \eta(1)$.

$t_{64}$ scatta quando $\bar{c} = \pi$ (l'ascensore ha raggiunto il
piano prenotato pi\`u vicino). Partono quindi le operazioni in
parallelo associate a $P_{35}$ e $P_{36}$. $P_{36}$ svolge un lavoro
analogo a $P_{33}$, accettando la prenotazione mentre l'ascensore \`e
fermo a $P_{35}$.

Ultimate le operazioni associate alla fermata, scatta $t_{67}$ ed
attraverso $P_{38}$ si effettua una scelta:
\begin{itemize}
\item Se $\eta$ \`e vuoto scatta $t_4$
\item Se $\eta$ non \`e vuoto ci saranno altre operazioni da servire
  in salita e scatta quindi $t_{68}$.
\end{itemize}

Per la fase di discesa, la rete \`e praticamente la stessa, ma ordinata
in maniera inversa.

\subsection{Carroponte di Petri}
\begin{figure}[!h]
  \begin{center}
    \includegraphics[scale=0.4]{./images/carropontepetri02}
    \caption{Carroponte}\label{fig:carropontePetri02}
  \end{center}
\end{figure} 
\input{./tex/carropontePetri}
La figura \ref{fig:carropontePetri} mostra la rete di Petri di un
carroponte. Il carroponte ha 4 postazioni $P_1$, $P_2$, $P_3$ e
$P_4$; pu\`o scendere, salire, muovere a sinistra e destra. Il
sensore $P_s$ \`e alto quando il carroponte \`e vicino alla 
sinistra di una postazione; il sensore $P_d$ \`e alto quando \`e
vicino alla destra.

\begin{itemize}
\item $P_1$: servo una postazione
\item $P_2$: carroponte libero
\item $P_3$: confronto tra chiamata e posizione (c,p)
\item $P_4$: carroponte si sposta a sinistra
\item $P_5$: carroponte si sposta a destra
\item $P_6$: postazione in cui si trova il carroponte
\item $t_1$: fine servizio
\item $t_2$: ricezione chiamata
\item $t_3$: se $c = p$
\item $t_4$: se $c < p$
\item $t_5$: se $c > p$
\item $t_6$: arriva un segnale $P_d$
\item $t_7$: arriva un segnale $P_s$
\item $t_8$: $c = p$
\item $t_9$: $c = p$
\end{itemize}

\subsection{Attraversamento di un fiume}
\begin{figure}[!h]
  \begin{center}
    \includegraphics[scale=0.4]{./images/attraversamentoFiume01}
    \caption{Attraversamento fiume}\label{fig:attraversamentoFiume01}
  \end{center}
\end{figure} 
I due bambini, indicati con lo ``sticky man'' e le tre guardie,
indicate con i rettangoli, devono attraversare il fiume dalla sponda
$S_A$ a quella $S_B$, figura~\ref{fig:attraversamentoFiume01}, usando
una sola barca. La barca pu\`o portare per ogni viaggio ``uno o due
bambini'' o ``una sola guardia''. Qual \`e la giusta sequenza di
viaggio per raggiungere l'obiettivo?

\begin{itemize}
\item $M(P_1)$ Numero di bambini sulla sponda $S_A$
\item $M(P_2)$ Numero di guardie sulla sponda $S_A$
\item $M(P_3)$ Numero di bambini sulla sponda $S_B$
\item $M(P_4)$ Numero di guardie sulla sponda $S_B$
\item $M(P_5)$ Barca sulla sponda $S_A$
\item $M(P_6)$ Barca sulla sponda $S_B$
\end{itemize}

\begin{itemize}
\item $t_1$ 2 bambini si muovono dalla sponda $S_A$ alla $S_B$ 
\item $t_2$ 1 bambino si muove dalla sponda $S_A$ alla $S_B$ 
\item $t_3$ 1 guardia si muove dalla sponda $S_A$ alla $S_B$ 
\item $t_4$ 2 bambini si muovono dalla sponda $S_B$ alla $S_A$
\item $t_5$ 1 bambino si muove dalla sponda $S_B$ alla $S_A$
\item $t_6$ 1 guardia si muove dalla sponda $S_B$ alla $S_A$
\end{itemize}

La sequenza di scatto si basa sull'idea di utilizzare i bambini come
``autisti'' della barca, per consentire alle guardie di attraversare
il fiume:
\[
\sigma = 1 \; 5\; 3\; 5\; 1 \; 5\; 3\; 5\; 1 \; 5\; 3\; 5\; 1
\]
Il vettore di scatto \`e:
\[
\overline{\sigma^T} = [4\; 0\; 3\; 0\; 6\; 0]
\]

\section{Grafo di raggiungibilit\`a}
\begin{definizione}
  Il grafo di raggiungibilit\`a di una rete marcata $\langle N, M_0
  \rangle$ \`e un grafo in cui ogni nodo corrisponde ad una marcatura
  raggiungibile ed ogni arco corrisponde ad una transizione.
\end{definizione}

Se la rete ha infiniti stati, il grafo di raggiungibilit\`a \`e
infinito. Si avr\`a un grafo di copertura che compatta le marcature
raggiungibili in un insieme finito di marcature, indicato con
$\omega$.
\subsection{Tracciamento del grafo di raggiungibilit\`a}
\begin{enumerate}
\item La marcatura iniziale $M_0$ \`e il primo nodo del grafo, detto
  nodo ``radice'', non etichettato
\item Considerato un nodo $M$ senza etichetta
  \begin{enumerate}
  \item per ogni transizione abilitata
      \begin{enumerate}
      \item si calcoli la marcatura $M' = M + C(\cdot,t)$ raggiunta da
        $M$ allo scatto di $t$
      \item se non esiste gi\`a un nodo $M'$ nel grafo, si aggiunga un
        nodo $M'$
      \item si aggiunga un arco $t$ tra $M$ ed $M'$
      \end{enumerate}
    \item si etichetti il nodo $M$ ``vecchio''
  \end{enumerate}
\item Se esistono nodi senza etichetta si ritorni a 2
\item Si rimuovano tutte le etichette dai nodi
\end{enumerate}
Il passo 2 dell'algoritmo viene eseguito tante volte quante sono le
marcature raggiungibili. 

Nel grafo di raggiungibilit\`a ogni marcatura raggiungibile della rete
compare una sola volta, mentre la transizione compare tante volte
quante sono le marcature che la abilitano. Quindi il grafo di
raggiungibilit\`a contiene tutte (e sole) le marcature raggiungibili e
tutte (e sole) le sequenze di transizioni che possono scattare in una
rete.

\subsection{Albero e grafo di copertura}
Da integrare.

\section{GMEC}
Le {\em Generalized Mutual Exclusion Constraints}\index{GMEC},
o ``vincoli di mutua esclusione generalizzata'', consentono di
descrivere in modo naturale una classe importante di specifiche
statiche, tipiche del controllo di processi composti da pi\`u
sottosistemi concorrenti che accedono in parallelo a un numero
limitato di risorse. 

\subsection{Mutua esclusione e GMEC}
Supponiamo di avere due condizioni logiche $A_1$ e $A_2$. Esse sono in
mutua esclusione se non possono verificarsi entrambe
contemporaneamente.
\[
M(P_1) = 1
\]
\[
M(P_2) = 1
\]
sono le marcature che indicano le condizioni logiche vere,
rispettivamente di $A_1$ e $A_2$. Il vincolo
\begin{equation}\label{eq:mutuaEsclusioneGMEC}
M(p_1) + M(p_2) \leq 1
\end{equation}
rappresenta la specifica che le due condizioni non debbano mai essere
contemporaneamente vere, quindi \`e vietata la marcatura
\[
M(P_1) = M(P_2) = 1
\]
Se la rete ha $m$ posti,
\[
\begin{array}{cccccccc}
  \omega = & [ & 1 & 1 & 0 & ... & 0 & ]^T\\
  M = & [ & M(P_1) & M(P_2) & M(P_3) & ... & M(P_m) & ]^T
\end{array}
\]
dove $\omega_i$ indica il numero di token del posto $i$-simo per cui la
condizione \`e vera, cio\`e ci sar\`a un 1 per ogni posto $P_n$
coivolto nella GMEC. La condizione diventa, quindi,
\[
M(P_1) + M(P_2) = \omega^T M
\]
e considerato che $k = 1$, la \ref{eq:mutuaEsclusioneGMEC} pu\`o anche
scriversi
\begin{equation}
  \omega^T M \leq k
\end{equation}
In generale
\[
\begin{array}{cccccccc}
  w = & [ & w_1 & w_2 & w_3 & ... & w_m & ]^T\\
  w^T M = & [ & w_1\;M(P_1) & w_2\;M(P_2) & w_3\;M(P_3) & ... & w_m\;(P_m) & ]^T
\end{array}
\]
dove $(\omega,k) \in \mathbb{Z}$. In questo modo \`e possibile pesare in
maniera diversa le marcature di posti diversi.

Sia $\langle N, M_0 \rangle$ una rete marcata con $m$ posti. La GMEC
$(\omega,k)$ definisce un insieme di {\em marcature legali}
\[
\mathcal{L}(w,k) = \{ M \in \mathbb{N}^m | w^T M \leq k \}
\]
\subsection{Il job-shop}\index{Job-Shop}
Supponiamo di avere un robot $r$ che carica due macchine $m_1$ ed
$m_2$ che lavorano dei pezzi e li immagazzinano in un deposito $d$. Il
robot $r$ pu\`o caricare una sola macchina per volta. La macchina
$m_1$ pu\`o lavorare pezzi di tipo $A$, con cardinalit\`a 2; la
macchina $m_2$ pu\`o lavorare pezzi di tipo $B$, con cardinalit\`a
1. Dal deposito $d$ si caricano contemporaneamente un pezzo di tipo
$A$ e un pezzo di tipo $B$ per un successivo assemblamento.
\input{./tex/jobShopPetri}
La figura \ref{fig:jobShopPetri} mostra la rete di Petri che descrive
lo scenario di cui sopra. Di seguito il dettaglio dei posti e delle
transizioni:
\begin{itemize}
\item $t_1$: inizio caricamento pezzo su $m_1$
\item $p_1$: caricamento $m_1$ in corso
\item $t_2$: fine caricamento pezzo su $m_1$ e inizio lavorazione su
  $m_1$
\item $p_2$: $m_1$ sta lavorando
\item $t_3$: fine lavorazione $m_1$ e deposito pezzo tipo $A$ in $d$
\item $p_3$: parti di tipo $A$ deposite in $d$
\end{itemize}
Analogamente
\begin{itemize}
\item $t_4$: inizio caricamento pezzo su $m_2$
\item $p_4$: caricamento $m_2$ in corso
\item $t_5$: fine caricamento pezzo su $m_2$ e inizio lavorazione su
  $m_2$
\item $p_5$: $m_2$ sta lavorando
\item $t_6$: fine lavorazione $m_2$ e deposito pezzo tipo $B$ in $d$
\item $p_6$: parti di tipo $B$ deposite in $d$
\end{itemize}
Si conclude con
\begin{itemize}
\item $t_7$: prelievo coppia di parti da $d$
\end{itemize}
Lo scenario si arricchisce di alcuni vincoli che guidano la rete di
Petri:
\begin{itemize}
\item il robot $r$ \`e unico e quindi pu\`o caricare una sola macchina
  per volta. Abbiamo un vincolo di mutua esclusione:
  \[
  M(p_1) + M(p_4) \leq 1
  \]
  e la GMEC $(w_1, k_1)$ \`e:
  \[
  \begin{array}{ccccccccc}
    \omega_1 = & [ & 1 & 0 & 0 & 1 & 0 & 0 & ]^T\\
    k_1 = 1
  \end{array}
  \]
\item le due macchine possono lavorare una sola parte per volta:
  \[
  M(p_2) \leq 1
  \]
  \[
  M(p_5) \leq 1
  \]
  e le GMEC $(\omega_{2a}, k_{2a})$ e $(\omega_{2b}, k_{2b})$ sono:
  \[
  \begin{array}{ccccccccc}
    \omega_{2a} = & [ & 0 & 1 & 0 & 0 & 0 & 0 & ]^T\\
    k_{2a} = 1\\
    w_{2b} = & [ & 0 & 0 & 0 & 0 & 1 & 0 & ]^T\\
    k_{2b} = 1
  \end{array}
  \]
\item il deposito ha una capacit\`a finita $x$. I pezzi di tipo $A$
  occupano 2 postazioni, quelli di tipo $B$ ne occupano 1. Il vincolo
  \`e:
  \[
  2M(p_3) + M(p_6) \leq x
  \]
  e la GMEC $(\omega_3, k_3)$ \`e:
  \[
  \begin{array}{ccccccccc}
    w_1 = & [ & 0 & 0 & 2 & 0 & 0 & 1 & ]^T\\
    k_1 = x
  \end{array}
  \]
\item l'eccedenza di pezzi di un tipo rispetto ad un altro non deve
  mai superare le $y$ unit\`a. Il vincolo \`e:
  \[
  |M(p_3) - M(p_6)| \leq y
  \]
  ma \`e non lineare, per via del modulo. In questi caso, il vincolo
  va riscritto come un sistema di vincoli lineari:
  \[
  \left \{
  \begin{array}{l}
  M(p_3) - M(p_6) \leq y\\
  M(p_6) - M(p_3) \leq y\\
  \end{array}
  \right .
  \]
  e le GMEC $(\omega_{4a}, k_{4a})$ e $(\omega_{4b}, k_{4b})$ sono:
  \[
  \begin{array}{ccccccccc}
    w_{4a} = & [ & 0 & 0 & 1 & 0 & 0 & -1 & ]^T\\
    k_{4a} = y\\
    w_{4b} = & [ & 0 & 0 & -1 & 0 & 0 & 1 & ]^T\\
    k_{4b} = y
  \end{array}
  \]
  Questo ultimo vincolo \`e detto {\em vincolo di
    equit\`a}\index{Vincolo di equit\`a}. \`E usato
  quando si richiede che diversi sottoprocessi non debbano
  monopolizzare l'uso di una risorsa ma debbano, al contrario,
  spartirsela secondo oppurtune regole.
\end{itemize}

\subsection{GMEC multipla}
Nell'esempio del job-shop, si desiderava imporre ad un processo pi\`u
GMEC $(\omega_i, k_i)$ con $i = 1,\;...,\;q$. \`E possibile raccogliere
queste GMEC in una unica GMEC multipla $(\Omega, k)$ dove 

\[
\begin{array}{cccccccc}
  W = & [ & w_1 & w_2 & w_3 & ... & w_q & ]\\
\end{array}
\]
dove $W$ \`e una matrice $[m \times q]$ le cui colonne sono i vettori
$w$ che definiscono le singole GMEC e
\[
\begin{array}{cccccccc}
  k = & [ & k_1 & k_2 & k_3 & ... & k_q & ]^T\\
\end{array}
\]
\`e un vettore $[q \times 1]$ che ha per elementi gli scalari $k_i$
delle singole GMEC.
L'insieme delle marcature legali per questa GMEC \`e:
\[
\begin{array}{ccc}
\mathcal{L}(W,k) & = & \{ M \in \mathbb{N}^m | W^T M \leq k\}\\
 & = & \{ M \in \mathbb{N}^m | w_1^T M \leq k_1, w_2^T M \leq k_2,
..., w_q^T M \leq k_q \}\\
 & = & \mathcal{L} (w_1, k_1) \cap \mathcal{L} (w_2, k_2) \cap
... \cap \mathcal{L} (w_q, k_q)
\end{array}
\]
Una marcatura \`e legame per la GMEC multipla $(W,k)$ se \`e legale per ogni
singola GMEC $(w_i, k_i)$.

\section{Posti monitor}
I posti monitor controllano che le specifiche non vengano
violate. La rete in esempio si trova in una marcatura legale $M$ e lo
scatto della transizioni $t$ porta in una marcatura $M' = M + C(\cdot,
t)$. Il supervisore (posto monitor) dovr\`a permettere lo scatto di $t$
se $M'$ \`e legale o impedire lo scatto di $t$ se $M'$ \`e illegale.

Considerata una GMEC $(\omega,k)$, si definisce {\em monitor}
corrispondente a $(\omega,k)$ il nuovo posto $p_s$ che ha per matrice di
incidenza il vettore riga $[1 \times n]$:
\[
\begin{array}{cccccc}
  C_s = & [ & C_s(t_1) & ... & C_s(t_n) & ]^T = -\omega^T C\\
\end{array}
\]
e marcatura iniziale
\[
M_0(p_s) = k - \omega^T M_0
\]

Con riferimento al job-shop, realizziamo i posti monitor. Per
calcolare la matrice di incidenza del posto monitor $p_{s1}$
consideriamo la matrice di incidenza $C$ della rete di Petri del
job-shop:
\[
C =
\begin{array}{c}
  P_1\\
  P_2\\
  P_3\\
  P_4\\
  P_5\\
  P_6
\end{array}
\begin{array}{cc}
  \\
 \begin{bmatrix}
   1 & -1 & 0 & 0 & 0 & 0 & 0\\
   0 & 1 & -1 & 0 & 0 & 0 & 0\\
   0 & 0 & 1 & 0 & 0 & 0 & -1\\
   0 & 0 & 0 & 1 & -1 & 0 & 0\\
   0 & 0 & 0 & 0 & 1 & -1 & 0\\
   0 & 0 & 0 & 0 & 0 & 1 & 1
 \end{bmatrix}\\
  t_1\;\;\;t_2\;\;\;t_3\;\;\;t_4\;\;\;t_5\;\;\;t_6\;\;\;t_7
\end{array}
\]
la marcatura iniziale $M_0$:
\[
\begin{array}{ccccccccc}
  M_0 = & [ & 0 & 0 & 0 & 0 & 0 & 0 &]^T
\end{array}
\]
ed il vettore della GMEC:
\[
\begin{array}{ccccccccc}
  \omega_1 = & [ & 1 & 0 & 0 & 1 & 0 & 0 & ]^T\\
\end{array}
\]
A questo punto sfruttiamo la definizione di ``monitor'' e la sua
matrice di incidenza:
\begin{equation}\label{eq:matriceIncidenzaMonitor}
C_s = -w^T C
\end{equation}
\[
\begin{array}{ccccccccc}
  -w_1 = & [ & -1 & 0 & 0 & -1 & 0 & 0 & ]^T\\
\end{array}
\]
Il prodotto riga $\times$ colonna tra la riga $-w_1$ e le colonne
della matrice di incidenza $C$, produce un vettore riga $C_{s1}$ pari
a:
\[
\begin{array}{cccccccccc}
  C_{s1} = -\omega_1^T C= & [ & -1 & 1 & 0 & -1 & 1 & 0 & 0 &]\\
\end{array}
\]
cio\`e tale monitor ha due archi pre (verso $t_1$ e $t_4$) e due archi
post (da $t_2$ e da $t_5$). La marcatura inizale del posto monitor
\`e calcolata come:
\begin{equation}\label{eq:marcaturaInizialeMonitor}
M_0(p_s) = k -\omega^TM_0
\end{equation}
Nel nostro caso
\[
M_0(p_{s1}) = k_1 - \omega_1^T M_0 = 1 - 0 = 1
\]
Bisogner\`a iterare il procedimento e calcolare gli altri posti
monitor per le rispettive GMEC.
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\chapter{Reti di Petri temporizzate}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\section{Introduzione}
Le reti di Petri temporizzate sono un ambiente omogeneo per la
modellazione, il progetto e l'analisi delle prestazioni dei DES.

Il concetto principale delle reti di Petri temporizzate \`e la
possibilit\`a di associare delle variabili temporali (tempi di
ritardo) ai posti, alle transizioni, agli archi ed alle marcature che
costituiscono una rete di Petri.

Nel caso si voglia associare la temporizzazione alle transizioni,
abbiamo due tipi di approcci: atomico e ``a tre fasi''.
\section{Reti di Petri temporizzate deterministiche}
Nel nostro studio, ci concentreremo sulle reti di Petri temporizzate
di tipo deterministico.

Vanno comunque accennate le reti di Petri Temporizzate Stocastiche: ad
una transizione \`e associato un ritardo specificato da una variabile
aleatoria con funzione di distribuzione di probabilit\`a nota.

\begin{definizione}\label{def:reteDiPetriTemporizzataDeterministica}
Una rete di Petri temporizzata \`e deterministica se ad essa \`e
associato un ritardo deterministico $\theta_i$; tale tempo viene
scelto {\em costante}, talvolta {\em variabile} secondo una sequenza
$\{ \theta_{i,1},\theta_{i,2},\theta_{i,3}, ... \}$ di tempi di ritardo noti
a priori, raramente funzione della marcatura.
\end{definizione}

Le reti di Petri Temporizzate Deterministiche si basano sul concetto
di {\em memoria di abilitazione}\index{Memoria di abilitazione}.
\begin{definizione}
Una transizione $t_i$ si dice a ``memoria di abilitazione'' se la
transizione $t_i$ ha memoria solo dell'attuale abilitazione e potr\`a
scattare solo dopo un ritardo pari a $\theta_i$ dall'istante della sua
abilitazione.
\end{definizione}
Lo scatto \`e atomico, viene cio\`e considetato un'operazione
indivisibile e ad ogni transizione viene associato un ritardo che
corrisponde al tempo che deve trascorrere tra la sua abilitazione e il
conseguente scatto. Se al termine del ritardo la condizione di
abilitazione continua a sussistere, la transizione scatta
effettivamente. 

Secondo lo schema dello scatto atomico, due transizioni abilitate
contemporaneamente e in conflitto tra loro, possono risolvere il
conflitto grazie al ritardo: la transizione col ritardo minore scatta
per prima.

Nello scatto in tre fasi, i token vengono prelevati dai posti di
ingresso, scorre il tempo e, infine, i token vengono depositati nei
posti d'uscita. 

\begin{definizione}
  Una rete di Petri temporizzata deterministica \`e caratterizzata
  dalla struttura algebrica
  \[
  N_d = (N, \Theta)
  \]
  dove
  \begin{itemize}
  \item $N = (P,T,Pre,Post)$
  \item $\Theta = \{ \Theta_i\; : \; t_i \in T\}$
    dove
    \begin{itemize} 
    \item[*] $\Theta_i = \{\theta_{i,1},\theta_{i,2},... \}$
    \item[*] $t_i \in T$
    \item[*] $\theta_{i,k} \in \mathbb{R_+} \cup \{0\}$
    \item[*] $k \in \mathbb{N_+}$
    \end{itemize}
  \end{itemize}
\end{definizione}
$\Theta$ \`e una struttura di orologio (o di temporizzazione)
deterministica: affinch\`e la transizione possa scattare, deve
trascorrere un tempo $\theta_i$ dall'istante in cui $t_i$ viene
abilitata. Per le RPT deterministiche, ricordiamo che, $\theta_i$ \`e
costante. Nel caso di ritardi costanti, $\theta_{i,k}$ \`e
semplificato in $\theta_i, \forall k \in \mathbb{N_+}$.

Una Rete di Petri Temporizzata Deterministica (RPTD) $N_d$, con una
marcatura $M_0$ all'istante di tempo iniziale $\tau_0$, \`e detta RPTD
marcata $\langle N_d, M_0 \rangle$.
\subsection{Evoluzione dinamica}
Lo stato di una RPTD \`e determinato dalla marcatura e dal valore
degli orologi associati alle transitioni.
\begin{definizione}
  Una transizione $t_i$ \`e detta abilitata da una marcatura $M_j$ se
  ogni posto $p \in P$ della rete contiene un numero di token pari o
  superiore a $Pre(p,t_i)$, cio\`e se $M_j \geq Pre(\cdot, t_i)$.
\end{definizione}
\begin{definizione}\index{Grado di
    abilitazione}\label{def:gradoDiAbilitazion}
  Il grado di abilitazione di una transizione $t_i$ abilitata da una
  marcatura $M_j$ \`e il pi\`u grande numero intero $k$ tale che $M_j
  \geq Pre(\cdot, t_i)$. Il grado di abilitazione di $t_i$ da $M_j$
  viene indicato con $\alpha_i(j)$. In ogni istante di tempo ogni
  transizione $t_i$ ha associato un numero di orologi pari al suo
  grado di abilitazione corrente.
\end{definizione}
\input{./tex/rptdEsempi}
La figura \ref{fig:retiPetriTemporizzate} mostra due esempi elementari
di reti temporizzate. La figura \ref{fig:gradoAbilitazioneInfinito}
mostra una transizione con grado di abilitazione infinito. La figura
\ref{fig:gradoAbilitazione2} mostra una transizione con grado di
abilitazione 2. Ogni transizione ha associato un numero di orologi
pari al suo grado di abilitazione corrente. Ogni volta che la
marcatura cambia, cio\`e allo scatto della transizione, cambia anche
il grado di abilitazione e cambia il numero di orologi.

Considerata una transizione $t_i$ abilitata, il tempo che deve passare
prima del prossimo scatto di $t_i$ \`e determinato dal pi\`u piccolo
orologio $o_i$ associato a $t_i$. Se il valore minimo di orologi \`e
maggiore di uno, quando la transizione sar\`a pronta a scattare,
scatter\`a $n$ volte quanti sono gli orologi associati a $t_i$.

\subsubsection{Esempi}
\begin{figure}[!hbp]
  \begin{center}
    \includegraphics[scale=0.5]{./images/petriEsempio01.png}
    \caption{Esempio RPTD}
    \label{fig:petriEsempio01}
  \end{center}
\end{figure}
La figura \ref{fig:petriEsempio01} mostra l'evoluzione della rete
\ref{fig:gradoAbilitazione2}. All'istante $\tau_0 = 0$, alla
transizione $t_1$ \`e associata una coppia di orologi $\vartheta_{1,1}
= 2$ e $\vartheta_{1,2} = 2$, dato il grado di abilitazione
$\alpha_1(0) = 2$.

All'istante $\tau_1 = \tau_0 + \vartheta_1$, dopo cio\`e un ritardo 2,
entrambi gli orologi si annullano, la transizione scatta due volte e i
due orologi si resettano nuovamente a $\vartheta_1 = 2$.

\begin{figure}[!h]
  \begin{center}
    \includegraphics[scale=0.4]{./images/rptd-serventiinfiniti.png}
    \caption{Esempio RPTD serventi infiniti}
    \label{fig:rptd-serventiinfiniti}
  \end{center}
\end{figure}
La figura~\ref{fig:rptd-serventiinfiniti} mostra un esempio di
serventi infiniti. Questo particolare tipo di {\em semantica di
  servente} associata alla RPTD si basa sul concetto che ogni
transizione rappresenti un'operazione che pu\`o essere eseguita da un
numero infinito di unit\`a operative che lavorano in
parallelo. Nell'esempio, la transizione $t_1$ scatter\`a tre volte
all'istante $\theta_1$ perch\`e le unit\`a operative possono
utilizzare (servire) tutti i token contemporaneamente.

\subsection{Evoluzione temporale di un RPTD}
Consideriamo la RPTD all'istante $\tau_j$ con la marcatura $M_j$ e i
valori degli orologi associati alle transitioni. La rete evolve nel
seguente modo:
\begin{enumerate}
\item Individuare il minimo orologio $o^*$ associato ad una delle
  transizioni abilitate nella marcatura $M_j$. Nel caso di orologi
  uguali associati a transizioni diverse, l'ordine di scatto delle
  transizioni pu\`o essere stabilito secondo due politiche:
  \begin{itemize}
  \item Deterministica, cio\`e si assegna una priorit\`a di scatto
    alle transizioni; 
  \item Non-deterministica, cio\`e si assegna una probabilit\`a di
    scatto alle transizioni.
  \end{itemize}
  
  Se in una marcatura
  $M_j$ il valore minimo di orologio $o_i$ di una transizione $t_i$
  corrisponde a pi\`u orologi, esempio $k$ orologi, ci\`o significa
  che se la transizione sar\`a la prossima a scattare, essa scatter\`a
  $k$ volte contemporaneamente. 
\item Il tempo avanza fino all'istante $\tau_j + o^*$ e la transizione
  $t^*$ scatta, portando la marcatura $M_j$ a $M_j + 1 = M_j +
  C(\cdot, t)$;
\item Raggiunta $M_j + 1$, $o^*$ viene scartato.
  \begin{itemize}
  \item Se il grado di abilitazione $\alpha(j + 1)$ nella marcatura
    raggiunta $M_j + 1$ \`e inferiore al grado di abilitazione
    $\alpha_i(j)$ che $t_i$ aveva nella marcatura precedente $M_j$, allora
    devono essere scartati $[\alpha_i(j) - \alpha(j + 1)]$ orologi
    associati alla transizione  $t_i$, che risultano evidentemente in
    esubero: vengono selezionati ed eliminati dall'insieme degli
    orologi gli $[\alpha_i(j)~-~\alpha(j + 1)]$ che hanno i valori
    pi\`u alti; 
  \item Se $\alpha_i(j + 1) > \alpha_i(j)$, $[\alpha_i(j + 1) -
    \alpha_i(j)]$ orologi devono essere associati a $t_i$ ed impostati
    ai valori specificati dalla struttura di temporizzazione $\Theta$
  \end{itemize}
\item Ripetere dal passo 1 ponendo $j + 1 \rightarrow j$.
\end{enumerate}
\subsubsection{Esempi}
La figura~\ref{fig:rptd-evoluzione01} mosta l'evoluzione temporale
della rete in figura~\ref{fig:rptd-evoluzione00}. La transizione $t_1$ (con
ritardo $\theta_1 = 2$) ha nell'istante iniziale $\tau_0 = 0$ grado di
abilitazione $\alpha_1(0)$ pari a 2; ci sono, quindi, inizialmente due
orologi attivi, $\theta_1$ e $\theta_2$, associati alla
transizione. Dopo un ritardo pari a 2, cio\`e all'istante $\tau_1 =
\tau_0 + \theta_1$, entrambi gli orologi si annullano, la transizione
scatta due volte e i due orologi vengono impostati nuovamente al
valore $\theta_1 = 2$. L'evoluzione della rete procede in base
all'algoritmo mostrato in precedenza.
\begin{figure}[!h]
  \begin{center}
    \includegraphics[scale=0.4]{./images/rptd-evoluzione00.png}
    \caption{Esempio RPTD}
    \label{fig:rptd-evoluzione00}
  \end{center}
\end{figure}
\begin{figure}[!h]
  \begin{center}
    \includegraphics[scale=0.4]{./images/rptd-evoluzione01.png}
    \caption{Esempio evoluzione temporale RPTD}
    \label{fig:rptd-evoluzione01}
  \end{center}
\end{figure}
\begin{figure}[!h]
  \begin{center}
    \includegraphics[scale=0.4]{./images/rptd-evoluzione04.png}
    \caption{Esempio evoluzione temporale RPTD}
    \label{fig:rptd-evoluzione04}
  \end{center}
\end{figure}
\begin{figure}[!h]
  \begin{center}
    \includegraphics[scale=0.4]{./images/rptd-evoluzione05.png}
    \caption{Descrizione RPTD}
    \label{fig:rptd-evoluzione05}
  \end{center}
\end{figure}


Una linea di produzione \`e composta da due macchine $m_1$ e $m_2$,
due bracci robotici $r_1$ e $r_2$ e due nastri trasportatori. Ogni
macchina usa in esclusiva un braccio robotico che esegue le operazioni
di carico e scarico dei pezzi che la macchina deve lavorare. Uno dei
nastri trasportatori \`e impiegato per trasportare al massimo due
pezzi alla volta, mentre l'altro nastro trasporta pallet vuoti, cio\`e
pronti per caricare un nuovo pezzo. I pallet che circolano nel sistema
sono 3.

Ogni pezzo viene lavorato secondo la stessa sequenza prima da $m_1$ e
poi da $m_2$, con rispettivi tempi di lavorazione di 10 e 20
unit\`a. Le operazioni di carico e scarico richiedono 1 unit\`a di
tempo, mentre il tempo di trasporto sui nastri \`e da considerarsi
trascurabile.

Il modello via RPTD del sistema produttivo \`e descritto in
figura~\ref{fig:rptd-evoluzione04} e nella
tabella~\ref{fig:rptd-evoluzione05}. Nella marcatura iniziale $M_0 = [3
\; 0 \; 0 \; 0 \; 0 \; 0\; 1 \; 2\; 1\; 1\; 1]^T$ la transizione $t_1$
\`e abilitata e comincia il suo scatto, che termina dopo un ritardo di
un'unit\`a di tempo; le rete ha raggiunto cos\`i la marcatura $M_1 = [2
  \;1 \;0 \;0 \;0 \;0 \;0 \;2 \;1 \;0 \;1]^T$, in cui la transizione
$t_2$ \`e abilitata e comincia a scattare. Lo scatto di $t_2$ termina
dopo un ritardo di 10 unit\`a di tempo, portando la rete alla nuova
marcatura $M_2 = [2 \;0 \;1 \;0 \;0 \;0 \;0 \;2 \;1 \;0
  \;1]^T$. L'evoluzione della rete va avanti seguendo la procedura
illustratra.


% MODELLI RICAVATI DALLA RISPOSTA AL GRADINO
\chapter{Modelli ricavati dalla risposta al gradino}
\section{Metodo della tangente}
\begin{figure}[!hbp]
  \center
  \begin{tikzpicture}[node distance=2.5cm,auto,>=latex']
    \node [int] (a) {$G(s)$};
    \node (b) [left of=a,node distance=2cm, coordinate] {a};
    \node [coordinate] (end) [right of=a, node distance=2cm]{};
    \path[->] (b) edge node {$u$} (a);
    \path[->] (a) edge node {$y$} (end);
  \end{tikzpicture}
  \caption{Schema a blocchi}
  \label{fig:schemaABlocchi}
\end{figure}
Si assume che il sistema sia modellabile con una funzione di
trasferimento del primo ordine del tipo:
\[
G(s) = \dfrac{\mu}{1 + sT} \cdot e^{-s\tau}
\]
\begin{figure}[!hbp]
  \begin{center}
    \includegraphics[scale=0.5]{./figures/metodoTangente01.png}
    \caption{Risposta al gradino di un sistema del primo ordine}
    \label{fig:rispostaGradino1Ordine}
  \end{center}
\end{figure}
\begin{figure}[!hbp]
  \begin{center}
    \includegraphics[scale=0.5]{./figures/metodoTangente02.png}
    \caption{Risposta al gradino di un sistema del primo ordine}
    \label{fig:rispostaGradino1Ordineyr}
  \end{center}
\end{figure}
Bisogna determinare i parametri della funzione di trasferimento:
\begin{itemize}
\item $\mu$ il guadagno statico
\item $T$ la costante di tempo
\item $\tau$ il ritardo
\end{itemize}
Viene considerata la risposta sperimentale (reale) del sistema con
ingresso a scalino:
\[
u(t) = \bar{u} \cdot 1(t)
\]

Supponiamo che i campioni dell'uscita siano determinati con un periodo
di campionamento $\Delta$, cio\`e un campione ogni $\Delta$
secondi. Il periodo di campionamento va scelto abbastanza piccolo
rispetto alla costante di tempo; diversamente, per\`o, un periodo di
campionamento troppo piccolo porterebbe ad un inutile sovraccarico dei
dati da memorizzare: sovracampionamento. Gli istanti di tempo di
campionamento saranno: 
\[
t_1 = \Delta \;\; t_2 = 2\Delta \;\; t_3 = 3\Delta \;\; ... \;\; t_k =
k\Delta \;\; ... \;\; t_N = N\Delta
\]
Il numero di campionamento $N$ va scelto in modo da ``raccogliere''
l'evoluzione dinamica del sistema, ma senza memorizzare campioni
``inutili'', una volta esautito il transitorio e si \`e a regime. Ad
esempio, si pu\`o scegliere:
\[
N : |t_N - 2 t_a| < \Delta
\]
cio\`e scegliere $N$ tale che $t_N$ sia circa pari al doppio del tempo
di assestamento $t_a$. I campioni dell'uscita saranno:
\[
y_1 = y(t_1) = y (\Delta) \;\; ... \;\; y_k = y(t_k) = y(k\Delta) \;\;
... \;\; y_N = y(t_N) = y(N\Delta)
\]
Per trovare il guadagno statico, si pu\`o assumere:
\[
y_{\infty} = \lim_{t \to \infty} y(t) \simeq y(N\Delta)
\]
e quindi fissare
\[
\mu = \dfrac{y(N\Delta)}{\bar{u}}
\]
essendo $\bar{u}$ una grandezza nota. Per calcolare i parametri $\tau$
e $T$, dobbiamo calcolare:
\begin{enumerate}[label=\emph{\alph*})]
\item la derivata di $y$, che indicheremo con $dy$;
\item il valore del massimo della derivata $(dy_{max})$ e il
  corrispondente istante di tempo $k_{max} \cdot \Delta$;
\item il valore di $y(k_{max} \cdot \Delta)$;
\item la retta $y_r(t)$ che passa per $(k_{max}\Delta,
  y(k_{max}\Delta))$ e ha pendenza $dy_{max}$;
\item i punti di intersezione della retta $y_r(t)$ con l'asse dei
  tempi $(y = 0)$ e con il valore a regime $(y = \mu \bar{u})$, come
  mostrato in figura \ref{fig:rispostaGradino1Ordineyr}.
\end{enumerate}
\begin{enumerate}[label=\underline{\emph{Punto \alph*}}]
\item La derivata di $y$ si pu\`o calcolare col medoto del rapporto
  incrementale. Con un algoritmo in stile Matlab:
  \[
  \begin{array}{l}
    dy(1) = y(1)/\Delta;\\
    for\;\; k = 2 : N\\
    \;\;\; dy(k) = (y(k) - y(k-1))/\Delta;\\
    end  
  \end{array}
  \]
\item Per calcolare il massimo, possiamo usare il comando Matlab:
  \[
  [kmax, dymax] = max(dy);
  \]
\item Il valore di $y$ nell'istante $k_{max}\cdot \Delta$ \`e dato da
  $y(k_{max})$
\item L'equazione della retta \`e
  \[
  y_r(t) = \alpha + \beta t
  \]
  Il parametro $\beta$ \`e la pendenza della retta e quindi
  \[
  \beta = dy_{max}
  \]
  Inoltre la retta deve passare per il punto $(k_{max}\cdot \Delta,
  y(k_{max}))$
  \[
   y(k_{max}) = \alpha + dy_{max} \cdot k_{max} \cdot \Delta
  \]
  da cui
  \[
  \alpha  = y(k_{max}) - dy_{max} \cdot k_{max} \cdot \Delta
  \]
\item Per trovare $\tau$ basta imporre
  \[
  y_r(\tau) = 0 \Rightarrow \alpha + \beta \tau = 0 \Rightarrow \tau = -\dfrac{\alpha}{\beta}
  \]
  da cui sostituendo i valori di $\alpha$ e $\beta$ si ha
  \[
  \tau = k_{max} \cdot \Delta - \dfrac{y(k_{max})}{dy_{max}}
  \]
  Per trovare $T$ si pu\`o imporre
  \[
  y_r(\tau + T) = y(N\Delta) \Rightarrow \alpha + \beta(\tau + T) = y(N\Delta)
  \]
  \[
  \Rightarrow \tau + T = \dfrac{y(N\Delta) - \alpha}{\beta} =
  \dfrac{y(N\Delta)}{\beta} - \dfrac{\alpha}{\beta}
  \]
  e considerato che $\tau = - \dfrac{\alpha}{\beta}$ si ha:
  \[
  T = \dfrac{y(N\Delta)}{dy_{max}}
\  \]
\end{enumerate}
\section{Metodo delle aree}
Consideriamo
\[
G(s) = \dfrac{\mu}{1 + sT}\cdot e^{-s \tau}
\]
con $\tau$ pari al ritardo, $\mu$ pari al guadagno statico, $T$ pari
alla costante di tempo.
\begin{figure}[!h]
  \begin{center}
    \includegraphics[scale=0.4]{./images/metodoDelleAree}
    \caption{Metodo delle aree}
    \label{fig:metodoDelleAree}
  \end{center}
\end{figure}
\[
\overline{y} = \mu \overline{u}
\]
\[
S_1 = \mu \overline{u} \tau + \int\limits_{0}^{+ \infty} \mu
\overline{u}\cdot e^{-\frac{t}{T}} dt =
\]
\[
= \mu\overline{u}\tau - \mu
\overline{u} T \cdot \left[e^{-\frac{t}{T}}\right]^{\infty}_0 =  \mu
\overline{u}\cdot(\tau + T) = \overline{y}\cdot(\tau + T)
\]
quindi
\[
\tau + T = \dfrac{S_1}{\overline{y}} = \dfrac{S_1}{\mu \overline{u}}
\]
\[
S_2 = \int\limits_{0}^{T} \mu \overline{u} (1 - e^{- \frac{t}{T}}) dt
= \mu \overline{u} T + \mu \overline{u} T \cdot
\left[e^{-\frac{t}{T}}\right]^{T}_0 = \dfrac{\mu \overline{u} T}{e} =
\dfrac{\overline{y} T}{e} 
\]
quindi
\[
T = \dfrac{e S_2}{\overline{y}} = \dfrac{e S_2}{\mu \overline{u}}
\]
\chapter{Modelli strutturali sistemi del primo ordine}
\begin{figure}[!hbp]
  \begin{center}
    \includegraphics[scale=0.5]{./figures/modelliStrutturali01.png}
    \caption{Circuito RC}
    \label{fig:circuitoRC}
  \end{center}
\end{figure}
Consideriamo il circuito elettronico in figura
\ref{fig:circuitoRC}. Applicando i principi di Kirchhoff si ha:
\begin{equation}\label{eq:modelliStrutturali01}
C \dfrac{dy}{dt} = \dfrac{1}{R} (u_1 - y) - u_2
\end{equation}
Applicando la trasformata di Laplace all'equazione
\ref{eq:modelliStrutturali01} si ha:
\[
(sC + \dfrac{1}{R}) Y(s) = \dfrac{1}{R} v_1(s) - v_2(s)
\]
da cui:
\begin{equation}\label{eq:modelliStrutturali02}
  Y(s) = \dfrac{1}{1 + sRC}v_1(s) - \dfrac{R}{1 + sRC} v_2(s)
\end{equation}
Le funzioni di trasferimento tra $u_1$ (ingresso) ed $y$ (uscita) e
tra $u_2$ e $y$ sono entrambe del primo ordine ed esprimibili nella
forma:
\begin{equation}\label{eq:modelliStrutturali03}
  G(s) = \dfrac{\mu}{1 + sT} = \dfrac{\dfrac{\mu}{T}}{s + \dfrac{1}{T}} =
    \dfrac{\rho}{s + p_1}
\end{equation}
con $G(0) = \mu$, guadagno statico.
\begin{figure}
  \center
  \begin{tikzpicture}[node distance=2cm,auto,>=latex']

    \node [pallino, label=below left:$+$] (a) {};
    \node [int] (R) [above of=a] {$R$};
    \node (b) [left of=a,node distance=2cm, coordinate] {a};
    \node (d) [left of=R,node distance=2cm, coordinate] {R};
    \node [int] (c) [right of=a] {$\dfrac{1}{1+ sRC}$};
    \node [coordinate] (end) [right of=c, node distance=2cm]{};
    
    \path[->] (b) edge node {$u_1$} (a);
    \path[->] (d) edge node {$u_2$} (R);
    \path[->] (a) edge node {} (c);
    \path[->] (R) edge node {$-$} (a);
    \draw[->] (c) edge node {$y$} (end) ;
  \end{tikzpicture}
  \caption{}
  \label{fig:modelliStrutturali01}
\end{figure}
Un possibile schema a blocchi
associato all'equazione \ref{eq:modelliStrutturali02} \`e mostrato in
figura \ref{fig:modelliStrutturali01}.

Supponiamo che $u_2 = 0$ e $u_1 = \bar{u} \cdot 1(t)$ (un gradino di
ampiezza unitaria) usando la funzione di trasferimento avremo:
\begin{equation}\label{eq:modelliStrutturali04}
  Y(s) = G(s) U_1(s) = \dfrac{\mu}{1 + s T} - \dfrac{\bar{u}}{s}
\end{equation}
Scomponendo in fratti semplici:
\[
Y(s) = \mu \bar{u} \dfrac{1}{s(1 + sT)} = \mu \bar{u} \left [ \dfrac{1}{s}
- \dfrac{T}{1 - ST} \right] = \mu \bar{u} \left [ \dfrac{1}{s} -
  \dfrac{1}{s + \frac{1}{T}} \right ]
\]
Antitrasformando si ha:
\begin{equation}\label{eq:modelliStrutturali05}
  y(t) = \mu \bar{u} (1 - e^{-\frac{t}{T}}) \; 1(t)
\end{equation}
dove $T$ \`e la costante di tempo.
\begin{figure}[!hbp]
  \begin{center}
    \includegraphics[scale=0.5]{./figures/modelliStrutturali03.png}
    \caption{Risposta al gradino}
    \label{fig:modelliStrutturali03}
  \end{center}
\end{figure}
La figura \ref{fig:modelliStrutturali03} mostra che
\begin{equation}\label{eq:modelliStrutturali06}
  \mu\bar{u} = T \cdot tan\alpha
\end{equation}
Infatti
\begin{equation}\label{eq:modelliStrutturali07}
  tan \alpha = \left . \dfrac{dy}{dt} \right | = \mu \bar{u} \left . \left [ +
    ( - \dfrac{1}{T} e^{-\frac{t}{T}})\right] \right |_{t = 0} = \mu
  \bar{u} \dfrac{1}{T}
\end{equation}
cio\`e l'equazione \ref{eq:modelliStrutturali07} coincide con
l'equazione \ref{eq:modelliStrutturali06}.

\begin{figure}[!h]
  \begin{center}
    \includegraphics[scale=0.5]{./figures/modelliStrutturali04.png}
    \caption{Tempo di assestamento}
    \label{fig:modelliStrutturali04}
  \end{center}
\end{figure}
Il tempo di assestamento all'$1\%$ \`e l'instante di tempo in cui la
risposta al gradino $y(t)$ diventa prossima al valore di regime
$\bar{y} = \mu \bar{u}$ a meno dell'$1\%$ del valore di regime stesso
come mostrato in figura \ref{fig:modelliStrutturali04}.
\[
\left . \bar{y} - y(t) \right |_{t = t_a} = 0.01\bar{y}
\]
\[
\bar{y} - (\bar{y} - \bar{y} e^{-\frac{t_a}{T}}) = 0.01\bar{y}
\Rightarrow \bar{y} e^{-\frac{t_a}{T}} = 0.01\bar{y}
\]
\[
\Rightarrow e^{-\frac{t_a}{T}} = 0.01 \Rightarrow  - t_a = T \cdot ln
0.01 \Rightarrow t_a \simeq 4.6 T
\]
\chapter{Controllo ad anello aperto}
Supponiamo di voler individuare un controllore $R(s)$ in modo che
l'uscita $y$ insegua nel miglior modo possibile l'uscita desiderata
(segnale di riferimento) $w$.
\begin{figure}[!hbp]
  \center
  \begin{tikzpicture}[node distance=2.5cm,auto,>=latex']
    \node [int] (rs) {$R(s)$};
    \node (b) [left of=rs,node distance=2cm, coordinate] {rs};
    \node [int] (gs) [right of=rs] {$G(s)$};
    \node [coordinate] (end) [right of=gs, node distance=2cm]{};

    \path[->] (b) edge node {$w$} (rs);
    \path[->] (rs) edge node {$u$} (gs);
    \path[->] (gs) edge node {$y$} (end);
  \end{tikzpicture}
  \caption{Schema a blocchi}
  \label{fig:controlloACicloAperto01}
\end{figure}
Potremmo scegliere
\begin{equation}\label{eq:controlloACicloAperto01}
  R(s) = \dfrac{1}{G(s)}
\end{equation}
in modo che
\begin{equation}\label{eq:controlloACicloAperto02}
  Y(s) = R(s) G(s) W(s) = \dfrac{1}{G(s)} G(s) W(s) = W(s)
\end{equation}
Per implementare l'equazione \ref{eq:controlloACicloAperto01} dovremmo
conoscere esattamente la $G(s)$. Considerata una incertezza $\Delta
G(s)$, lo schema in figura \ref{fig:controlloACicloAperto01}
diventerebbe come quello in figura \ref{fig:controlloACicloAperto02}
\begin{figure}[!hbp]
  \center
  \begin{tikzpicture}[node distance=2.5cm,auto,>=latex']
    \node [int] (rs) {$R(s)$};
    \node (b) [left of=rs,node distance=2cm, coordinate] {rs};
    \node [int] (gs) [right of=rs] {$G(s) + \Delta G(s)$};
    \node [coordinate] (end) [right of=gs, node distance=2cm]{};

    \path[->] (b) edge node {$w$} (rs);
    \path[->] (rs) edge node {$u$} (gs);
    \path[->] (gs) edge node {$y$} (end);
  \end{tikzpicture}
  \caption{Schema a blocchi}
  \label{fig:controlloACicloAperto02}
\end{figure}
e l'equazione \ref{eq:controlloACicloAperto02} diventerebbe:
\begin{equation}\label{eq:controlloACicloAperto03}
  \begin{array}{l}
  Y(s) = (G(s) + \Delta G(s)) W(s) = (G(s) + \Delta G(s))
  \dfrac{1}{G(s)} W(s) = \\
  = W(s) + \dfrac{\Delta G(s)}{G(s)} W(s) \neq W(s)
  \end{array}
\end{equation}
Quindi l'incertezza sul modello di $G$ si ripercuote direttamente su
una differenza tra $w$ e $y$. Un altro elemento che riduce l'efficacia
della scelta di un controllore ad anello aperto \`e legato alla
presenza di disturbi. Se l'uscita $y$ \`e influenzata da un disturbo,
si ha lo scema a blocci in figura \ref{fig:controlloACicloAperto03}.
\begin{figure}[!hbp]
  \center
  \begin{tikzpicture}[node distance=2.5cm,auto,>=latex']
    \node [int] (1gs) {$\dfrac{1}{G(s)}$};
    \node (w) [left of=1gs,node distance=2cm, coordinate] {1gs};
    \node [int] (gs) [right of=1gs] {$G(s)$};
    \node [pallino] (sommatore) [right of=gs] {$+$};
    \node (d) [above of=sommatore, node distance=2cm, coordinate] {};
    \node [coordinate] (end) [right of=sommatore, node distance=2cm]{};

    \path[->] (w) edge node {$w$} (1gs);
    \path[->] (1gs) edge node {} (gs);
    \path[->] (gs) edge node {} (sommatore);
    \path[->] (d) edge node {$d$} (sommatore);
    \path[->] (sommatore) edge node {$y$} (end);
  \end{tikzpicture}
  \caption{Schema a blocchi}
  \label{fig:controlloACicloAperto03}
\end{figure}
e l'equazione dell'uscita diventa
\begin{equation}\label{eq:controlloACicloAperto05}
  Y(s) = D(s) + G(s) \dfrac{1}{G(s)} W(s) = W(s) + D(s) \neq W(s)
\end{equation}
Anche in questo caso la presenza di disturbi si ripercuote
direttamente su una differenza tra $w$ e $y$.

Infine il controllore mostrato in figura
\ref{fig:controlloACicloAperto01} il pi\`u delle volte non \`e
fisicamente realizzabile, cio\`e la funzione di trasferimento $R(s)$
ha pi\`u zeri che poli. Un modo per intuire il perch\`e una funzione
di trasferimento con pi\`u zeri che poli non sia fisicamente
realizzabile \`e riferirsi ai diagrammi di Bode dei moduli della sua
corrispondente risposta in frequenza. Con un grado relativo
(differenza tra numero di poli e numero di zeri) negativo, si avrebbe:
\[
\lim_{w \to +\infty} |R(j\omega)| = + \infty
\]
e quindi al crescere della frequenza dovremmo essere in grado di
produrre un segnale di controllo sempre pi\`u elevato, il che non \`e
possibile. 

\chapter{Controllo a retroazione}
\section{Schema generale del controllo a retroazione}
\input{./tex/controlloARetroazione}
La figura \ref{fig:controlloARetroazione} mostra lo schema generale di
un controllo a retroazione. In seguito, per semplicit\`a, i blocchi
Controllore, Attuatore e Processo verranno collassati in un unico
blocco $L(s)$ che rappresenza la funzione di trasferimento ad anello
aperto:
\[
L(s) = R(s) A(s) P(s) = R(s) G(s)
\]

\section{Convertitore elettronico DC/DC}
\begin{figure}[!h]
  \begin{center}
    \includegraphics[scale=0.25]{./images/convertitore-dcdc}
    \caption{Circuito Convertitore DC-DC}\label{fig:convertitore-dcdc}
  \end{center}
\end{figure}
La figura \ref{fig:convertitore-dcdc} mostra il circuito RLC che compone un
convertitore elettronico DC/DC. Un convertitore DC-DC \`e un circuito
che converte una sorgente di corrente continua da una tensione a
un'altra. Costituisce una classe di convertitori di potenza. Il
convertitore in figura \`e un convertitore a switch di tipo buck.

I convertitori elettronici a switch DC-DC sono disponibili per
convertire un livello di tensione in un altro. Questi circuiti
tipicamente compiono la conversione applicando tensione continua DC su
un induttore per un periodo di tempo nel quale scorre una corrente
elettrica cos\`i da immagazzinare energia magnetica. Quando viene
tolta la tensione, si trasferisce l'energia immagazzinata come tensione
d'uscita del convertitore in maniera controllata.

Agendo sul rapporto di on/off time, detto anche duty cycle, la
tensione d'uscita rimane regolata anche se la corrente d'uscita cambia.

La presenza dei due interruttori, $S_1$ ed $S_2$, permette di avere un
comportamento periodico della tensione $v$ ai capi dell'interruttore
$S_2$. I due interruttori sono mutuamente esclusivi:
\[
S_1 \neq S_2
\]
Se $S_1$ \`e chiuso, $S_2$ \`e aperto e la tensione $v$ sar\`a pari
alla tensione di alimentazione $V_{dc}$. Viceversa, se $S_1$ \`e aperto, $S_2$
\`e chiuso e la tensione $v$ \`e nulla. Questo comportamento ci
consente di avere in ingresso un'onda quadra di ampiezza massima
$V_{dc}$ e di periodo $T$, come mostrato in
figura~\ref{fig:convertitore-dcdc02}. 
\begin{figure}[!h]
  \begin{center}
    \includegraphics[scale=0.4]{./images/convertitore-dcdc02}
    \caption{Tensione in ingresso al Convertitore
      DC-DC}\label{fig:convertitore-dcdc02} 
  \end{center}
\end{figure}
L'ingresso periodo, nonostante non sia sinusoidale, \`e sufficiente
per poter sfruttare le propriet\`a della serie di
Fourier (\ref{apx:sdf}): un segnale periodo pu\`o essere rappresentato
come la somma di infiniti segnali sinusoidali.
\[
v = \bar{v} + \sum_{n=1}^{\infty} V_n sin(n \omega t + \varphi_n)
\]
\[
y_{\infty}(t) = G(0) \bar{v} + \sum_{n=1}^{\infty} V_n \cdot
|G(j\omega)| \cdot sin(n \omega t + \varphi_{n} + arg(G(j n \omega))
\]
\[
y_m = R_s y \;\;\; y = \dfrac{1}{R_s} y_m
\]
\[
\begin{array}{l}
  \bar{v} = \dfrac{1}{T} \int_0^T v(t) dt \equiv \textrm{valore
    medio}\\
  = \dfrac{1}{T} \left[ \int_0^{\tau} v(t) dt + \int_{\tau}^T v(t) dt
    \right] = V_{dc} \cdot \dfrac{\tau}{T}
\end{array}
\]
con $\dfrac{\tau}{T} = D$: {\em duty cicle}\index{Duty cicle}, che
rappresenta la variabile di controllo e il cui valore varia tra $0$ e
$1$. 
\[
v = D V_{dc} + d_A
\]
con $d_A$ pari al disturbo.
\input{./tex/convertitoreDCDC01}
Valutiamo la funzione di trasferimento tra $v$ ed $y$. Applicando i
principi di Kirchhoff si ha:
\[
\left\{
\begin{array}{l}
  L \dfrac{dx_1}{dt} = - R_1 x_1 - x_2 + v\\
  C \dfrac{dx_2}{dt} = x_1 - \dfrac{1}{R_s + R_2}x_2\\
  y = \dfrac{1}{R_s + R_2}x_2\\
  y_m = R_s y
\end{array}
\right .
\]
La corrente $y$ \`e misurata attraverso una resistenza di {\em
  sensing} $R_s$ e quindi la tensione \`e una possibile misura
indiretta di $y$ (essendo nota $R_s$).
\[
\left\{
\begin{array}{l}
  sLX_1(s) = -R_1 X_1(s) - X_2(s) + V(s)\\
  sCX_2(s) = X_1(s) - \dfrac{1}{R_s + R_2}X_2(s)\\
  Y(S) = \dfrac{1}{R_s + R_2}X_2(s)
\end{array}
\right .
\]
\[
\left\{
\begin{array}{l}
 X_1(s) = \dfrac{1}{R_1 + sL} (V(s) - X_2(s))\\
 X_2(s) = \dfrac{1}{sC + \dfrac{1}{R_s + R_2}} X_1(s)
\end{array}
\right .
\]
\input{./tex/convertitoreDCDC02}
La figura \ref{fig:convertitoreDCDC02} pu\`o essere ripensata
raggruppando i due blocchi in serie
\[
G_1(s) = \dfrac{1}{R_1 + sL}
\]
\[
G_2(s) = \dfrac{1}{sC + \dfrac{1}{R_s + R_2}}
\]
per ottenere cos\`i un'unica funzione di trasferimento
\[
\tilde{L}(s) = G_1(s) G_2(s)
\]
\[
x_2 = \tilde{L}(V - x_2) = (1 + \tilde{L}) x_2 = \tilde{L}V
\]
\[
x_2(s) = \dfrac{\tilde{L}(s)}{1 + \tilde{L}(s)} V(s)
\]
dove
\[
\dfrac{\tilde{L}}{1 + \tilde{L}(s)} = \tilde{F}(s)
\]
\`e la funzione di trasferimento a ciclo chiuso o funzione di
sensitivit\`a complementare\index{Funzione di sensitivit\a`
  complementare}.
\begin{figure}[!h]
  \begin{center}
    \includegraphics[scale=0.4]{./images/convertitore-dcdc04}
    \caption{$\tilde{L}(s)$}\label{fig:convertitore-dcdc04} 
  \end{center}
\end{figure}
Il sistema tra $v$ e $x_2$ pu\`o essere visto come un sistema {\em
  intrinsecamente retroazionato}, cio\`e con una retroazione
strutturale e non indotta da un controllo a ciclo chiuso.

In generale, in un sistema retroazionato, $L(s)$ si dice
funzione di trasferimento ad anello aperto ed $F(s)$ funzione di
trasferimento a ciclo chiuso o funzione di sensitivit\`a
complementare.
%%%%%%%%%%%%%%%%%%%%%%%%
\section{Cruise control}
%%%%%%%%%%%%%%%%%%%%%%%%
Partendo dall'equazione di Newton
\[
m \cdot a = F
\]
ricaviamo il modello del cruise control, modellando la dinamica
dell'auto come un sistema del primo ordine:
\begin{equation}\label{eq:cruise01}
  m \dfrac{dv}{dt} = - \beta v + F_w - F_L
\end{equation}
dove
\begin{itemize}
\item $- \beta v$ \`e l'attrito viscoso dell'aria;
\item $F_w$ \`e la forza sulle ruote, applicata attraverso il cambio
  che ha un rapporto dei raggi pari a $\rho$;
\item $F_L$ \`e la forza di carico. \`E contraria al moto se, per
  esempio, l'auto procede in salita. \`E additiva al moto se l'auto
  \`e in discesa
\end{itemize}
La velocit\`a dell'automobile non viene calcolata con il GPS, ma
conoscendo la velocit\`a angolare della ruota e approssimando ad una
circonferenza la ruota:
\[
v = \omega_w \cdot R_w
\]
\[
\omega_w = \dfrac{1}{R_w} v
\]
dove $\omega_w$ \`e la velocit\`a angolare della ruota $\left[
  \frac{rad}{s}\right]$ ed $R_w$ \`e il raggio della ruota $[m]$. Il
segnale di riferimento sar\`a la velocit\`a di crociera desiderata
$v^{rif}$. Va ingnorata la deformazione del pneumatico che rende la
ruota non perfettamente circolare.

La forza $F_w$ applicata alle ruote arriva dal motore alle ruote
attraverso il cambio, di rapporto $\rho$. Possiamo introdurre anche le
coppie:
\[
T_w = F_w \cdot R_w = \rho T_e
\]
\[
T_w \omega_w = T_e \omega_e
\]
dove
\begin{itemize}
\item $T_w$ \`e la coppia sulle ruote
\item $T_e$ \`e la coppia motore
\item $\omega_e$ \`e la velocit\`a angolare del motore
\end{itemize}

Supponiamo che l'attuatore sia modellabile come un sistema dinamico
LTI del primo ordine con guadagno $k_a$ e costante di tempo
$\tau_a$. L'atttuato nell'esempio in analisi \`e rappresentato dal
motore. 

Consideriamo lo schema a blocchi associato
all'equazione~\ref{eq:cruise01} a cui \`e applicata la trasformata di
Laplace (con condizioni iniziali nulle):
\[
m\; sV(s) = - \beta V(s) + F_w(s) - F_L(s)
\]
\[
V(s) = \dfrac{1}{ms + \beta} [ F_W(s) - F_L(s)]
\]
\begin{equation}\label{eq:cruise04}
  V(s) = \dfrac{1}{ms + \beta} F_W(s) - \dfrac{1}{ms + \beta} F_L(s)
\end{equation}
Mettendo insieme le equazioni~\ref{eq:cruise01} e \ref{eq:cruise04} e
tenendo conto delle considerazioni fatte in precedenza, si ottiene lo
schema a blocchi in figura~\ref{fig:cruisecontrol01}.
\begin{figure}[!h]
  \begin{center}
    \includegraphics[scale=0.25]{./images/cruisecontrol01}
    \caption{Schema a blocchi del Cruise
      Control}\label{fig:cruisecontrol01}
  \end{center}
\end{figure}
Si noti che lo schema in figura~\ref{fig:cruisecontrol01} corrisponde
al tipico schema di controllo a retroazione: \`e stato anche aggiunto
il disturbo $d_T$ sul trasduttore di misura e l'attuatore \`e dato
dalla serie del motore e del cambio. La funzione di trasferimento
$R(s)$ rappresenta il controllore.
\begin{figure}[!h]
  \begin{center}
    \includegraphics[scale=0.25]{./images/cruisecontrol02}
    \caption{Schema a blocchi del Cruise
      Control}\label{fig:cruisecontrol02}
  \end{center}
\end{figure}
Portando il blocco ``trasduttore di uscita'' a monte ed a valle del
nodo sommatore della retroazione, si ha lo schema in
figura~\ref{fig:cruisecontrol02}. Tenendo conto che:
\[
\dfrac{1}{R_w} \cdot R_w = 1
\]
e posto
\begin{equation}\label{eq:cruise05}
  G(s) = \dfrac{\dfrac{k_a \rho}{R_w^2}}{1 + s \tau_a} \cdot
  \dfrac{1}{ms + \beta}
\end{equation}
dallo schema in figura~\ref{fig:cruisecontrol02} si evince
immediatamente lo schema studiato per i sistemi di controllo mostrato
in figura~\ref{fig:cruisecontrol03}
\begin{figure}[!h]
  \begin{center}
    \includegraphics[scale=0.25]{./images/cruisecontrol03}
    \caption{Schema a blocchi del Cruise
      Control}\label{fig:cruisecontrol03}
  \end{center}
\end{figure}

Si noti che per il cambio, caratterizzato dalla relazione $T_w = \rho
T_e$, si pu\`o ricavare la relazione considerando due dischi di raggi
diversi, mostrati in figura~\ref{fig:cruisecontrol04}.
\begin{figure}[!h]
  \begin{center}
    \includegraphics[scale=0.25]{./images/cruisecontrol04}
    \caption{Dischi}\label{fig:cruisecontrol04}
  \end{center}
\end{figure}
\[
\overline{v} = \omega_1 R_1 = \omega_2 R_2 \Rightarrow
\dfrac{\omega_1}{\omega_2} = \dfrac{R_2}{R_1}
\]
Assumento uguale potenza
\[
T_1 \omega_1 = T_2 \omega_2
\]
si ricava
\begin{equation}\label{eq:cruise06}
  T_2 = \dfrac{\omega_1}{\omega_2} T_1 = \dfrac{R_2}{R_1} T_1 = \rho T_1
\end{equation}
dove $\rho$ \`e il rapporto dei raggi. Il disco 1 ruota alla stessa
velocit\`a angolare del motore $(T_1 = T_e)$ e il disco 2 a quella delle
ruote $(T_2 = T_w)$ e quindi dall'equazione~\ref{eq:cruise06} si ha
\[
T_w = \rho \cdot T_e
\]
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\section{Margine di guadagno}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\input{./tex/schemaABlocchiLs}
Si supponga che la funzione $L(s)$, mostrata in figura
\ref{fig:schemaABlocchiLs}, abbia guadagno positivo e possieda solo
poli a parte reale negativa. Si definisce ``margine di guadagno'' del
sistema retroazionato, il valore
\[
k_m = \dfrac{1}{|L(j \omega_\pi)|}
\]
Indica di quanto possa aumentare il guadagno d'anello aperto del sistema
prima che il sistema a ciclo chiuso diventi instabile.
$\omega_{\pi}$ \`e il punto in cui il diagramma delle fasi della funzione
$L(s)$ attraversa il valore $-\pi$, come mostrato dalla figura {\bo DA
  SCANSIONARE 9.21}. Data la $L(s)$, possiamo pensare di aumentare il
guadagno del sistema di un parametro $k$. $k_m$ \`e il massimo valore
che pu\`o assumere $k$ senza trasformare il sistema asintoticamente
stabile in un sistema instabile.
%%%%%%%%%%%%%%%%%%%%%%%%%
\section{Margine di fase}
%%%%%%%%%%%%%%%%%%%%%%%%%
Indica di quanto possa aumentare la fase d'anello aperto del sistema
prima che il sistema a ciclo chiuso diventi instabile.
Se consideriamo il sistema \ref{fig:schemaABlocchiLs} con un guadagno
positivo, la figura {\bo DA SCANSIONARE 9.24} ne mostra i diagrammi di
Bode con una particolare attenzione al margine di fase $\varphi_m$. Il
diagramma dei moduli interseca l'asse delle $\omega$ in un punto
$\omega_c$, noto come ``pulsazione critica''\index{Pulsazione
  critica} o ``pulsazione di attraversamento''\index{Pulsazione di
  attraversamento} e rappresenta la pulsazione alla quale il modulo di
$L(j \omega)$ vale $1$ (che in decibel vale 0). Il margine di fase
$\varphi$ pu\`o essere calcolato con:
\[
\begin{array}{l}
  \varphi_m = \pi - |arg L(j \omega_c)|\\
  \varphi_c = arg L(j \omega_c)\\
  |L(j \omega_c)| = 1
\end{array}
\]
Con un $\varphi_m > 0$ il sistema \`e asintoticamente stabile, secondo
il criterio di Bode (\ref{criterioDiBode}). Per ottenere questa
condizione: 
\begin{itemize}
\item I poli devono essere a parte reale negativa
\item Il diagramma dei moduli deve ``attraversare'' una sola volta
  l'asse a $0 dB$.
\end{itemize}
\subsection{Sistema retroazionato con ritardo}
\input{./tex/sistemaRetrazionatoConRitardo}
La figura \ref{fig:sistemaRetroazionatoConRitardo} mostra il sistema
$L(s)$, preso gi\`a in esame, ritardato. La variabile $\tau$
rappresenta un arbitrario ritardo di tempo. La presenza del ritardo
non altera il valore del modulo, ma induce uno sfasamento.
\[
\mathfrak{L}[f(T - \tau)] = e^{-s \tau} F(s)
\]
quindi
\[
L_1(s) = e^{-s \tau} L(s)\\
\]
e calcoliamo il modulo:
\[
\begin{array}{l}
  |L_1(j \omega)| = |e^{-j \omega \tau}| \cdot |L(j \omega)| = 1 \cdot
  |L(j \omega)|\\
  \textrm{dato che, per la formula di Eulero:}\\
  |e^{j \alpha}| = |cos \alpha + j sin \alpha| = 1 \;\;\; \forall \alpha \in
  \mathfrak{R}\\
  \textrm{quindi}\\
  |L(j \omega_c)| = 1 \Rightarrow |L_1(j \omega_{c_{1}})| = 1\\
  \textrm{e abbiamo che } \omega_c = \omega_{c_{1}}
\end{array}
\]
Calcoliamo la fase:
\[
\begin{array}{l}
  arg L_1(j \omega) = arg e^{-j \omega \tau} + arg L(j \omega) =
  -\omega \tau + arg L(j \omega)\\
  \varphi_{m1} = \pi - |arg L_1(j \omega_{c_{1}})| = \\
  = \pi - | - \omega \tau + arg L(j \omega)| = \pi - | - (\omega_c \tau
  - arg L(j \omega_c))|\\
  \pi - \omega_c \tau - |arg L(j \omega_c)| =
\end{array}
\]
\begin{equation}
  \varphi_{m1} = \varphi_m - \omega_c \tau
\end{equation}
Ricordando il teorema di Bode:
\[
L_1(s) \textrm{ \`e asintoticamente stabile se } \varphi_{m1} > 0
\Rightarrow \varphi_m > \omega_c \tau
\]
$\omega_c$ \`e un valore costante, quindi \`e $\tau$ la varibile che
pu\`o rendere instabile il sistema.
\subsubsection{Esempio di sistema con ritardo}
Calcoliamo il modulo:
\[
\begin{array}{l}
  L(s) = \dfrac{10}{(s + 1)^2}\\
  L(j \omega) = \dfrac{10}{(j \omega +1)^2}\\
  |L(j \omega)| = \dfrac{10}{(1 + \omega_c^2)} = 1\\
  \omega_c^2 = 10 -1 \Rightarrow \omega_c = 3
\end{array}
\]
Calcoliamo la fase:
\[
\begin{array}{l}
  arg L(j \omega) = arg 10 - 2 arg (j \omega + 1) = 0 - 2\cdot \tan^{-1}
  \omega\\
  arg L(j \omega_c) = -2 \cdot tan^{-1} 3\\
  \varphi_m = 180^{\circ} - 2 \cdot tan^{-1} 3 = 36.87^{\circ}
\end{array}
\]
Dovendo rispettare il vincolo
\[
\varphi_m > \omega_c \tau
\]
si capisce che
\[
\varphi_m \cdot \dfrac{\pi}{180} [rad] = \omega_c \cdot \tau_{max}
\Rightarrow \tau_{max} = \dfrac{\varphi_m}{\omega_c} = 0.2\; secondi
\]
Il fattore di conversione \`e necessario perch\`e la pulsazione
$\omega_c$ \`e espressa in radianti al secondo, mentre il margine di
fase $\varphi_m$ \`e espresso in gradi. In definitiva, il sistema \`e
asintoticamente stabile per tutti valori
\[
\textrm{di } \tau \textrm{ inferiori a }
\dfrac{\dfrac{\varphi_m}{\omega_c}\pi}{180} \Rightarrow \left(
\dfrac{\dfrac{gradi}{\frac{radianti}{secondo}}radianti}{gradi} =
      [secondi]\right)
      \]
\section{Criterio di Bode}\label{criterioDiBode}
\`E un utile metodo per determinare i criteri di stabilit\`a di un
sistema sfruttando i diagrammi di Bode, i margini di fase e i margini
di guadagno, a patto che
\begin{itemize}
\item il sistema in esame non possieda poli a parte reale positiva;
\item il diagramma di Bode del modulo attraversi una sola volta l'asse
  a $0 dB$.
\end{itemize}
Se consideriamo ancora la figura \ref{fig:schemaABlocchiLs}, $\mu$ il
suo guadagno e $\varphi_m$ il suo margine di fase, il sistema \`e
asintoticamente stabile se
\[
\begin{array}{l}
  \mu > 0\\
  \varphi_m > 0^{\circ}
\end{array}
\]
Inoltre notiamo che:
\[
\tau_{max} = \dfrac{\varphi_m}{\omega_c}
\]

\section{Prestazioni di un sistema di controllo}
\input{./tex/schemaDiControlloARetroazione.tex}
\begin{itemize}
\item funzione di sensitivit\`a
  \begin{equation}\label{eq:funzioneDiSensitivita}
  S(s) = \dfrac{1}{1 + R(s)G(s)} = \dfrac{1}{1 + L(s)}
  \end{equation}
\item funzione di sensitivit\`a complementare
  \begin{equation}\label{eq:funzioneDiSensitivitaComplementare}
  F(s) = \dfrac{R(s) G(s)}{1 + R(s) G(s)} = \dfrac{L(s)}{1 + L(s)}
  \end{equation}
\item funzione di sensitivit\`a del controllo
  \begin{equation}\label{eq:funzioneDiSensitivitaDiControllore}
  Q(s) = \dfrac{R(s)}{1 + R(s) G(s)} = \dfrac{F(s)}{G(s)} = R(s)S(s)
  \end{equation}
\end{itemize}
Analizzando lo schema a blocchi, riusciamo ad isolare $Y(s)$, $U(s)$ e
$E(s)$ ed otteniamo le equazioni del sistema di controllo:
\begin{equation}\label{eq:sistemaDiControllo}
\left \{
\begin{array}{l}
  Y(s) = W(s)F(s) + D(s)S(s) - N(s)F(s)\\
  U(s) = W(s)Q(s) - D(s)Q(s) - N(s)Q(s)\\
  E(s) = W(s)S(s) - D(s)S(s) + N(s)F(s)
\end{array}
\right .
\end{equation}
In forma matriciale:
\[
  \begin{bmatrix}
    Y(s)\\
    U(s)\\
    E(s)
  \end{bmatrix}\\
  =
  \begin{bmatrix}
    F(s) & S(s) & -F(s)\\
    Q(s) & -Q(s) & -Q(s)\\
    S(s) & -S(s) & F(s)
  \end{bmatrix}
  \begin{bmatrix}
    W(s)\\
    D(s)\\
    N(s)
  \end{bmatrix}
\]
Affinch\`e l'uscita $y$ coincida con il segnale di riferimento $w$ e
siano nulli i disturbi $d$ su $y$, basterebbe imporre
\[
\begin{array}{l}
  F(s) = 1\\
  S(s) = 0
\end{array}
\]
ma questo comporterebbe un ripercuotersi totale, senza attenuazione,
del disturbo $n$ sull'uscita $y$ e sull'errore $e$:
\[
\begin{array}{l}
  Y(s) = W(s) - N(s)\\
  E(s) = N(s)
\end{array}
\]
Si nota la necessit\`a di un approccio flessibile al problema del
controllo e ad un inevitabile compromesso. Si punter\`a ad avere
\[
|F(j \omega)| \simeq 1
\]
nella banda di pulsazioni in cui prevale l'esigenza di un inseguimento
del riferimento $w$ e
\[
|F(j \omega)| \simeq 0
\]
alle alte frequenze, dove \`e tipicamente concentrata l'energia del
disturbo $n$. In definitiva, ricordiamo che
\begin{itemize}
\item $G(s)$ \`e la funzione di trasferimento in anello aperto del
  sistema, da $u$ ad $y$;
\item $L(s)$ \`e la funzione di trasferimento in anello aperto del
  sistema controllato, da $e$ ad $y$;
\item $F(s)$ \`e la funzione di trasferimento in anello chiuso del
  sistema controllato, da $w$ ad $y$.
\end{itemize}

\section{Analisi della funzione di sensitivit\`a complementare}
La funzione di sensitivit\`a complementare
\[
F(s) = \dfrac{L(s)}{1 + L(s)}
\]
\`e la funzione di trasferimento a ciclo chiuso del sistema
controllato. Questa funzione $F(s)$ \`e anche:
\begin{itemize}
\item la funzione di trasferimento tra il riferimento $w$ e
  l'uscita $y$
  \[
  F(s) = \dfrac{Y(s)}{W(s)}
  \]
\item la funzione di trasferimento, cambiata di segno, tra il disturbo
  $n$ e l'uscita $y$
  \[
  - F(s) = \dfrac{Y(s)}{N(s)}
  \]
\item la funzione di trasferimento tra il disturbo $n$ e l'errore $e$
  \[
  F(s) = \dfrac{E(s)}{N(s)}
  \]
\end{itemize}

\subsection{Precisione statica a regime}
Consideriamo la $L(s)$ in forma di Bode:
\[
L(s) = \dfrac{\mu}{s^g} \cdot \dfrac{\prod (1 + s\tau_i) \cdot \prod
  (1 + \dfrac{2 \xi}{\alpha_{ni}}s + \dfrac{1}{\alpha_{ni}^2}
  s^2)}{\prod (1 + sT_i) \cdot \prod \left(1 + \dfrac{2
    \zeta}{\omega_{ni}}s + \dfrac{1}{\omega_{ni}^2}s^2\right)}
\]
Il segnale di riferimento \`e
\[
W(s) = \dfrac{\overline{A}}{s}
\]
un gradino di ampiezza $A$.
\[
\begin{array}{l}
  y_{\infty} = \lim_{s \to 0} sF(s) W(s)\\
  \textrm{con le opportune sostituzioni}\\
  \bar{A}\lim_{s \to 0} F(s) = \bar{A}\lim_{s \to 0}\dfrac{\dfrac{\mu}{s^g}}{1 +
    \dfrac{\mu}{s^g}} = \bar{A}\lim_{s \to 0} \dfrac{\mu}{s^g + \mu}
\end{array}
\]
Al variare dei valori di $g$ avremo limiti differenti:
\[
\left\{
\begin{array}{ll}
  \dfrac{\bar{A}\mu}{1 + \mu} & \textrm{per } g = 0\\
  0 & \textrm{per } g < 0\\
  \bar{A} & \textrm{per } g > 0\\
\end{array}
\right.
\]
\begin{itemize}
\item Caso $g > 0$\\
  $y_{\infty} = \bar{A} = W_{\infty}$ ovvero se la funzione d'anello
  possiede almeno un polo nell'origine, il sistema in feedback
  fornisce migliori prestazioni statiche, in quanto il guadagno di
  $F(s)$ \`e unitario ed $y$ segue fedelmente $w$;
\item Caso $g = 0$\\
  Il guadagno di $F(s)$ \`e $\mu_F = \dfrac{\mu}{1 + \mu}$ ed \`e
  prossimo ad $1$ solo per valori di $|\mu|$ elevati ed in generale
  risulta $0 < \mu_F < 1$ quando $\mu > 0$. Inoltre se $g = 0, \; \mu
  = -1$,\; $F(s)$ ha almeno un polo nell'origine e non \`e
  asintoticamente stabile.
\item Caso $g < 0$\\
  C'\`e almeno un polo nell'origine ed $F(s)$ contiene almeno una
  azione derivativa (cio\`e un prodotto per $s$). Quindi il sistema di
  controllo non offre buone prestazioni statiche in quanto $y_{\infty}
  = 0 \;\; \forall \;W$ 
\end{itemize}

\subsection{Poli e zeri}
Calcoliamo i poli e gli zeri di $F(s)$ per analizzare il comportamento
dinamico.
\[
\begin{array}{l}
  L(s) = \dfrac{N_L(s)}{D_L(s)} = \dfrac{numeratore}{denominatore}\\
  \\
  F(s) = \dfrac{\dfrac{N_L(s)}{D_L(s)}}{1 + \dfrac{N_L(s)}{D_L(s)}} = 
  \dfrac{\dfrac{N_L(s)}{D_L(s)}}{\dfrac{N_L(s) + D_L(s)}{D_L(s)}}\\
  \\
  F(s) = \dfrac{N_L(s)}{D_L(s) + N_L(s)}
\end{array}
\]
Quindi gli zeri di $F(s)$ sono gli zeri di $L(s)$ e i poli di $F(s)$
sono le radici del polonimio $D_L(s) + N_L(s)$, che \`e il polinomio
caratteristico del sistema retroazionato.

\subsection{Risposta in frequenza}
Per soddisfare le specifiche sulle prestazioni nominali dell'uscita
$y$ e dell'errore $e$, dovremmo cercare di otterenere $F(s) = 1$. Ci
basta per\`o considerare la struttura dell'equazione
\ref{eq:funzioneDiSensitivitaComplementare} per capire che \`e
irrealizzabile. Possiamo per\`o considerare l'esempio in cui $L(s)$
sia un tipico filtro passa-basso. Il diagramma dei moduli \`e piatto
fino al punto di rottura, per poi scendere con una certa pendenza,
fino ad intersecare l'asse a $0 dB$ nel punto $\omega_c$. SCANSIONARE
LA FIGURA 10.2 

La funzione di sensitivit\`a complementare \`e
\[
F(s) = \dfrac{L(s)}{1 + L(s)}
\]
\[
F(j \omega) = \dfrac{L(j \omega)}{1 + L(j \omega)}
\]
\[
|F(j \omega)| = \dfrac{|L(j \omega)|}{|1 + L(j \omega)|}
\]
A questo punto abbiamo due possibili scenari:\begin{enumerate}
\item $\omega \ll \omega_c$
  \[
  \begin{array}{l}
    |L(j \omega)| \gg 1\\
    |1 + L(j \omega)| \simeq |L(j \omega)|\\
    |F(j \omega)| = 1
  \end{array}
  \]
  Questo \`e lo scenario ideale per quanto riguarda l'obbiettivo di far
  coincidere l'uscita $y$ con il riferimento $w$, ma non consente
  di attenuare in alcun modo l'effetto del disturbo $n$ sull'uscita
  stessa e sull'errore $e$.
\item $\omega \gg \omega_c$
  \[
  \begin{array}{l}
    |L(j \omega)| \ll 1\\
    |1 + L(j \omega)| \simeq 1\\
    F(j \omega) = L(j \omega)
  \end{array}
  \]
  Quindi, $|F(j \omega)|$ insegue perfettamente $|L(j \omega)|$.
\end{enumerate}
Il modulo della risposta in frequenza di $F(j \omega)$ \`e simile a
quello di un filtro passa-basso ideale (nell'intervallo $[0,
\omega_c]$). Finch\`e $\omega \leq \omega_c$, $F(j
\omega)$ insegue correttamente. Quando $\omega > \omega_c$, $F(j
\omega)$ attenua il segnale in ingresso. Quindi, tutte le componenti
di $w$ a pulsazione minore di $\omega_c$ vengo riprodotte
fedelmente in uscita. Vengono per\`o riprodotte anche tutte le
componenti di $n$ di frequenza minore di $\omega_c$. Fortunatamente,
$n$ \`e tipicamente una sinusoide a frequenza molto elevata e viene,
quindi, attenuanta naturalmente dal sistema.

Dato che nel diagramma di $|F(j \omega)|_{dB}$ non ci sono variazioni
di pendenza prima di $\omega_c$, possiamo affermare che in
prossimit\`a di $\omega_c$ ci sono i poli dominanti della
$F(s)$. Bisogna considerare che al fine di non provocare eccessive
distorsioni di fase, \`e necessario che $arg F(j \omega) \simeq 0$
all'interno della banda passante (supposto che $W(j \omega)$ non
abbia componenti significative al di fuori di tale banda).
  
In definitiva, conviene sempre aumentare $\omega_c$ per incrementare
la capacit\`a del sistema di inseguire le veloci variazioni del
riferimento $w$, ma senza raggiungere le frequenze in cui il
disturbo $n$ sul trasduttore diventi rilevante.

\subsection{Legame tra il margine di fase $\varphi_m$ e il picco di
  risonanza $\zeta$} 
Scriviamo $F(s)$ nella forma di Bode:
\[
F(s) \simeq \dfrac{1}{\dfrac{1}{\omega_c^2}s^2 + \dfrac{2
    \zeta}{\omega_c}s + 1}
\]
dove $\omega_c$ \`e una approssimazione della pulsazione naturale
$\omega_n$ dei poli dominanti, considerati complessi coniugati.
\[
\begin{array}{l}
  |L(j \omega_c)| = 1\\
  |F(j \omega_c)| = \dfrac{|L(j \omega_c)|}{|1 + L(j \omega_c)|} =
  \dfrac{1}{|1 + L(j \omega_c)|}\\
\end{array}
\]
Tenendo conto che $L(j\omega)$ \`e un numero complesso di modulo
unitario e fase $\varphi_c$
\[
L(j \omega_c) = e^{j \varphi_c}
\]
\[
\begin{array}{l}
  |F(j \omega_c)| = \dfrac{1}{|1 + e^{j \varphi_c}|} = \dfrac{1}{|1 + cos \varphi_c -
    j sin \varphi_c|} =\\
  = \dfrac{1}{\sqrt{1 + cos^2 \varphi_c + 2 cos \varphi_c + sin^2
      \varphi_c}} = \\
  = \dfrac{1}{\sqrt{2 \cdot (1 + cos \varphi_c)}}\\
  \textrm{Considerato che}\\
  \varphi_m = \pi - |\varphi_c|\\
  \varphi_c = -\varphi_m + \pi\\
  \textrm{otteniamo che}\\
  |F(j \omega_c)| = \dfrac{1}{\sqrt{2\cdot (1 - cos \varphi_m)}}\\
  \textrm{Considerata la formula di bisezione }\\
  cos \varphi_m = cos \left( \dfrac{\varphi_m}{2} +
  \dfrac{\varphi_m}{2} \right) = cos^2 \dfrac{\varphi_m}{2} - sin^2
  \dfrac{\varphi_m}{2}\\ 
  \Rightarrow \dfrac{1}{\sqrt{2 \cdot (1 - cos \varphi_m)}} =
  \dfrac{1}{\sqrt{2 \cdot 2 sin^2 \dfrac{\varphi_m}{2}}} =
  \dfrac{1}{2 sin \dfrac{\varphi_m}{2}}\\
  \\
  |F(j \omega_c)| = \dfrac{1}{|1 + \dfrac{2 \zeta}{\omega_c} j
    \omega_c + \dfrac{1}{\omega_c^2}(- \omega^2)} = \dfrac{1}{2 \zeta}
\end{array}
\]
Considerate che $\omega_n = \omega_c$ e che il sistema \`e sel secondo
ordine, senza zeri e con guadagno unitario:
\begin{equation}
  \begin{array}{l}
    \dfrac{1}{2 \zeta} = \dfrac{1}{2sin \left( \dfrac{\varphi_m}{2} \right)}\\
    \zeta = sin \left( \dfrac{\varphi_m}{2} \right)\\
    \varphi_m = 2 arc sin(\zeta)\\
    \textrm{oppure}\\
    \zeta = \dfrac{\varphi_m}{2} \dfrac{\pi}{180} \simeq
    \dfrac{\varphi_m}{100}
  \end{array}
\end{equation}
e abbiamo quindi la possibilit\`a di variare lo smorzamento variando il
margine di fase. Questa formula ci fornisce una valutazione
attendibile di $\zeta$ fino a valori di $\varphi_m \simeq
75^{\circ}$:
\[
\varphi_m > 75^{\circ} \;\; F(s) \textrm{ ha un polo dominante reale
  con } \tau \simeq \dfrac{1}{\omega_c}
\]
\[
0 < \varphi_m \leq 75^{\circ} \;\; F(s) \textrm{ ha una coppia di poli
complessi con } \omega_n \simeq \omega_c \textrm{ e } \zeta \simeq
\left(\dfrac{\varphi_m}{100}\right) 
\]

\subsection{Risposta allo scalino}
Anche le informazioni relative al tempo di assestamento $T_{a
  \varepsilon}$, alla sovraelongazione $S\%$ ed al periodo $T_P$, la
distanza temporale tra due picchi successivi, possono essere ricavate
dalla $F(s)$ con le stesse approssimazioni a poli dominanti effettuate
in precedenza e con l'utilizzo della $\omega_c$ e $\varphi_m$.

\subsection{Effetto di un ritardo di tempo}
Se la $L(s)$ contiene un ritardo di tempo, ovvero essa \`e
\[
L(s) = e^{-\tau s} L'(s) \;\; \textrm{con $L'(s)$ razionale}
\]
gran parte dei risultati ricavati in precedenza possono essere
applicati anche in questo caso.

Per quanto riguarda l'analisi statica, il fattore $e^{- \tau s}$ non
modifica il calcolo del limite. Per le caratteristiche dinamiche, la
presenza del ritardo non modifica la $\omega_c$, ma il margine di fase
$\varphi_m$ diminuisce di una quantit\`a pari a $\omega_c \tau
\dfrac{180}{\pi}$. Pertanto, anche se $F(s)$ continua ad essere un
filtro passa-basso, ha una dinamica con smorzamento $\zeta$ minore. In
definitiva, il margine di fase per effetto del ritardo di tempo
sar\`a
\[
\varphi_{m_{\tau}} = \varphi_m - \omega_c \tau \cdot \dfrac{180}{\pi}
\]

% ANALISI DELLA FUNZIONE DI SENSITIVITA`
\section{Analisi della funzione di sensitivit\`a}
Consideriamo la classica
\[
\begin{array}{l}
  Y(s) = D(s) + L(s)(W(s) - Y(s))\\
  \textrm{e scegliamo } W(s) = 0\\
  Y(s) = \dfrac{1}{1 + L(s)} \cdot D(s)
\end{array}
\]
A questo punto abbiamo ottenuto la funzione di sensitivit\`a $S(s)$
\begin{equation}\label{eq:funzioneDiSensitivitaLs}
S(s) = \dfrac{1}{1 + L(s)}
\end{equation}
che rappresenta
\begin{itemize}
\item la funzione di trasferimento tra il disturbo~$d$ e l'uscita~$y$
  \[
   S(s)  = \dfrac{Y(s)}{D(s)}
  \]
\item la funzione di trasferimento tra il riferimento~$\omega$ e
  l'errore~$e$
  \[
  S(s) = \dfrac{E(s)}{W(s)}
  \]
\item la funzione di trasferimento, cambiata di segno, tra il
  disturbo~$d$ e l'errore~$e$
  \[
  S(s) = - \dfrac{E(s)}{D(s)}
  \]
\end{itemize}
Teoricamente dovremmo puntare ad avere $S(s) = 0$, che ci consentirebbe
di non avere effetti sull'errore degli ingressi~$w$ e $d$. Si
nota, per\`o, che dall'equazione~\ref{eq:funzioneDiSensitivitaLs}
\[
\lim_{s \to \infty} S(s) = 1
\]
ed $S(s) = 0$ \`e praticamente irrealizzabile.
Possiamo invece cercare di ottenere una risposta in frequenza di $S(j
\omega)$ in cui il modulo sia sufficientemente piccolo nella banda di
pulsazioni dove si presume che lo spettro dei segnali~$\omega$ e $d$
presenti parti significative.
\subsection{Analisi statica}
Applicando le considerazioni fatte per la funzione di sensitivit\`a
complementare, otteniamo:
\[
\lim_{s \to 0} S(s) = \lim_{s \to 0} \dfrac{s^g}{s^g + \mu} =
\left\{
\begin{array}{cll}
  \dfrac{1}{1 + \mu} &,& g = 0\\
  1 &,& g < 0\\
  0 &,& g > 0
\end{array}
\right.
\]
Pertanto si ha che
\begin{itemize}
\item se $g > 0$ esiste una azione derivativa nella S(s)
\item se $g = 0\;\;\mu = -1$ esiste una azione integrale nella S(s)
\item se $g < 0$ e in tutti gli altri casi il limite rappresenta il
  guadagno statico $\mu_s$ sella $S(s)$
  \[
  \left\{
  \begin{array}{l}
    g = 0\;,\;\mu \neq -1 \Rightarrow \mu_s = \dfrac{1}{1 +
      \mu}\\
    g < 0 \Rightarrow \mu_s = 1
  \end{array}
  \right.
  \]
\end{itemize}
Se consideriamo un ingresso $W$ a gradino, $W(t) = A \delta_1(t)$,
l'errore a transitorio esautito sar\`a, per il teorema del valore
finale:
\[
e_{\infty} = \lim_{s \to 0} s S(s) \dfrac{A}{s} = A \lim_{s \to 0}
  S(s) =
\]
\begin{itemize}
\item $g > 0 \;,\; e_{\infty} = 0$ \\
  C'\`e almeno un polo nell'origine. La precisione statica \`e
  massima.
\item $g = 0\;,\; e_{\infty} = \dfrac{A}{1 + \mu}$\\
  se $\mu > 0$ la precisione aumenta all'aumentare di $\mu$ (il
  guadagno d'anello) e l'errore all'infinito pu\`o essere reso
  arbitrariamente piccolo scegliendo $\mu$ sufficientemente grande;  
\item $g < 0$ $L(s)$ ha un'azione derivativa; l'entit\`a dell'errore
  \`e pari a quella dell'ingresso che lo ha generato.
\end{itemize}
Nota: se invertiamo il segno di questi risultati, possiamo accettarli
anche per l'errore a transitorio esaurito dovuto ad un andamento a
gradino del disturbo $d$.

In generale, nel caso in cui ci sia un ingresso $W$, dinamico, con
$\mathfrak{L}\{ W(t)\} = \dfrac{A}{s^i}$ con $i > 0$ e intero, si ha
che
\[
W(s) = \dfrac{A}{s^i} \;\;,\;\; i \geq 2
\]
dall'applicazione del teorema del valore finale si ha
\[
e_{\infty} = \lim_{s \to \infty} sS(s) \dfrac{A}{s^i} = A \lim_{s \to
  \infty} \dfrac{s^{g-i+1}}{s^g + \mu} = 
\]
\[
\left \{
\begin{array}{cll}
  \infty & g < i -1 & \textrm{ L'errore diverge}\\
  \dfrac{A}{\mu} & g = i -1 & e_{\infty} \propto \mu\\
  0 & g > i - 1 & \textrm{L'errore all'infinito \`e asintoticamente nullo} 
\end{array}
\right .
\]

In definitiva, per limitare $e_{\infty}$ bisogna aumentare le azioni
integrali al crescere di $i$. La tabella \ref{tab:errorig} mostra
l'errore all'infinito $e_{\infty}$ per ingressi $W$ canonici e tipo
$g$ della funzione d'anello diverso. Gli stessi risultati, ma cambiati
di segno valgono anche per l'errore in risposta ad un disturbo $d$
canonico.
\begin{equation}\label{tab:errorig}
  \begin{array}{cccc}
    & Asca(t) & Aramp(t) & Apar(t)\\
    g = 0 & \dfrac{A}{1 + \mu} & \infty & \infty\\
    g = 1 & 0 & \dfrac{A}{\mu} & \infty \\
    g = 2 & 0 & 0 & \dfrac{A}{\mu}\\
    g = 3 & 0 & 0 & 0
  \end{array}
\end{equation}
I risultati ottenuti sono totalmente indipendenti dalla $G(s)$ del
sistema sotto controllo. Tali risultati godono quindi della
propriet\`a di robustezza essendo validi anche in presenza di
incertezza. Se sono presenti incertezze sulla $G(s)$ tali da non
pregiudicare l'asintotica stabilit\`a in anello chiuso e il regolatore
$R(s)$ ha almeno una azione integrale, $e_{\infty} = 0$. In questo
caso si dice che il regolatore assicura la regolazione robusta a zero
dell'errore, o nel caso dell'errore $d$, la reiezione robusta del
disturbo a gradino.
\subsection{Poli e zeri}
\[
L(s) = \dfrac{N_c(s)}{D_L(s)}
\]
\[
S(s) = \dfrac{D_L(s)}{D_L(s) + N_L(s)}
\]
Si evince che gli zeri di $S(s)$ sono i poli di $L(s)$, mentre i poli
di $S(s)$ sono le radici del polinomio $D_L(s) + N_L(s)$. In
particolarmente se risulta $L(s)$ asintoticamente stabile, cio\`e
$S(s)$ non ha zeri a $\mathfrak{R} > 0$.
\subsection{Risposta in frequenza}
\[
|S(j \omega) = \dfrac{1}{|1 + L(j \omega)|} \simeq
\left\{
\begin{array}{l}
  \dfrac{1}{|L(j \omega)|} \;\;,\; \omega \leq \omega_c\\
  1 \;\;,\; \omega > \omega_c
\end{array}
\right.
\]
Il diagramma di Bode di $S(j\omega)$ \`e mostrato in figura SCANSIONARE LA
FIGURA 10.11 e si nota la natura passa-alto di $S(s)$. Se si guarda ad
$S$ come una funzione di trasferimento tra $d$ ed $y$ si deduce che,
in condizioni di asintotica stabilit\`a, il sistema in retroazione
ha un effetto attenuante, sulla variabile controllata per tutte le
componenti del disturbo a pulsazione $\omega < \omega_c$; effetto
tanto pi\`u consistente quanto maggiore \`e il $|L(j \omega)|$ in
quella banda di pulsazioni. Le componenti di disturbo $d$ a pulsazione
maggiore di $\omega_c$ non subiscono attenuazioni. Quindi otteniamo un
valore di $|S(j \omega)|$ piccolo scegliendo un valore elevato della
pulsazione $\omega_c$. 
\subsection{Altri limiti prestazionali}
Nel caso in cui la differenza tra il grado del denominatore e il grado
del numeratore (grado relativo della funzione d'anello) sia
maggiore o uguale a 2 si pu\`o applicare il seguente teorema:
\begin{teorema}
  In condizioni di asintotica stabilit\`a, la $L(s)$ non ha poli a
  parte reale positiva e ha grado relativo maggiore o uguale di 2,
  risulta
  \[
  \int_{0}^{\infty} |S(j \omega)|_{dB} d\omega = 0
  \]
\end{teorema}
cio\`e il valore medio di $|S(j \omega)|_{dB}$ sull'intero asse delle
pulsazioni \`e nullo. Se ci sono, quindi, tratti del diagramma sotto
l'asse a $0_{dB}$. ve ne devono essere altrettanti al di sopra dello
stesso asse.

Ricordando che $S(s)$ \`e la funzione di trasferimento, cambiata di
segno, tra $d$ ed $e$, si pu\`o concludere che un'attenuzione in una
certa banda di pulsazioni \`e inevitabilmente compensata da una
significativa amplificazione in un'altra banda.

\section{Analisi della funzione di sensitivit\`a del controllo}
\begin{equation}\label{eq:sensitivitaControllo}
  Q(s) = \dfrac{R(s)}{1 + L(s)} = R(s) S(s) = \dfrac{F(s)}{G(s)}
\end{equation}
L'equazione \ref{eq:sensitivitaControllo} rappresenta la funzione di
trasferimento tra $W$ ed $n$ e la variabile di controllo
$u$. Analizzare la $Q(s)$ significa analizzare la moderazione della
variabile di controllo. Per ridurre le sollecitazioni a cui $u$ \`e
sottoposta, sarebbe desiderabile che la $Q(j \omega)$ sia quanto pi\`u
piccola possibile nell'intervallo di pulsazioni in cui gli ingressi
presentano componenti significative. Purtroppo nella maggior parte dei
casi reali, lo spettro del disturbo di misura $n$ \`e prevalentemente
concentrato verso le alte frequenze, mentre quelli dei segnali $w$ e
$d$ verso le basse frequenze.

\subsection{Analisi statica}
Considerando una $L(s)$ con $g = 0$, cio\`e senza alcuna azione
integrale o derivativa n\`e nel controllore n\`e nel processo, e
indicando con $\mu_R$, $\mu_G$ e $\mu$ i guadagni di $R(s)$, $G(s)$ e
$L(s)$ si ha che:
\[
\mu_q = \lim_{s \to 0} Q(s) = \lim_{s \to 0} \mu_R S(s) =
\dfrac{\mu_R}{1 + \mu} = \lim_{s \to 0} \dfrac{F(s)}{\mu_G} =
\dfrac{\mu}{\mu_G(1 + \mu)}
\]
Quindi, se
\[
\mu \gg 1 \Rightarrow \mu_q \simeq \dfrac{1}{\mu_G}
\]
Ci\`o significa che per ottenere un piccolo guadagno nella regolazione
di un processo ed avere prestazioni soddisfacenti, \`e necessario
imporre valori elevati della variabile di controllo $u$, perch\`e il
suo valore di regime $\mu_{\infty}$ \`e inversamente proporzionale al
guadagno del processo da controllare.

\subsection{Poli e zeri}
Utilizzando li relazioni:
\[
\begin{array}{l}
  R(s) = \dfrac{N_R(s)}{D_R(s)}\\
  G(s) = \dfrac{N_G(s)}{D_G(s)}
\end{array}
\]
si ricava che
\[
\begin{array}{ll}
  Q(s) = & \dfrac{\dfrac{N_R(s)}{D_R(s)}}{1 +
    \dfrac{N_R(s)N_G(s)}{D_G(s)D_R(s)}} =
  \dfrac{\dfrac{N_R(s)}{D_R(s)}}{\dfrac{D_G(s)D_R(s) +
      N_R(s)N_G(s)}{D_G(s)D_R(s)}} \\
   & \dfrac{N_R(s)D_G(s)}{D_G(s)D_R(s) + N_R(s)N_G(s)}\\
   & \dfrac{N_R(s)D_G(s)}{D_L(s) + N_L(s)}
\end{array}
\]
Gli zeri di $Q(s)$ sono quindi i poli di $G(s)$ e gli zeri di $R(s)$,
per cui la risposta al gradino delle $Q(s)$ pu\`o avere
sovraelongazioni di elevata ampiezza ogni volta che $R(s)$ ha zeri o
$G(s)$ ha poli inferiori a $\omega_c$ che rappresenta in buona
approssimazione la pulsazione dei poli dominanti a ciclo chiuso. La
presenza di sovraelongazione \`e incompatibile con le limitazioni
naturali della variabile di controllo $u$.
\subsection{Risposta in frequenza}
Mediante le consuete approssimazioni si pu\`o scrivere:
\[
|Q(j \omega)| = \dfrac{R(j \omega)}{|1 + L(j \omega)|} \simeq
\left \{
\begin{array}{ll}
  \dfrac{1}{|G(j \omega)|} & \omega \leq \omega_c\\
  |R(j \omega)| & \omega > \omega_c
\end{array}
\right .
\]
In corrispondenza di $\omega_c$, i diagrammi $\dfrac{1}{|G(j
  \omega)|}$ e $|R(j \omega)|$ si intersecano e
\[
|L(j \omega_c)| = |R(j \omega_c)| |G(j \omega_c)| = 1
\]
Si pu\`o dire, esaminando il diagramma di $|Q(j \omega)|_{dB}$, che
\begin{itemize}
\item il $|Q(j \omega)|_{dB}$ dipende solo dal processo $G(s)$ per
  pulsazioni $\omega < \omega_c$
\item il $|Q(j \omega)|_{dB}|$ dipende solo dal regolatore $R(s)$ a
  pulsazioni elevata
\end{itemize}
Per limitare le sollecitazioni sulla variabile di controllo $u$,
bisogna evitare regolatori con $|R(j \omega)|$ elevato ad alta
frequenza. Considerando invece la relazione
\[
|Q(j \omega)| = \dfrac{|F(j \omega)}{|G(j \omega)|}
\]
si pu\`o dire che, siccome il diagramma di $|Q(j \omega)|$ \`e la
differenza tra quello di $|F(j \omega)|$ e $|G(j \omega)|$ e $|F(j
\omega)|$ \`e tipicamente un filtro passa-basso con guadagno unitario
e banda passante $[0, \omega_c]$, considerando che $G(s)$ tipicamente
\`e un filtro passa-basso con $B = [0, \overline{\omega}]$, si
conclude che per $\omega_c > \overline{\omega}$, il diagramma di $|Q(j
\omega)|$ ha un tratto con andamento crescente nell'intervallo
$[\overline{\omega}, \omega_c]$. Se quindi risulta $\omega \gg
\overline{\omega}$ $|Q(j \omega)|$ raggiunge valori elevati ad alte
frequenze. Ci\`o evidenzia il compromesso a cui si \`e soggetti quando
si vuole aumentare $\omega_c$ per otterenere un sistema a ciclo chiuso
pi\`u veloce di quello in anello aperto.
\subsection{Prestazioni in condizioni perturbate}
Nel caso in caso in cui non si conosca in maniera definitiva il
modello del sistema ed in particolare quello del processo $G(s)$, \`e
importante garantire quanto pi\`u possibile, che le prestazioni del
sistema di controllo rimangano inalterate anche in presenza di
incertezze in $G(s)$. In particolare, si indica con $G_a(s)$ la
funzione di trasferimento effettiva e $G(s)$ quella nominale.
\subsection{Regolazione robusta a zero dell'errore}
Tale propriet\`a \`e gi\`a stata discussa in precedenza ed indica che
l'errore a regime \`e nullo (se il tipo $g$ della funzione d'anello
\`e maggiore di zero) quando il sistema \`e sottoposto
all'azione di un riferimento $w$ o di un disturbo $d$ a scalino,
indipendentemente dalla presenza di incertezze su $G(s)$, purch\`e
queste non pregiudichino l'asintotica stabilit\`a in anello chiuso.
\subsection{Reiezione robusta di disturbi sinusoidali}
Si suppone che $d(t) = A sin(\overline{\omega}t)$. Assumendo il sistema
di controllo asintoticamente stabile, affinch\`e l'effetto di $d(t)$
su $e(t)$ sia nullo, occorre che risulti $|S(j \overline{\omega})| =
0$ ovvero occorre cge $S(s)$ abbia una coppia di zeri in $s = \pm j
\overline{\omega}$ per cui bisogna utilizzare un $R(s)$ con poli in $s
= \pm j \overline{\omega}$. Questo risultato \`e indipendente  da
incertezze su $G(s)$ che non alterano l'asintotica stabilit\`a e si
parla quindi di reiezione robusta al disturbo sinusoidale.

\`E differente, invece, il caso in cui siano presenti in certezze su
$\overline{\omega}$ del disturbo. Inoltre bisogna considerare che \`e
difficile garantire l'asintotica stabilit\`a, quando un $R(s)$ ha poli
in $s = \pm j \overline{\omega}$ con smorzamento nullo, in quanto
questi determinano uno sfasamento di $- 180^{\circ}$ da
$\overline{\omega}$ in poi.
\subsection{Attenuazione robusta dei disturbi a banda limitata}
In presenza di disturbi che non hanno componenti spettrali a
pulsazioni maggiori di $\overline{\omega}$, un tipico requisito per il
sistema di controllo consiste nell'imporre
\[
|S(j \omega)| < c \;\;,\;\; \forall \omega \in [0, \overline{\omega}]
\;\;\textrm{con c = costante} < 1
\]
In questo modo tutte le componenti del disturbo vengono attenuate di
un fattore pari a $c$.

Comn un'incertezza su $G(s)$ si ha:
\[
G_a(s) = G(s) + \delta G(s)
\]
con
\begin{itemize}
\item $G(s)$ pari al modello nominale
\item $\delta G(s)$ pari alla perturbazione
\end{itemize}
La perturbazione \`e tale per cui
\[
|\delta G(j \omega)| \leq \gamma(\omega)
\]
con $\gamma(\omega)$ assegnata. Inoltre
\[
\begin{array}{l}
L_a(s) = R(s) G_a(s) = R(s) (G(s) + \delta G(s)) =\\
= R(s)G(s) + R(s)\delta G(s) = L(s) + R(s)\delta G(s)
\end{array}
\]
e
\[
S_a(s) = \dfrac{1}{1 + L_a(s)}
\]
Per un'attenuzione robusta bisogna avere
\[
\begin{array}{ll}
  |S_a(j \omega)| < c & \\
  |1 + L_a(j \omega)| > \dfrac{1}{c} & \forall \omega \in [0,
  |\overline{\omega}]\;\textrm{e}\;\forall \delta G(s) \textrm{ ammissibile}
\end{array}
\]
Si osserva che
\[
\begin{array}{l}
  |1 + L_a(j \omega)| = |1 + L(j \omega) + R(j \omega) \delta G(s)|
  \geq\\
  \geq |1 + L(j \omega)| - |R(j \omega)|\cdot|\delta G(j \omega)|
  \geq\\
  \geq |1 + L(j \omega)| - \gamma(\omega) |R(j \omega)|
\end{array}
\]
dove si \`e sfruttata la diseguaglianza triangolare, ovvero che
\[
| a + b | \geq |a| - |b| \;\; \textrm{con } a \textrm{ e } b \in
\mathfrak{C}
\]
Quindi se ponendo
\[
|1 + L(j \omega)| > \dfrac{1}{c} + \gamma(\omega) |R(j \omega)| \;,\;
\omega \leq \overline{\omega}
\]
si ricava che
\[
|1 + L(j \omega)| > \dfrac{1}{c}
\]

\section{Sensitivit\`a rispetto ad incertezze parametriche}
Considerando una funzione di trasferimento del processo acente
incertezza su un parametro $\theta$, possiamo scrivere:
\begin{itemize}
\item $G(s, \overline{\theta}) = $ Funzione di trasferimento nominale
\item $G(s, \theta) = $ Funzione di trasferimento perturbata
\end{itemize}
con $\Delta \theta \equiv \theta - \overline{\theta}$ lo scostamento
del valore effettivo da quello nominale.

L'analisi di sensitivit\`a consente di determinare l'effetto del
$\Delta \theta$ sul sistema retrazionato.

Per quanto riguarda l'effetto di $\Delta \theta$ su $G(s, \theta)$,
utilizziamo lo sviluppo in serie di Taylor, fermato al primo ordine,
si ha, per $\Delta \theta$ sufficientemente piccolo:
\[
\Delta G(s, \theta, \overline{\theta}) = G(s, \theta) - G(s,
\overline{\theta}) \simeq \dfrac{\partial G(s,
  \theta)}{\left. \partial \theta \right|_{\theta = \overline{\theta}}
\Delta \theta}
\]
effettivo
\[
E_G(s, \theta, \overline{\omega}) = \dfrac{\Delta G(s, \theta,
  \overline{\theta})}{G(s, \theta)}
\]
che \`e la variazione relativa della funzione di trasferimento in
anello aperto e $E_G(j \omega, \theta, \overline{\theta})$ rappresenta
l'effetto dell'incertezza parametrica sulla risposta in
frequenza. Valori elevati del $|E_G(j \omega, \theta,
\overline{\omega})|$ indicano che in quella banda di pulsazioni, la
risposta in frequenza presenta un elevato grado di sensitivit\`a
rispetto alla variazione del parametro. Considerando l'impatto
dell'incertezza sulla $F(s)$ si ha:
\[
F(s, \theta) = \dfrac{R(s) G(s, \theta)}{1 + R(s) G(s, \theta)}
\]
e la $F(s, \overline{\theta})$ \`e la funzione di trasferimento in
condizioni nominali.\\
Si pone:
\[
\begin{array}{l}
  \Delta F(s, \theta, \overline{\theta}) = F(s, \theta) - F(s,
  \overline{\theta})\\
  \dfrac{\partial F(s, \theta)}{\partial \theta} = \dfrac{R(s)}{(1 +
    R(s) G(s, \theta))^2} \dfrac{\partial G(s, \theta)}{\partial
    \theta}
\end{array}
\]
Si ricava cha la variazione relativa alla $F(s, \theta)$ \`e:
\[
E_F(s, \theta, \overline{\theta}) = \dfrac{\Delta F(s, \theta,
  \overline{\theta})}{F(s, \overline{\theta})} \simeq \dfrac{1}{F(s,
  \overline{\theta})} \left. \dfrac{\partial F(s, \theta)}{\partial
  \theta} \right |_{\theta = \overline{\theta}}
\]
\[
\dfrac{\Delta G(s, \theta, \overline{\theta})}{(1 + R(s)G(s,
  \overline{\theta}))G(s, \overline{\theta})} = S(s,
\overline{\theta})E_G(s, \theta, \overline{\theta})
\]
dove $S(s, \overline{\theta})$ \`e la funzione di sensitivit\`a
nominale. In particolare:
\[
|E_F(j \omega, \theta, \overline{\theta})| = |S(j \omega,
\overline{\theta})||E_G(j \omega, \theta, \overline{\theta})|
\]
quindi
\[
|S(j \omega, \overline{\theta})| = \dfrac{|E_F(j \omega, \theta,
  \overline{\theta})|}{|E_G(j \omega, \theta, \overline{\theta})|}
\]
Per cui nell'intervallo in cui $|S(j \omega, \overline{\theta})| \ll
1$ la presenza della retroazione produce una notevole attenuazione
dell'effetto dell'incertezza. Dato che tipicamente $|S(j \omega,
\overline{\theta})| < 1$ con $\omega < \omega_c$, il feedback
garantisce un buon livello di insensitivit\`a rispertto a incertezze
parametriche all'interno della banda passante del sistema di
controllo.

\section{Sintesi dei sistemi di controlli a tempo continui}
Il progetto di un sistema di controllo in retroazione, si concentra
alla scelta accurata della $R(s)$.

\subsection{Requisiti di riferimento per il progetto di un
  controllore}
\input{./tex/schemaDiControlloARetroazione.tex}
Supponendo di conoscere il sistema sotto controllo $G(s)$, il progetto
consiste nella scelta di $R(s)$ in modo tale che il sistema di
controllo fornisca determinate prestazioni e risponda a determinati
requisiti. Si \`e visto in precedenza che gran parte dei requisiti
possono essere soddisfatti imponendo specifiche sulla funzione di
anello $L(s) = R(s) G(s)$. Si assumer\`a in seguito che la $L(s)$
soddisfi le condizioni di applicabilit\`a del criterio di Bode ($\mu >
0$ e $\varphi_m > 0^{\circ}$) per cui $G(s)$ non abbia poli a parte
reale positiva.

\subsection{Principali requisiti}
\subsubsection{Stabilit\`a in condizioni nominali}
Se il Criterio di Bode \`e applicabile, \`e garantita l'asintotica
stabilit\`a. Bisogna evitare cancellazioni tra singolarit\`a con parte
reale maggiore di zero.
\subsubsection{Stabilit\`a in condizioni perturbate}
L'obiettivo \`e ottenere un elevato grado di robustezza nei confronti
di incertezze sulla $G(s)$. Un modo per ottenere ci\`o \`e quello di
imporre valori elevati del margine di fase $\varphi_m$ e del margine
di guadagno $k_m$. La scelta di $\omega_c$, per evitare eventuali
ritardi di tempo di cui non si \`e tenuto conto, possono condurre ad
instantilit\`a. Ricordiamo che un ritardo di tempo porta a:
\[
\varphi_{m_{\tau}} = \varphi_m - \omega_c \tau \dfrac{180}{\pi}
\]
\subsubsection{Precisione statica}
Per ridurre l'ampiezza dell'errore all'infinito $e_{\infty}$ in
presenza di $W$ e $d$ canonici, occorre aumentare il tipo $g$ e/o il
guadagno $\mu$ della $L(s)$.
\subsubsection{Precisione dinamica}
Per permettere all'uscita $y$ di seguire fedelmente il riferimento
$W$, anche quando questo varia velocemente, occorre aumentare la banda
passante della $F(s)$ ed ottenere, quindi, una $\omega_c$
sufficientemente elevata.

Se si vogliono limitare le sovraelongazioni ed evitare eccessive
oscillazioni della risposta al gradino, bisogna imporre uno
smorzamento $\zeta$ minimo ai poli dominanti di $F(s)$, cio\`e
richiedere un margine di fase $\varphi_m$ elevato.

Le specifiche del dominio del tempo relative al tempo di assestamento
$T_{a\varepsilon}$ e alla sovraelongazione $S\%$ possono essere
tradotte in limiti inferiori, sui valori di $\omega_c$ e $\varphi_m$.

\subsubsection{Attenuazione dell'effetto del disturbo $d$}
Analizzando le propriet\`a della $S(s)$, bisogna fare in modo che
risulti:
\[
|L(j \omega)| \gg 1
\]
nell'intervallo di pulsazioni in cui \`e concentrato lo spettro del
disturbo $d$. Ci\`o implica un vincolo sul valore minimo della
$\omega_c$.

\subsubsection{Attenuazione dell'effetto del disturbo $n$}
Se lo spettro di $n$ \`e tipicamente confinato ad alta frequenza
questo requisito implica un vincolo sul massimo valore di $\omega_c$.

\subsubsection{Moderazione della varibile di controllo}
Dalla $Q(s)$ si evince che la propriet\`a di moderazione \`e legata al
valore di $|R(j \omega)|$ a pulsazioni maggiori di $\omega_c$. \`E
opportuno mantenere limitato $|R(j \omega)|$ per $\omega > \omega_c$ o
evitare che nello stesso insieme di pulsazioni risulti $|L(j \omega)|
\gg |G(j \omega)|$.

\subsubsection{Realizzabilit\`a del regolatore}
Per soddisfare requisiti di realizzabilit\`a del regolatore (deve
essere un sistema dinamico proprio) \`e necessario imporre che
risulti:
\[
-k_L \leq -k_G \Rightarrow k_L > k_G
\]
dove $k_L$ e $k_G$ sono le pendenze asintotiche per $\omega \to
\infty$ dei diagrammi di Bode del $|L(j \omega)|$ e $|G(j \omega)|$.

%%%%%%%%%%%%%%%%%%%%%%%
% APPROCCI ALLA SINTESI
%%%%%%%%%%%%%%%%%%%%%%%
\chapter{Approcci alla sintesi}
Un primo approccio alla progettazione del controllore \`e descritto
nei passi seguenti:
\begin{itemize}
\item Traduzione dei requisiti del sistema di controllo in vincoli di
  progetto sulla $L(s)$ con l'aggiunta di ulteriori condizioni su
  margine di fase $\varphi_m$ e/o margine di guadagno $k_m$ e
  sull'assenza di cancellazioni tra singolarit\`a a parte reale
  positiva;
\item Individuazione di una funzione $L(s)$ il cui diagramma di Bode
  del modulo giaccia nella regione di ammissibilit\`a e che soddisfi
  anche i rimanenti requisiti o vincoli;
\item Determinazione della funzione di trasferimento del regolatore
  attraverso la relazione
  \[
  R(s) = \dfrac{L(s)}{G(s)}
  \]
\end{itemize}
Tale approccio per\`o, se da una parte rispetta per costruzione tutti
i requisiti posti inizialmente, dall'altra non permette di tener
facilmente conto di vincoli aggiuntivi relativi alla struttura del
regolatore, in quanto nelle applicazioni reali non tutti gli
obbiettivi sono noti a priori in maniera chiara, precisa ed
esauriente.

Si preferisce, quindi, un approccio noto come {\em sintesi per
  tentativi}\index{Sintesi per tentativi}: si considerano dapprima
regolatori strutturalmente semplici e li si complica poco per volta in
modo da rispettare tutte le specifiche di progetto, valutando di volta
in volta i risultati tramite diagrammi di Bode di $L(j
\omega)$. Seguendo questo approccio \`e conveniente esprimere la
$R(s)$ come:
\[
R(s) = R_1(s) R_2(s)
\]
con
\[
R_1(s) = \dfrac{\mu_R}{s^r}
\]
parte statica del regolatore e $r$ tipo della $R(s)$ e con
\[
R_2(s) = \dfrac{\prod_i (1 + \tau_i s) \prod_i (1 + \frac{2\xi_i
    s}{\alpha_{n_i}} + \frac{s^2}{\alpha^2_{n_i}})}{\prod_i (1 + T_i s) \prod_i (1 + \frac{2\zeta_i
    s}{\omega_{n_i}} + \frac{s^2}{\omega^2_{n_i}})}
\]
parte dinamica o rete stabilizzatrice.
\section{Il progetto}
Il progetto allora si articola in due fasi:
\begin{enumerate}
\item Assumendo il sistema retroazionato asintoticamente stabile al
  termine della sintesi, si sceglie $R_1(s)$ (ovvero il tipo $r$ e il
  guadagno $\mu_R$ del regolatore) in maniera tale da soddisfare le
  specifiche di progetto statico;
\item In un secondo momento si considera la possibilit\`a di
  introdurre un fattore $R_2(s) \neq 1$ per assicurare l'asintotica
  stabilit\`a e il rispetto di tutti gli altri vincoli di progetto
  (... dinamico). $R_2(s)$ \`e utilizzata per modificare
  opportunamente le caratteristiche della $L(s)$ a pulsazione diversa
  da zero.
\end{enumerate}
%%%%%%%%%%%%%%%%%%%%
% LUOGO DELLE RADICI
%%%%%%%%%%%%%%%%%%%%
\chapter{Luogo delle radici}
Un'altra tecnica di analisi e sintesi dei sistemi di controllo in
retroazione per sistemi SISO \`e la tecnica del Luogo delle
Radici. Attraverso una particolare rappresentazione grafica, consente
di ottenere informazioni circa l'esatta collocazione dei poli del
sistema a ciclo chiuso a partire dalla funzione a ciclo aperto $L(s)$.

Tale tecnica \`e applicabile anche nel caso di sistemi di controllo
instabili ed in situazioni in cui non sono soddistatte le condizioni
di applicabilit\`a del criterio di Bode.

\section{Definizione e propriet\`a}
\input{./tex/schemaABlocchiLs}
La funzione di trasferimento d'anello pu\`o essere espressa come
\begin{equation}\label{eq:luogoRadiciLs}
L(s) = \rho \dfrac{\prod\limits_{i = 1}^{m} (s + z_i)}{\prod\limits_{i = 1}^{n} (s +
  p_i)} = \rho \dfrac{N(s)}{D(s)}
\end{equation}
dove $\rho$ \`e la costante di trasferimento. Lo schema di riferimento
\`e quello mostrato in figura \ref{fig:schemaABlocchiLs}. Lo schema
non presenta riferimenti ai disturbi perch\`e l'attenuazione \`e
concentrata esclusivamente nei poli del sistema a ciclo chiuso ovvero
nella seguente equazione caratteristica:
\begin{equation}
  1 + L(s) = 0
\end{equation}
Il problema \`e tipicamente quello di determinare come si modificano i
poli in anello chiuso al variare di $\rho$ che \`e proporzionale al
guadagno d'anello $\mu$:
\[
F(s) = \rho \dfrac{\rho \dfrac{N(s)}{D(s)}}{1 + \rho
  \dfrac{N(s)}{D(s)}} = \dfrac{\rho N(s)}{D(s) + \rho N(s)}
\]
Quindi al variare di $\rho$, variano i poli di $F(s)$ ed al variare
dei poli c'\`e il luogo delle radici.

\section{Caratterizzazione del luogo}
Consideriamo il seguente esempio:
\[
L(s) = \rho \dfrac{1}{s + \frac{5}{2}}
\]
Quindi
\[
F(s) = \dfrac{\rho \dfrac{1}{s + \frac{5}{2}}}{1 + \rho \dfrac{1}{s +
    \frac{5}{2}}} = \dfrac{\rho}{s + \frac{5}{2} + \rho}
\]
$\overline{s}_f = \left(- \dfrac{5}{2} - \rho \right)$ \`e il polo di $F(s)$.
Variando $\rho$ variamo i poli:
\begin{definizione}
  Il luogo delle radici \`e il luogo descritto nel piano complesso
  dalle radici dell'equazione caratteristica al variare di $\rho$ da
  $- \infty$ a $+ \infty$, con $\rho \neq 0$
\end{definizione}
Abbiamo quindi tre diversi scenari:
\begin{itemize}
\item $\rho = 0$ \`E il caso in cui i poli di $F(s)$ sono i poli di
  $L(s)$, cio\`e l'assenza di retroazione;
\item $\rho > 0$ \`E il {\em luogo diretto}\index{Luogo diretto}:
  comprende tutti i punti dell'asse reale che lasciano alla propria
  destra un numero dispari di poli e zeri di $L(s)$. Nei nostri studi,
  saremo sempre in questo scenario;
\item $\rho < 0$ \`E il {\em luogo inverso}\index{Luogo inverso}.
\end{itemize}
Se riconsiderdiamo l'esempio precedente, noteremo che all'aumentare di
$\rho$, il polo si muove verso sinistra. Avremo cos\`i una $F(s)$
sempre pi\`u veloce. Di conseguenza, $\omega_c$ si muover\`a verso
destra e avremo una banda passante sempre maggiore.

Consideriamo un ulteriore esempio:
\[
L(s) = R(s)G(s) = \mu_R \dfrac{s + 1}{2s + 1} = \rho \dfrac{s + 1}{s + \frac{1}{2}}
\]
con $\rho = \dfrac{\mu_R}{2}$
\[
\left\{
\begin{array}{l}
  N(s) = s + 1\\
  D(s) = \overline{s}_F + \frac{1}{2}
\end{array}
\right .
\]
\[
\begin{array}{l}
  D(s) + \rho N(s) = 0 \;\;\;\textrm{Poli a ciclio chiuso}\\
  \overline{s}_F + \frac{1}{2} + \rho (s + 1) = 0\\
  (1 + \rho) \overline{s}_F = - \frac{1}{2} - \rho\\
  \overline{s}_F = \dfrac{- \frac{1}{2} - \rho}{1 + \rho}\\
  \lim_{\rho \to \infty} \overline{s}_F = -1
\end{array}
\]
Quando $\rho \to \infty$, l'unico polo finisce nell'unico zero. In
generale, vale la regola:
\[
\left\{
\begin{array}{l}
  m \textrm{ rami vanno negli zeri}\\
  \nu = n - m \textrm{ rami vanno all'infinito}
\end{array}
\right .
\]

Per determinare la forma del luogo delle radici, sfruttiamo
l'equazione
\[
\begin{array}{l}
  \rho \dfrac{N(s)}{D(s)} + 1 = 0\\
  \dfrac{N(s)}{D(s)} = - \dfrac{1}{\rho}\\
  \dfrac{D(s)}{N(s)} = - \rho
\end{array}
\]
quindi i valori di $s$ che soddisfano tale equazione per qualche
valore reale di $\rho$ corrispondono ai punti che appartengono al
luogo delle radici. La relazione complessa equivale alle relazioni
espresse in termini di modulo e fase:
\begin{equation}\label{eq:luogoRadiciModulo}
  \dfrac{|N(s)|}{|D(s)|} = \dfrac{1}{|\rho|} \Rightarrow
  \dfrac{|D(s)|}{|N(s)|} = |\rho|
\end{equation}
che caratterizza completamente l'aspetto geometrico del
luogo. Ricordando che la fase di un numero negativo \`e $180^{\circ}$
e la fase di un rapporto \`e la differenza delle fasi:
\begin{equation}\label{eq:luogoRadiciFasi}
  \begin{array}{l}
    arg N(s) - arg D(s) = 180^{\circ} - arg \rho = \\
    \left \{
    \begin{array}{lcl}
      (2k + 1)\cdot 180^{\circ} &,& \rho > 0 \;\;,\; k \textrm{
        intero}\\
      2k \cdot 180^{\circ} &,& \rho < 0 \;\;,\; k \textrm{ intero}
    \end{array}
    \right .
  \end{array}
\end{equation}
che determina la punteggiatura del luogo rispetto a $\rho$.

Sfruttando l'equazione \ref{eq:luogoRadiciLs}, otteniamo:
\begin{equation}
  \begin{array}{l}
    arg N(s) = arg \prod\limits_{i = 1}^{m} (s + z_i) = \sum_{i =
      1}^{m} arg (s + z_i) = \sum_{i = 1}^{m}\theta_i\\
    arg D(s) = arg \prod\limits_{i = 1}^{n} (s + p_i) = \sum_{i =
      1}^{n} arg (s + p_i) = \sum_{i = 1}^{m}\varphi_i
  \end{array}
\end{equation}
dove gli angoli $\theta_i$ e $\varphi_i$ rappresentano rispettivamente
l'angolo formato con il semiasse $\mathfrak{R}e > 0$ del vettore
congiungente lo zero $(-z_i)$ o il polo $(-p_i)$ al generico punto s
del piano.

Un punto $s$ del piano appartiene al luogo diretto semiasse
\[
\sum_i \theta_i - \sum_i \varphi_i = (2k + 1) \pi
\]
cio\`e ad un multiplo dispari di $\pi$:
\[
\sum_{i = 1}^{m} arg (s + z_i) - \sum_{i = 1}^{n} arg (s + p_i) = (2k
+ 1) \pi \;\;\; k = 0,1,2,...,(n - m -1)
\]
Notiamo anche che
\[
|N(s)| = \prod\limits_{i = 1}^{m} |s + z_i|
\]
\`e il prodotto delle distanze del generico punto $s$ dagli zeri e
\[
|D(s)| = \prod\limits_{i = 1}^{n} |s + p_i|
\]
\`e il prodotto delle distanze del generico punto $s$ dai poli.

\section{Regole di tracciamento}
Nota: il baricentro\index{Baricentro} \`e la somma dei poli in anello
chiuso diviso per $n$.

Ponendo $n$ ed $m$ i gradi del denominatore e del numeratore di
$L(s)$, strettamente proprie, e $\nu = n - m > 0$ il grado relativo,
il tracciamento del luogo delle radici avviene come segue:
\begin{enumerate}
\item Il luogo delle radici \`e composto da $2n$ rami: $n$ del luogo
  diretto e $n$ del luogo inverso.
  \begin{equation}\label{eq:polinomioCaratteristicoFs}
    D(s) + \rho N(s) = 0
  \end{equation}
  che ha $n$ radici complesse e dipendenti da $\rho$
\item Il luogo delle radici \`e simmetrico rispetto all'asse reale;
\item I rami partono dai poli di $L(s)$. Per $|\rho| \to 0$ le radici
  dell'equazione \ref{eq:polinomioCaratteristicoFs} convergono verso i
  poli della funzione d'anello $L(s)$;
\item Sia nel luogo diretto che nel luogo inverso, per $|\rho| \to
  \infty$, $m$ rami arrivano negli zeri di $L(s)$ e i restanti $\nu
  \to \infty$. Quando $|\rho| \to \infty$ l'equazione
  \ref{eq:polinomioCaratteristicoFs} diventa
  \[
  N(s) = 0
  \]
  che ha solo $m$ radici: gli zeri di $L(s)$.
\item I rami che vanno all'infinito, lo fanno lungo gli $\nu$ asintoti
  che intersecano l'asse reale nel punto di ascissa
  \begin{equation}\label{eq:xa}
    x_a = \dfrac{1}{\nu} \left( \sum_{i = 1}^{m} z_i - \sum_{i =
      1}^{n} p_i  \right) 
  \end{equation}
  e formano con l'asse reale angoli pari a:
  \[
  \psi_{ak} =
  \left \{
  \begin{array}{llll}
    \dfrac{(2k + 1) \cdot 180^{\circ}}{\nu} &, k=0,1,...,\nu - 1 &,
    \rho > 0 & LD\\
    \dfrac{2k \cdot 180^{\circ}}{\nu} &, k=0,1,...,\nu - 1 &,
    \rho < 0 & LI
  \end{array}
  \right .
  \]
\item Tutti i punti dell'asse reale, tranne quelli corrispondenti a
  singolarit\`a di $L(s)$, appartengono a luogo delle radici. Fanno
  parte del luogo diretto tutti i punti a sinistra di un numero
  dispari di singolarit\`a di $L(s)$. Fanno parte del luogo inverso,
  tutti i punti a sinistra di un numero pari di singolarit\`a di
  $L(s)$.
  \begin{dimostrazione}
    Preso un generico punto $s$ sull'asse reale, per ogni
    singolarit\`a reale alla sua sinistra e ogni coppia di
    singolarit\`a complesse, produce un contributo a
    \[
    arg N(s) - arg D(s)
    \]
    nullo o pari a $\pm 360^{\circ}$. Invece per ogni
    singolarit\`a alla sua destra d\`a un contributo di $\pm
    180^{\circ}$. Affinch\`e la somma dei vari termini sia pari ad un
    multiplo dispari (o pari) di $180^{\circ}$, il punto deve essere a
    sinistra di un numero dispari (o pari) di singolarit\`a.
  \end{dimostrazione}
\item Quando $\nu \geq 2$, il baricentro del luogo delle radici non
  dipende da $\rho$ ed \`e costante e coincide col punto di ascissa:
  \begin{equation}\label{eq:xb}
    x_b = - \dfrac{1}{n} \sum_{i = 1}^{n} p_i
  \end{equation}
  \begin{dimostrazione}
    In un polinonio di grado $n$, il rapporto tra i coefficienti del
    termine di grado $n - 1$ e quello di grado $n$, cambiato di segno,
    \`e sempre uguale alla somma delle radici ( e quindi alla somma
    delle parti reali). Quando $\nu \geq 2$ i due coefficienti
    dell'equazione \ref{eq:polinomioCaratteristicoFs} non dipende da
    $\rho$ e quindi al variare di $\rho$ la somma delle radici rimane
    costante, e coincide col baricentro moltiplicato per $n$. Poich\`e
    per $\rho = 0$ il baricentro coincide con il punto di ascissa
    $x_b$, la propriet\`a \`e dimostrata.
  \end{dimostrazione}
\item Si consideri un polo $-p_j$ di $L(s)$ con molteplicit\`a
  $h_j$. Gli $h_j$ rami del luogo diretto e gli $h_j$ rami del luogo
  inverso che partono da questo polo, hanno in quel punto tangenti che
  formano con l'asse reale angoli pari a
  \[
  \alpha_{jk} =
  \left \{
  \begin{array}{lll}
    \dfrac{1}{h_j} \left[ (2k + 1) \cdot 180^{\circ} + \sum\limits_{i =
        1}^{m} \theta_i - \sum\limits_{i \neq j} \varphi_i \right], & k=0, 1,
    ..., h_j - 1, & \rho > 0 LD\\
    \dfrac{1}{h_j} \left[ 2k \cdot 180^{\circ} + \sum\limits_{i =
        1}^{m} \theta_i - \sum\limits_{i \neq j} \varphi_i \right], & k=0, 1,
    ..., h_j - 1, & \rho < 0 LI
  \end{array}
  \right .
  \]
  dove gli angoli $\varphi_i$ e $\theta_i$ sono quelli calcolati in
  base alla F3, considerando i vettori congiungenti il punto $s =
  -p_j$ agli altri poli e agli zeri. Se il polo \`e semplice, la
  tangente del ramo uscente presenta un angolo pari a:
  \[
  a_j =
  \left \{
  \begin{array}{ll}
    180^{\circ} + \sum\limits_{i = 1}^{m} \theta_i - \sum\limits_{i \neq j}
    \varphi_i &, \rho > 0 LD\\
    \sum\limits_{i = 1}^{m} \theta_i - \sum\limits_{i \neq j} \varphi_i &, \rho < 0 LI
  \end{array}
    \right .
  \]
\item Si consideri lo zero $-z_i$ di $L(s)$ con molteplicit\`a
  $h_j$. Gli $h_j$ rami del luogo diretto LD e gli $h_j$ rami del
  luogo inverso LI che arrivano in questo zero hanno in quel punto
  tangenti che formano con l'asse reale $\mathfrak{R}e$ angoli uguali
  a:
  \[
  \beta_{jk} =
  \left\{
  \begin{array}{lll}
    \dfrac{1}{h_j}\left[ (2k + 1)\cdot 180^{\circ} - \sum\limits_{i
        \neq 1} \theta_i + \sum\limits_{i=1}^{n}\varphi_i \right] & k
    = 0, 1, ..., h_j - 1 & \rho > 0\;LD\\
    \dfrac{1}{h_j}\left[ 2k\cdot 180^{\circ} - \sum\limits_{i
        \neq 1} \theta_i + \sum\limits_{i=1}^{n}\varphi_i \right] & k
    = 0, 1, ..., h_j - 1 & \rho < 0\;LI\\
  \end{array}
  \right .
  \]
  dove gli angoli $\theta_i$ e $\varphi_i$ sono quelli che formano i
  vettori congiungenti il punto $-z_i$ agli altri zeri e ai poli.

  Se lo zero \`e semplice, la tangente del ramo entrante presenta un
  angolo pari a
  \[
  \beta_j =
  \left\{
  \begin{array}{ll}
  180^{\circ} - \sum\limits_{i \neq j}\theta_i + \sum\limits_{i = j}^n
  \varphi_i &, \rho > 0 \; LD\\
  - \sum\limits_{i \neq j}\theta_i + \sum\limits_{i = j}^n
  \varphi_i &, \rho < 0 \; LI\\
  \end{array}
  \right .
  \]
\item Eventuali punti di incrocio di rami sull'asse reale si possono
  determinare i minimi e i massimi relativi della funzione
  \[
  \gamma(x) = -\dfrac{D(x)}{N(x)}
  \]
  con $x$ reale. Se $\overline{x}$ \`e un punto di minimo e $s =
  \overline{x}$ appartiene al luogo diretto, esistono 2 rami complessi
  che intersecano l'asse reale in $\overline{x}$; se $\overline{x}$
  \`e un punto di massimo e $s = \overline{x}$ appartiene al luogo
  diretto, esistono 2 rami reali che si incontrano in $\overline{x}$ e
  si separano diventando complessi. La situazione \`e inversa nel caso
  del luogo inverso.
\item Per ogni punto del luogo, il valore di $|\rho|$ \`e dato dato
  \[
  |\rho| = \dfrac{\prod\limits_{i = 1}^{n} \eta_i}{\prod\limits_{i =
      1}^{m}\lambda_i} 
  \]
  con $\lambda_i$ e $\eta_i$ che rappresentano le distanze del punto
  dagli zeri e dai poli di $L(s)$.
\end{enumerate}
Nota: con $\rho > 0$ (LD) l'angolo con il quale il luogo delle radici
lascia un polo $p_i$ in anello aperto vale:
\[
 \varphi_{p_i} = (2 \nu +1)\pi + \sum\limits_{j = 1}^{m} arg(p_i -
 z_j) - \sum\limits_{j = 1\\j\neq 1} arg(p_i - p_j)
\]
con $\nu = 0, 1, ... , n-m$.
Per lo zero, invece, l'angolo \`e:
\[
 \varphi_{p_i} = (2 \nu +1)\pi - \sum\limits_{j = 1}^{m} arg(z_i -
 z_j) + \sum\limits_{j = 1\\j\neq 1} arg(z_i - p_j)
\]

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\section{Regola del baricentro}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
La regola del baricentro \`e applicabile solo se l'eccesso poli-zeri
\`e maggiore o uguale di 2:
\[
\nu = n - m \geq 2
\]
Fatta questa supposizione, data una funzione di trasferimento ad
anello aperto 
\begin{equation}\label{eq:baricentro01}
L(s) = \rho \dfrac{N(s)}{D(s)} = \rho \dfrac{\prod\limits_{i =
    1}^{m} (s + z_i)}{\prod\limits_{i = 1}^{n} (s + p_i)}
\end{equation}
la funzione di trasferimento a ciclo chiuso \`e data data
\begin{equation}\label{eq:baricentro02}
F(s) = \dfrac{L(s)}{1 + L(s)} = \dfrac{\rho N(s)}{D(s) + \rho N(s)} =
\dfrac{\rho \prod\limits_{i = 1}^{m} (s + z_i)}{\prod\limits_{i =
    1}^{n} (s + p_{F_i})}
\end{equation}
dove con $-p_{F_i}$ sono indicati i poli della funzione di
trasferimento a ciclo chiuso $F(s)$, mentre $-p_i$ e $-z_i$ sono i
poli e gli zeri della funzione di trasferimento ad anello aperto
$L(s)$. 

Se consideriamo nell'equazione~\ref{eq:baricentro02} i valori di $N(s)$
e $D(s)$ espressi nell'equazione~\ref{eq:baricentro01} ottiamo la
seguente uguaglianza
\begin{equation}\label{eq:baricentro03}
  \prod\limits_{i = 1}^{n} (s + p_i) + \prod\limits_{i = 1}^{m} (s +
  z_i) = \prod\limits_{i = 1}^{n} (s + p_{F_i})
\end{equation}
\[
s^n + \left( \sum\limits_{i = 1}^{n} p_i \right)\cdot s^{n - 1} + 
... = s^n + \left( \sum\limits_{i = 1}^{n} p_{F_i} \right)\cdot s^{n - 1} +
\]
Quindi
\[
\sum\limits_{i = 1}^{n} p_{F_i} = \sum\limits_{i = 1}^{m} p_i
\]
cio\`e
\begin{definizione}
  La somma dei poli della funzione di trasferimento a ciclo chiuso
  \`e pari alla somma dei poli della funzione di trasferimento a ciclo
  aperto.
\end{definizione}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\section{Regola degli angoli}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
Data una funzione di trasferimento ad anello aperto 
\begin{equation}\label{eq:angoli01}
L(s) = \rho \dfrac{N(s)}{D(s)} = \rho \dfrac{\prod\limits_{i =
    1}^{m} (s + z_i)}{\prod\limits_{i = 1}^{n} (s + p_i)}
\end{equation}
la funzione di trasferimento a ciclo chiuso \`e data data
\begin{equation}\label{eq:angoli02}
F(s) = \dfrac{L(s)}{1 + L(s)} =  \dfrac{\rho N(s)}{D(s) + \rho N(s)}
\end{equation}
I poli della $F(s)$ sono le radici di
\[
D(s) + \rho N(s) = 0
\]
che possiamo riscrivere come
\begin{equation}\label{eq:angoli03}
- \rho = \dfrac{D(s)}{N(s)}
\end{equation}

Supponiamo di voler calcolare l'angolo di partenza del luogo delle
radici dal generico polo $-p_1$. Calcolando la fase del primo e del
secondo membro dell'equazione~\ref{eq:angoli03}, per ogni valore di
$s$ corrispondente ad un punto del luogo delle ragici deve valere:
\begin{equation}\label{eq:angoli04}
arg(- \rho) = arg \left(\dfrac{D(s)}{N(s)} \right)
\end{equation}
Supponendo $\rho > 0$
\[
arg(- \rho) = (2k + 1)\pi
\]
\[
arg(D(s)) = arg\left( \prod\limits_{i = 1}^{n}(s + p_i) \right) =
\sum\limits_{i = 1}^{n} arg(s + p_i) = arg(s + p_i) + \sum\limits_{i =
2}^{n} arg(s + p_i)
\]
\[
arg(N(s)) = arg\left( \prod\limits_{i = 1}^{m}(s + z_i) \right) = \sum\limits_{i =
2}^{n} arg(s + z_i)
\]
Sfruttando l'uguaglianza
\[
arg \left( \dfrac{D(s)}{N(s)}\right) = arg(D(s)) - arg(N(s))
\]
sostituendo nell'equazione~\ref{eq:angoli03}, si ha:
\begin{equation}\label{eq:angoli05}
  arg(s + p_i) = - \sum\limits_{i = 2}^{n} arg(s + p_i) +
  \sum\limits_{i = 1}^{m} arg(s + z_i) + (2k + 1)\pi
\end{equation}

L'angolo con cui il luogo delle radici parte da $-p_1$ \`e dato dalla
fase del vettore $s + p_1$ quando $s$ tende a $-p_1$, come mostrato in
figura~\ref{fig:regolaAngoli}.
\begin{figure}[!h]
  \begin{center}
    \includegraphics[scale=0.3]{./images/regolaAngoli}
    \caption{Regola degli angoli}\label{fig:regolaAngoli}
  \end{center}
\end{figure}
Quindi nell'equazione~\ref{eq:angoli05} bisogna valutare il limite di
entrambi i membri per $s \to -p_1$:
\[
\lim_{s \to -p_1} arg(s + p_i) = - \lim_{s \to -p_1}\sum\limits_{i = 2}^{n} arg(s + p_i) +
  \lim_{s \to -p_1}\sum\limits_{i = 1}^{m} arg(s + z_i) + (2k + 1)\pi
\]
\[
\lim_{s \to -p_1} arg(s + p_i) = - \sum\limits_{i = 2}^{n} arg(-p_1 + p_i) +
  \sum\limits_{i = 1}^{m} arg(-p_1 + z_i) + (2k + 1)\pi
\]
che \`e l'espressione cercata.

Analogamente si possono calcolare gli angoli di arrivo del luogo delle
radici negli zeri e nel caso di poli o zeri con molteplicit\`a
maggiore di uno.
\section{Vincoli nell'uso del luogo delle radici}
\begin{figure}[!h]
  \begin{center}
    \includegraphics[scale=0.4]{./images/vincoliLuogo}
    \caption{Vincoli nell'uso del luogo delle
      radici}\label{fig:vincoliLuogo}
  \end{center}
\end{figure}
\subsection{Vincoli sullo smorzamento}
I vincoli di tipo
\[
\zeta \geq \overline{\zeta}
\]
relativi allo smorzamento dei poli dominanti, si possono tradurre
nell'imporre che i poli in anello chiuso siano confinati nella parte
del piano complesso individuata da due rette simmetriche rispetto
all'asse reale che formano un angolo pari ad $arccos
\overline{\zeta}$ come mostrato nella sottofigura $a$ della
figura~\ref{fig:vincoliLuogo}.
\subsection{Vincoli sulla pulsanzione}
I vincoli sulla pulsanzione naturale dei poli dominanti del tipo
\[
\omega_n \geq \overline{\omega_n}
\]
si possono tradurre nell'imporre che tali poli giacciano nella regione
esterna all'anello di raggio $\overline{\omega_n}$ e centro
nell'origine, mostrato nella sottofigura $b$ della
figura~\ref{fig:vincoliLuogo}.
\subsection{Vincolo sul tempo di assestamento}
Un eventuale vincolo sul tempo massimo di assestamento pu\`o essere
visto come un vincolo sulla parte reale $-\theta$ dei poli ad anello
chiuso $(p_i = - \theta \pm \beta j)$ che definisce il semipiano
$- \overline{\theta} \geq - \theta$, mostrato nella sottofigura $c$ della
figura~\ref{fig:vincoliLuogo}. Ricordiamo che
\[
\begin{array}{l}
  \theta = - \zeta \omega_n\\
  \beta = \omega_n \sqrt{1 - \zeta^2}
\end{array}
\]
%%%%%%%%%%%%%%%%%%%%%%%%%%%
\chapter{Regolatori comuni}
%%%%%%%%%%%%%%%%%%%%%%%%%%%
\section{Regolatore proporzionale}
\[
R_P(s) = \mu_R \;\;o\;\; k_P
\]
\section{Regolatore integrale}
\[
R_I(s) = \dfrac{\mu_R}{s} \;\;o\;\; \dfrac{k_I}{s}
\]
\section{Regolatore proporzionale-integrale}
\[
R_{PI}(s) = k_P + \dfrac{k_I}{s}
\]
\begin{itemize}
\item $k_P + \dfrac{s + \frac{k_I}{k_P}}{s}$
\item $k_I + \dfrac{1 + s\frac{k_P}{k_I}}{s}$
\end{itemize}
Un polo nell'origine; uno zero dove scelgo; un guadagno che scelgo.
%%%%%%%%%%%%%%%%%%%%%%%%
\section{Regolatore PID}
%%%%%%%%%%%%%%%%%%%%%%%%
PID sta per proporzionale-integrale-derivativo. La struttura di un PID
\`e introdotta secondo la considerazione empirica che la variabile di
controllo $u$ sia generata come la somma di tre contributi:
\begin{enumerate}
\item Uno proporzionale all'errore $e$ tra $w$ e $y$;
\item Uno proporzionale a $\int e$ (ovvero al suo valore medio) ed \`e
  richiesto per imporre che l'errore si annulli asintoticamente a
  fronte di segnali di riferimento o disturbi additivi costanti;
\item Uno proporzionale a $de(t)$ e tenta di anticipare l'andamento
  dell'errore negli istanti futuri: se $de(t) > 0$, cos\`i come il
  guadagno del sistema, \`e opportuno aumentare $\mu$ per provocare un
  aumento di $y$ e quindi una diminuzione di $e$.
\end{enumerate}
La legge di controllo tra $e$ ed $u$ \`e quindi:
\[
u(t) = k_P e(t) + k_I\int\limits_{t_0}^{t} e(\tau) d\tau + k_D
\dfrac{de(t)}{dt}
\]
dove $k_P$ \`e il coefficiente dell'azione proporzionale, $k_I$ \`e il
coefficiente dell'azione integrale e $k_D$ \`e il coefficiente
dell'azione derivativa. I tre coefficiente sono costanti e maggiori di
zero.
\[
R_{PID}(s) = k_P + \dfrac{k_I}{s} + k_Ds = \dfrac{k_D s^2 + k_P s +
  k_I}{s} 
\]
Volendo esprimere $R_{PID}(s)$ in funzione del tempo, con
\[
\begin{array}{ll}
  T_I = \dfrac{k_P}{k_I} & \textrm{tempo di reset o integrale}\\
  T_D = \dfrac{k_D}{k_p} & \textrm{tempo derivativo}
\end{array}
\]
si ha
\[
R_{PID}(s) = k_P + \dfrac{k_p}{T_I s} + k_P T_D s = k_P (1 +
\dfrac{1}{T_I s} + T_D s)
\]
\begin{equation}
  R_{PID}(s) = k_P \cdot \dfrac{T_I T_D s^2 + T_I s + 1}{T_I s}
\end{equation}
\section{Reti correttrici o stabilizzatrici}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\subsection{Rete anticipatrice}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
Questa rete produce due effetti:
\begin{itemize}
\item un anticipo di fase: il margine di fase $\varphi_m$ aumenta
\item un aumento della banda passante: $\omega_n$ aumenta
\end{itemize}
\begin{equation}
  R(s) = \mu_R \dfrac{1 + \frac{s}{\overline{z}}}{1 +
    \frac{s}{\overline{p}}} \;\; \textrm{ con }\; \overline{z} < \overline{p}
\end{equation}
oppure
\begin{equation}
  \begin{array}{l}
    R(s) = \mu_R \dfrac{1 + Ts}{1 + \alpha Ts}\\
    \mu_R > 0\\
    T > 0\\
    0 < \alpha < 1
  \end{array}
\end{equation}
Questo tipo di regolatore produce un anticipo di fase. Questo anticipo
\`e massimo per una pulsazione $\overline{\omega} = \dfrac{1}{T
  \sqrt{\alpha}}$, il punto medio sul diagramma di Bode tra $\omega =
\dfrac{1}{T}$ (zero) e $\omega = \dfrac{1}{\alpha T}$ (polo).
La fase di questo controllore \`e quindi:
\begin{equation}
  arg R(j \overline{\omega}) = arctan \dfrac{1}{\sqrt{\alpha}} -
  arctan \sqrt{\alpha}
\end{equation}
L'anticipo di fase introdotto da questo tipo di regolatore favorisce,
come gi\`a detto, l'aumento del margine di fase $\varphi_m$, che vede
il suo massimo in
\[
\varphi_{max} = arcsin \dfrac{1 - \alpha}{a + \alpha}
\]
in corrispondenza di
\[
\omega_A = \sqrt{\dfrac{1}{T} \dfrac{1}{\alpha T}}
\]
L'aumento del margine di fase pu\`o essere
reso ancora pi\`u efficace diminuendo $\alpha$ fino ad arrivare ad un
contributo alla fase di circa $90^{\circ}$, anche se questo provoca
una maggiore amplificazione ad alta frequenza, con una conseguente
diminuzione della robustezza e della moderazione del controllo.

Di norma, lo zero e il polo sono ad una decade di distanza l'uno
dall'altro, ponendo cio\`e $\alpha = 0.1$. Questo consente di ottenere
un $\varphi_{max} \simeq 55^{\circ}$ in corrispondenza di
$\overline{\omega}$.

Con $\alpha = 0$ il controllore diventa un controllore
proporzionale-derivativo.
\subsection{Rete ritardatrice}
Questa rete produce due effetti:
\begin{itemize}
\item un miglioramento della precisione statica
\item una maggiore attenuazione del disturbo alle basse frequenze
\end{itemize}
\begin{equation}
  \begin{array}{l}
    R(s) = \mu_R \dfrac{1 + Ts}{1 + \alpha Ts}\\
    \mu_r > 0\\
    T > 0\\
    \alpha > 1
  \end{array}
\end{equation}
Questo tipo di regolatore consente di aumentare $|L(j \omega)|$ a
bassa frequenza, a patto di introdurre uno sfasamento negativo che
raggiunge il suo minimo $\overline{\omega} =
\dfrac{1}{T\sqrt{\alpha}}$. Per evitare che questo ritardo di fase
introdotto influenzi eccessivamente $\varphi_m$ occorre scegliere $T >
\dfrac{1}{\omega_c}$ ($T = \dfrac{10}{\omega_c}$ porta ad uno
sfasamento minore di $6^{\circ}$).

Per migliorare il margine di fase $\varphi_m$, si sceglie $\mu_R =
1$. Questo comporta un abbassamento di $|L(j \omega)|$ tale da portare
all'attraversamento dell'asse a $0_{dB}$ ad una pulsazione pi\`u
favorevole.

Per $\alpha \to \infty$, la rete assumer\`a la forma di un controllore
proporzionale-integrale
\[
\varphi_m = - arcsin \dfrac{1 - \alpha}{1 + \alpha} \;\;\textrm{ con
}\;\; \omega_A = \sqrt{\dfrac{1}{T}\dfrac{1}{\alpha T}}
\]
es. si sceglie un polo in modo che sia due decadi alla sinistra di
$\omega_c$.
\subsection{Rete a sella}
\`E la combinazione della due reti precedenti. \`E usato per sfruttare
contemporaneamente i vantaggi di entrambe le reti:
\begin{equation}
  \begin{array}{l}
  R(s) = \mu_R \dfrac{(1 + \tau_1 s)(1 + \tau_2 s)}{(1 + T_1 s)(1 +
    T_2 s)}\\
  \mu_R > 0\\
  T_1 > \tau_1 \geq \tau_2 > T_2 > 0\\
  \end{array}
\end{equation}
\begin{equation}
  \begin{array}{l}
    \lim_{\omega \to \infty} |R(j \omega)| = \mu_R\\
    \textrm{con } T_1T_2 = \tau_1 \tau_2
  \end{array}
\end{equation}
Per otterenere prestazioni soddisfacenti dall'anticipo di fase
introdotto da questa rete, si possono scegliere i poli e gli zeri
affinch\`e risulti:
\[
\tau_2 > \dfrac{1}{\omega_c} > T_2
\]
con $\omega_c$ pulsazione critica desiderata.
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% Metoto della tangente e delle aree
% 14.4.2 pagina 383
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

%%%%%%%%%%%%%%%%%%%%
% CONTROLLI DIGITALI
%%%%%%%%%%%%%%%%%%%%
\chapter{Controllo digitale}
\section{Introduzione}
\begin{figure}[!hbp]
  \begin{center}
    \includegraphics[scale=0.5]{./images/controlloDigitale00}
    \caption{Schema a blocchi di un controllo digitale}\label{fig:controlloDigitale00}
  \end{center}
\end{figure} 
La figura~\ref{fig:controlloDigitale00} mostra lo schema a blocchi di
un controllo in retroazione effettuato con un controllore digitale. Lo
schema mostra come nel mondo del controllo digitale coesistano segnali
nel dominio del tempo continuo $t$, i segnali da controllare, e
segnali nel dominio del tempo discreto $k$, i segnali manipolati dal
controllore digitale.

\subsection{Analogie col controllo analogico}
Come per il controllo analogico, anche il controllo digitale prevede
un processo $P(s)$ e una conseguente uscita $y(t)$. Dal confronto tra
la misura dell'uscita $y(t)$ e il segnale di riferimento $Rif(t)$,
otteniamo il segnale analogico di errore $e(t)$.

La misura di $y(t)$ viene effettuata con {\bo sensore
  ideale}\index{Sensore ideale}: questo sensore \`e caratterizzato da
dinamiche talmente veloci rispetto a quelle del processo $P(s)$ da poterlo
considerare istantaneo e commettendo, cos\`i, un errore
trascurabile. Se il nostro sensore fosse un sistema lineare, il luogo
delle radici vedrebbe i poli della sua funzione di trasferimento molto
a sinistra dell'asse immaginario, cosicch\`e le costanti di tempo
associate siano trascurabili. Nell'analisi in frequenza, questo si
traduce con l'avere un sensore avente una banda passante pi\`u ampia
rispetto a quella del sistema a ciclo chiuso.

\subsection{Elementi esclusivi del controllo digitale}
Il controllore digitale \`e indicato tipicamente con $R^{*}(z)$ e $T$
\`e il suo tempo di campionamento\index{Tempo di campionamento} o
tempo di attivazione del controllore\index{Tempo di attivazione}.

\subsubsection{Convertitori ADC/DAC}
L'ingresso del controllore digitale \`e un segnale discreto o sequenza
di campioni $e(kT)$, ottenuta campionando il segnale analogico di
errore $e(t)$.

Il campionatore ideale\index{Campionatore ideale} \`e un convertitore
che, quindi, dato in ingresso un segnale $e(t)$ produce in uscita un
segnale a tempo discreto:
\[
e^{*}(k) = e (kT_s + \tau_s)
\]
Ricordiamo che $T$ o $T_s$ \`e il periodo di campionamento\index{Periodo di
  campionamento}, cio\`e l'intervallo di tempo continuo tra i due
istanti in cui vengono prelevati due campioni successivi. Nel nostro
studio avremo sempre $\tau_s = 0$ perch\`e faremo riferimento a
sistemi stazionari.

Il periodo di campionamento ci consente di definire anche la
pulsazione di campionamento\index{Pulsazione di campionamento}
$\omega_s$ e la frequenza di campionamento\index{Frequenza di
  campionamento} $f_s$:
\[
\omega_s = 2 \pi
\]
\[
f_s = \dfrac{2 \pi}{T_s}
\]

L'uscita prodotta dal controllore digitale \`e il segnale discreto
$u(kT)$, che, per essere applicato in ingresso ad un processo
analogico, va convertito con un convertitore digitale/analogico DAC.
\[
u(t) = u^{*}(k), \;\;\; kT_m \leq t \leq (k + 1)T_m
\]
\`e il caso pi\`u semplice di conversione D/A. $T_m$ \`e il periodo di
mantenimento\index{Periodo di mantenimento}. Nuovamente, da $T_m$
otteniamo la frequenza di mantenimento\index{Frequenza di mantenimento}
\[
f_m = \dfrac{1}{T}
\]
e la pulsazione di mantenimento\index{Pulsazione di mantenimento}
\[
\omega_m = \dfrac{2 \pi}{T_m}
\]

Purtroppo questi convertitori, o dispositivi di interfaccia, hanno
delle dinamiche non trascurabili, non lineari, che introducono dei
ritardi di tempo nell'anello di controllo digitale. Questi ritardi,
pericolosi per la stabilit\`a del sistema, vanno adeguatamente gestiti
per realizzare un controllore digitale $R^*(z)$ efficace.

\`E comprensibile, quindi, che $R^*(z)$ dovr\`a essere progettato in
modo diverso rispetto al controllore analogico $R(s)$, al fine di
considerare le sopracitate dinamiche non trascurabili.

\section{Strumenti matematici per l'analisi dei sistemi discreti}
\begin{quote}
  {\em ``Come descrivere il legame tra la sequenza di campioni $u(kT)$
    prodotta dal controllore digitale $R^*(z)$ e la sequenza di campioni
    $e(kT)$ generata dal convertitore analogico/digitale (ADC)?''
  }
\end{quote}
\begin{figure}[!hbp]
  \begin{center}
    \includegraphics[scale=0.5]{./figures/controlloDigitaleSchemaReale}
    \caption{Schema controllo
      digitale}\label{fig:controlloDigitaleSchemaReale} 
  \end{center}
\end{figure}
Dovendo individuare una relazione ingresso-uscita, affermiamo che
esiste una {\bo certa sequenza $u(kT)$} (o $u_k$) che \`e funzione
lineare o non lineare dei campioni della {\bo sequenza $e(kT)$} (o $e_k$)
a partire dall'istante $kT$ fino all'istante $(k - m)T$ e degli stessi
campioni della {\bo sequenza di campioni $u(kT)$} a partire dall'istante $(k
- 1)T$ fino all'istante $(k - n)T$:
\begin{equation}\label{eq:lineareDifferenzeDiscreto01}
  u_k = f(e_k, e_{k-1}, ... , e_{k-m};u_{k-1}, u_{k-2}, ..., u_{k-n}, k)
\end{equation}
Ovviamente, se $n = m = 0$ si elimina la dinamica e il sistema,
continuo o discreto, diventa statico: l'uscita \`e funzione del solo
ingresso correntemente applicato.
\[
u(kT) = f(e(kT), k)
\]
Assumendo che la funzione $f$ sia lineare e dipendente da un
numero finito di valori passati delle sequenze di campioni $e(kT)$ e
$u(kT)$, possiamo riscrivere
l'equazione~\ref{eq:lineareDifferenzeDiscreto01} come:
\begin{equation}\label{eq:lineareDifferenzeDiscreto02}
  u(k) = - a_1 u (k - 1) - \;...\; - a_n u (k - n) + b_0 e [k - (n -
    m)] + \;...\; + b_m e (k - m)
\end{equation}
che \`e {\bo l'equazione lineare alle differenze di ordine
  $n$}\index{Equazione lineare alle differenze di ordine $n$} del caso
discreto, avendo trascurato solo per comodit\`a $T$.
\subsubsection{Esempio: Serie di Fibonacci}
La serie di Fibonacci \`e un comodo esempio introduttivo ai sistemi
tempo discreto. Come \`e noto, la serie si basa sul concetto che
l'n-esimo valore \`e la somma dei due valori precedenti. Formalizzando
\begin{equation}\label{eq:fibonacci}
u_k = u_{k-1} + u_{k-2}
\end{equation}
Per risolvere questa equazione abbiamo bisogno solo di conoscere i
valori iniziali e l'istante iniziale di tempo:
\[
\begin{array}{l}
  k = 2\\
  u(0) = u_0 = 1\\
  u(1) = u_1 = 1
\end{array}
\]
Considerata l'assenza di un ingresso, la sequenza \`e
\[
1,1,2,3,5,8,13,...
\]
\`E palese la natura ``divergente'' della serie: il sistema \`e
instabile.

Per riuscire a valurare la stabilit\`a di un sistema senza calcolarne
i valori esplicitamente, assumiamo che la soluzione dell'equazione
abbia una struttura con costanti da determinare in base alle
condizioni iniziali. Nel caso continuo, si utilizzavano soluzioni di
tipo esponenziale $e^{st}$. Analogamente, per i sistemi discreti
utilizzeremo soluzioni di tipo $z^k$, con $z$ variabile complessa che
sostituisce $s$ e $k$ \`e la variabile discreta indipendente che
sostituisce $t$. Quindi l'equazione~\ref{eq:fibonacci} ha soluzione:
\begin{equation}\label{eq:fibonacci02}
  cz^k = cz^{k-1} + cz^{k-2}
\end{equation}
Divideno per $cz^k$, otteniamo
\[
z^2 - z -1 = 0
\]
di soluzioni
\[
z_{1,2} = \dfrac{1 \pm \sqrt{5}}{2}
\]
$u_k$ \`e una equazione lineare, quindi la somma delle sue soluzioni
\`e ancora una soluzione:
\[
u_k = c_1 z_1^k + c_2z_2^k
\]
con $c_1$ e $c_2$ costanti, calcolabili a partire dalle condizioni
iniziali:
\[
\begin{array}{l}
  c_1 + c_2 = u_0 = 1\\
  c_1z_1 + c_2z_2 = u_1 = 1\\
  c_{1,2} = \dfrac{\pm 1 + \sqrt{5}}{2 \sqrt{5}}
\end{array}
\]
\[
u_k = \dfrac{1 + \sqrt{5}}{2 \sqrt{5}}\dfrac{1 + \sqrt{5}}{2} +
\dfrac{-1 + \sqrt{5}}{2 \sqrt{5}}\dfrac{1 - \sqrt{5}}{2} 
\]
Per valutare la stabilit\`a del sistema, valutiamo $z_1$ e $z_2$:
\[
z_1 = \dfrac{(1 + \sqrt{5})}{2} > 1
\]
quindi $c_1z_1^k$ cresce illimitatamente al crescere di $k$ e conferma
l'instabilit\`a del sistema.

La precedente analisi si basa sul concetto che se una delle soluzioni
dell'equazione caratteristica $u_k = z^k$ ha modulo maggiore di 1
(quindi \`e esterna alla circonferenza di raggio 1 centrata
nell'origine del piano complesso $z$), l'equazione alle differenze \`e
instabile. Se tutte le radici sono interne alla circonferenza,
l'equazione alle differenze \`e stabile, cio\`e la sua soluzione
converger\`a a zero al crescere di $k$ per ogni condizione iniziale.

\section{Rappresentazione di stato}
Una rappresentazione alternativa alla equazione lineare alle
differenze di ordine $n$ \`e la coppia di equazioni:
\[
\begin{array}{l}
  x(k + 1) = f(x(k), u(k), k)\\
  y(k) = g(x(k), u(k), k)
\end{array}
\]
$f$ e $g$ sono due funzioni vettoriali tali che:
\begin{itemize}
\item la prima equazione \`e un sistema di $n$ equazioni alle
  differenze di primo ordine che consente di definire l'andamento
  dello stato del sistema ed \`e detta {\bo equazione di stato};
\item la seconda \`e la {\bo trasformazione dell'uscita} e consente di
  determinare l'uscita del sistema discreto ad un certo istante di
  tempo $k$, noti lo stato e l'ingresso allo stesso istante.
\end{itemize}

\section{Equilibrio di un sistema discreto}
Un punto di equilibrio \`e un particolare punto in cui il sistema non
presenta dinamica. Nel dominio del tempo discreto $k$, ci\`o equivale
a dire che lo stato del sistema discreto non varia all'aumentare del
tempo, cio\`e:
\[
x(k + 1) = x(k) = \overline{x}
\]
Come per il caso continuo, si fissa un ingresso costante $u(k) =
\overline{u}$ e la rappresentazione di stato diventa:
\[
\begin{array}{l}
  \overline{x} = f (\overline{x},\overline{u})\\
  \overline{y} = g (\overline{x}, \overline{u})
\end{array}
\]
Le soluzioni di questa equazione di stato rappresentano i punti di
equilibrio.

\section{Linearizzazione}
Dato il sistema discreto SISO non-lineare e tempo invariante
\begin{equation}\label{eq:sisoDiscretoStato}
  \begin{array}{l}
    x (k + 1) = f(x(k), u(k))\\
    y(k) = g(x(k), u(k))
  \end{array}
\end{equation}
e un punto di equilibrio $P = (\overline{u}, \overline{x},
\overline{y})$, possiamo ottenere un'approssimazione linearizzata del
nostro sistema intorno al punto di equilibrio $P$.

Le variazioni dello stato, dell'ingresso e dell'uscita sono definite
come: 
\[
\begin{array}{l}
  \delta x(k) = x (k) - \overline{x}\\
  \delta u(k) = u (k) - \overline{u}\\
  \delta y(k) = y (k) - \overline{y}\\
\end{array}
\]
Possiamo riscrivere le equazioni~\ref{eq:sisoDiscretoStato} come:
\begin{equation}
  \begin{array}{l}
    \delta x (k + 1) + \overline{x} = f ( \delta x(k) + \overline{x},
    \delta u (k) + \overline{u})\\
    \delta y (k) + \overline{y} = g (\delta x (k) + \overline{x},
    \delta u(k) + \overline{u})
  \end{array}
\end{equation}
Sviluppando in serie di Taylor le funzioni $f$ e $g$ intorno al punto
di equilibrio $P$ avremo:
\[
\begin{array}{l}
  f (\delta x (k) + \overline{x}, \overline{u}(k) + \overline{u}) =\\
  = f(\overline{x}, \overline{u}) + \left. \dfrac{\partial f(x,
   u)}{\partial x}\right|_{x = \overline{x} \;,\; u = \overline{u}}
 \cdot \delta x(k) +  \left.\dfrac{\partial f(x,
   u)}{\partial u}\right|_{x = \overline{x} \;,\; u = \overline{u}}
 \cdot \delta u(k) + o (\delta x(k), \delta u(k))\\
 
  g (\delta x (k) + \overline{x}, \overline{u}(k) + \overline{u}) =\\
  = g(\overline{x}, \overline{u}) + \left. \dfrac{\partial g(x,
   u)}{\partial x}\right|_{x = \overline{x} \;,\; u = \overline{u}}
 \cdot \delta x(k) + \left. \dfrac{\partial g(x,
   u)}{\partial u}\right|_{x = \overline{x} \;,\; u = \overline{u}}
 \cdot \delta u(k) + o (\delta x(k), \delta u(k))
\end{array}
\]
Poich\`e le funzioni $f$ e $g$ non dipendono dal tempo continuo $k$,
possiamo dire che:
\[
\begin{array}{l}
  \dfrac{\partial f(x,u)}{\partial x} = A \in R^{n \times m}\\
  \dfrac{\partial f(x,u)}{\partial u} = B \in R^{n \times 1}\\
  \dfrac{\partial g(x,u)}{\partial x} = C \in R^{1 \times n}\\
  \dfrac{\partial g(x,u)}{\partial u} = C \in R^{1 \times 1}\\
\end{array}
\]
Ricordiamo che l'infinitesimo di ordine superiore al primo $o(\delta
x(k), \delta u(k))$ tende a zero per $\delta x(k)$ e $\delta 
u(k)$ che tendono a zero, cio\`e nelle vicinanze del punto di
equilibrio $P$.

Possiamo riscrivere:
\[
\begin{array}{l}
  f (\delta x (k) + \overline{x}, \overline{u}(k) + \overline{u})
  \cong f(\overline{x}, \overline{u}) + A \cdot \delta x(k) + B\cdot
  \delta u(k)\\
 
  g (\delta x (k) + \overline{x}, \overline{u}(k) + \overline{u})
  \cong g(\overline{x}, \overline{u}) + C \cdot \delta x(k) + D\cdot
  \delta u(k)
\end{array}
\]
Riconsiderando
\begin{equation*}
  \begin{array}{l}
    \delta x(k + 1) + \overline{x} = f ( \delta x(k) + \overline{x},
    \delta u (k) + \overline{u})\\
    \delta y (k) + \overline{y} = g (\delta x (k) + \overline{x},
    \delta u(k) + \overline{u})
  \end{array}
\end{equation*}
\begin{equation}
  \begin{array}{l}
    \delta x(k + 1) + \overline{x} = f(\overline{x}, \overline{u}) + A
    \cdot \delta x(k) + B\cdot \delta u(k) \\
    \delta y (k) + \overline{y} = \cong g(\overline{x},
    \overline{u}) + C \cdot \delta x(k) + D\cdot \delta u(k)
  \end{array}
\end{equation}
e ricordando che $\overline{x} = f(\overline{x}, \overline{u})$ e
$\overline{y} = g(\overline{x}, \overline{u})$, otteniamo
l'espressione del sistema linearizzato intorno al punto di equilibrio:
\begin{equation}
  \begin{array}{l}
    \delta x(k + 1)= A \cdot \delta x(k) + B\cdot \delta u(k) \\
    \delta y (k) = C \cdot \delta x(k) + D\cdot \delta u(k)
  \end{array}
\end{equation}

\chapter{Z-trasformata}
La Z-trasformata della sequenza di campioni $x(kT)$ \`e l'equivalente
del caso continuo della trasformata di Laplace del segnale analogico
$x(t)$. Essa consente di passare dal dominio del tempo discreto $k$ al
dominio della variabile complessa $z$. Questo dominio offre una
maggiore semplicit\`a di calcolo e garantisce la possibilit\`a di
ritornare al dominio discreto grazie all'anti-trasformata.

Nell'ipotesi di avere una sequenza di campioni $x(kT) \in R$, definita
per $k = 0, 1, 2, ...$ e nulla per $k < 0$, si definisce
Z-trasformata unilatera $( \Rightarrow k \in [0, + \infty))$:
\begin{equation}\label{eq:Z-trasformata01}
  Z[x(kT)] = \sum\limits_{k=0}^{\infty} x(kT) z^{-k}
\end{equation}
Si pu\`o, per comodit\`a trascurare il tempo di campionamento e
riscrivere l'equazione~\ref{eq:Z-trasformata01} come:
\begin{equation}\label{eq:Z-trasformata02}
  Z[x(k)] = \sum\limits_{k=0}^{\infty} x(k) z^{-k}
\end{equation}
\[
Z[x(k)] = X(z) = x_0 + x_1z^{-1} + x_2 z^{-2} + ... =
\sum\limits_{k=0}^{\infty} x(k) z^{-k} 
\]

La Z-trasformata $Z[x(k)]$ esiste nella regione di spazio detta {\em
  dominio di convergenza}\index{Dominio di convergenza}, cio\`e
nell'insieme dei punti $z$ per cio la serie~\ref{eq:Z-trasformata02}
converge. Poich\`e la $X(z)$ \`e una serie in $z^{-1}$, il dominio di
convergenza \`e la zona del piano $z$ esterna ad un cerchio di raggio
$R$ (raggio di convergenza\index{Raggio di convergenza}) centrato
nell'origine. 

\section{Propriet\`a della Z-trasformata}
\subsection{Linearit\`a}
La Z-trasformata \`e un operatore lineare: una sequenza $x(k)$,
combinazione lineare delle sequenze $f(k)$ e $g(k)$, avr\`a una
Z-trasformata $X(z)$ combinazione lineare delle Z-trasformate $F(z)$ e
$G(z)$. Formalmente:
  \[
   x(k) = af(k) + bg(k) \Rightarrow X(z) = aF(z) + bG(z)
  \]
  
  {\bo Dimostrazione}
  \[
  X(z) = Z[x(k)] = Z[af(k) + bg(k)] = \sum_{k=0}^{\infty} [af(k) + bg(k)]z^{-k}
  \]
  Per la propriet\`a di linearit\`a della sommatoria, possiamo
  scrivere
  \[
  = a\sum_{k=0}^{\infty} [f(k)]z^{-k} + b\sum_{k=0}^{\infty} [g(k)]z^{-k}
  \]
  che per definizione, ci porta a
  \[
  = aZ[f(k)] + bZ[g(k)] = aF(z) + bG(z)
  \]
\subsection{Moltiplicazione per $a^k$}
Considerata la sequenza $a^k$, con $a$ costante diversa da $0$
\[
Z[a^k x(k)] = \sum\limits_{k = 0}^{\infty} a^k x(k) z^{-k}
\]
Se riscriviamo $a^k = (a^{-1})^{-k}$, otteniamo
\[
= \sum\limits_{k=0}^{\infty} x(k)(a^{-1})^{-k}z^{-k}
= \sum\limits_{k=0}^{\infty} x(k)(a^{-1}z)^{-k} = X(a^{-1} z)
\]
Notiamo che in questo caso, la Z-trasformata \`e funzione di $z$ e
$a^{-1}$.
\subsection{Traslazione nel tempo}
\begin{description}
\item[Ritardo]
  La Z-trasformata della sequenza $x(k)$ ritardata nel tempo
  discreto $k$ di $n$ passi \`e
  \[
  Z[x(k -n)] = \sum\limits_{k=0}^{\infty} x(k -n)z^{-k}
  \]
  Moltiplichiamo e dividiamo per $z^n$
  \[
  \sum\limits_{k=0}^{\infty} x(k - n) z^{-k} z^n z^{-n} =
  \sum\limits_{k=0}^{\infty} x(k - n) z^{-(k - n)} z^{-n}
  \]
  Portiamo $z^{-n}$, indipendente da $k$, fuori dalla sommatoria;
  sostituiamo $m = k - n$ e consideriamo nulla la sequenza $x(m)$
  per $m < 0$
  \[
  = z^{-n} \sum\limits_{m = 0}^{\infty} x(m) z^{-m} = 
  \]
  A questo punto, imponendo $m = k$
  \[
  z^{-n} \sum\limits_{m = 0}^{\infty} x(m) z^{-m} = z^{-n}
  \sum\limits_{k = 0}^{\infty} x(k) z^{-k} \triangleq Z[x(k)]
  \triangleq X(z) = z^{-n}X(z)
  \]
  Quindi, la Z-trasformata della sequenza $x(k)$ ritardata nel tempo
  discreto $k$ di $n$ passi \`e pari al prodotto della Z-trasformata
  di $x(k)$ e del fattore di ritardo $z^{-n}$.
  \begin{figure}[!h]
    \begin{center}
      \includegraphics[scale=0.3]{./figures/discretoRitardo.png}
      \caption{Z-trasformata
        ritardata}\label{fig:Z-trasformataRitardo} 
    \end{center}
  \end{figure}
  
  \item[Anticipo]
    La Z-trasformata di $Z[x(k + n)]$ \`e semplicemente la z-trasformata
    di $Z[x(k)]$ moltiplicata per il fattore di anticipo $z^n$, che
    tiene traccia di quanto si stia anticipando la sequenza $x(k)$, meno una certa
    quantit\`a che compensa gli $n - 1$ campioni persi durante la
    traslazione o attraversamento dell'origine degli assi.
    \[
    Z[x(k + n)] = \sum\limits_{k=0}^{\infty} x(k + n)z^{-k}
    \]
    Moltiplichiamo e dividiamo per $z^n$
    \[
    \sum\limits_{k=0}^{\infty} x(k + n) z^{-k} z^n z^{-n} =
    \sum\limits_{k=0}^{\infty} x(k + n) z^{-(k + n)} z^{n}
    \]
    Col cambio di variabile
    \[
    m = k + n
    \]
    la sommatoria cambier\`a in
    \[
    \sum_{m = n}^{m = \infty} x(m)z^{-m}
    \]
    rispettivamente se $k = 0$ o $k = \infty$.
    La precedente sommatoria \`e la sommatoria della Z-trasformata di
    x(m), privata dei campioni da $0$ ad $n -1$. A questo punto,
    sommiamo e sottraiamo i ``campioni mancanti'':
    \[
    z^n \left[ \sum_{m=n}^{\infty} x(m)z^{-m} + \sum_{m=0}^{n-1} x(m)z^{-m}
    - \sum_{m=0}^{n-1} x(m)z^{-m}\right] = 
    \]
    ponendo $m = k$, concludiamo dicendo che:
    \[
    Z[x(k +n)] = \sum\limits_{k=0}^{\infty} x(k + n)z^{-k} = z^n
    \left[ X(z) - \sum\limits_{m=0}^{n-1} x(m)z^{-m} \right]
    \]
    \begin{figure}[!h]
      \begin{center}
        \includegraphics[scale=0.3]{./figures/discretoAnticipo.png}
        \caption{Z-trasformata
          anticipata}\label{fig:Z-trasformataAnticipo} 
      \end{center}
    \end{figure}
  \end{description}
\subsection{Teorema del valore iniziale}
  Il teorema del valore iniziale consente di determinare il valore
  iniziale della sequenza $x(k)$, nel dominio del tempo discreto $k$,
  senza praticare la Z-trasformata. Il teorema del valore inizale \`e
  sempre applicabile perch\`e la sequenza $x(k)$ avr\`a sempre ``un punto
  al finito''\index{Punto al finito} o campione iniziale da cui parte.
  \begin{equation}\label{eq:teoremaInizialeDiscreto}
    \lim\limits_{k \to 0} x(k) = x(0) = \lim\limits_{z \to \infty}
    X(z) = X(\infty)
  \end{equation}

\subsubsection{Dimostrazione}
\[
X(z) = \sum_{k = 0}^{\infty} x(k)z^{-k} = x_0z^0 + x_1z^{-1} +
 x_2z^{-2} + ... = 
\]
Applichiamo ad entrambi i membri il $\lim\limits_{z \to \infty}$
\[
\lim\limits_{z \to \infty} X(z) = \lim\limits_{z \to \infty} [x_0z^0 + x_1z^{-1} +
 x_2z^{-2} + ...]
\]
Per la propriet\`a di linearit\`a, il limite della somma \`e pari alla
somma dei limiti:
\[
\lim\limits_{z \to \infty} X(z) = \lim\limits_{z \to \infty} x_0 +
\lim\limits_{z \to \infty} x_1z^{-1} + \lim\limits_{z \to \infty}
x_2z^{-2} + ...
\]
Il $\lim\limits_{z \to \infty}$ fa s\`i che i termini
$z^{-esponente}$ convergano a 0, giungendo a:
\[
\lim\limits_{z \to \infty} X(z) = \lim\limits_{k \to 0} x(k) = x(0)
\]

\subsection{Teorema del valore finale}\label{teoremaFinaleDiscreto}
Il teorema del valore finale consente di conoscere il valore finale o
di regime della sequenza $x(k)$ nel dominio del tempo discreto $k$,
senza praticare la Z-trasformata. Questo teorema \`e applicabile solo
se la sequenza $x(k)$ \`e convergente, cio\`e se i modi di evoluzione
sono asintoticamente stabili ovvero se la Z-trasformata $X(z)$ ha
tutti i poli all'interno del cerchio di raggio unitario e al pi\`u un
polo semplice per $z = 1$.
\begin{equation}
  \lim\limits_{k \to \infty} x(k) = x(\infty) = \lim\limits_{z \to
    1}[(1 - z^{-1})X(z)]
\end{equation}

\subsubsection{Descrizione}
\[
X(z) = \sum_{k=0}^{\infty} x(kT) z^{-k}
\]
\[
Z[x(k-1)] = z^{-1}X(z) = \sum_{k=0}^{\infty} x(k -1) z^{-k}
\]
Per la propriet\`a di linearit\`a, sottraendo le due quantit\`a membro
a membro otteniamo:
\[
X(z) - z^{-1}X(z) = \sum_{k=0}^{\infty} x(kT) z^{-k} -
\sum_{k=0}^{\infty} x(k -1) z^{-k} 
\]
\[
X(z)(1 - z^{-1}) = \sum_{k=0}^{\infty} x(kT)z^{-k} - x(k - 1)z^{-k}
\]
Applichiamo ad entrambi i membri il $\lim_{z \to 1}$:
\[
\lim\limits_{z \to 1}X(z)(1 - z^{-1}) = \lim\limits_{z \to
  1}\left[\sum_{k=0}^{\infty} \left[ x(kT)z^{-k} - x(k -
    1)z^{-k}\right]\right] 
\]
Al sedondo membro, tutti i termini $z^{-k}$ tenderanno ad 1 per
qualsiasi valore di $k$. 
\[
\lim\limits_{z \to 1}X(z)(1 - z^{-1}) = \lim\limits_{z \to
  1}\left[\sum_{k=0}^{\infty} \left[x(kT) - x(k - 1) \right]\right]
\]
La commatoria al secondo membro pu\`o essere ``esplosa'' come:
\[
\lim\limits_{z \to 1}X(z)(1 - z^{-1}) = [x(0) - x(-1)] + [x(1) - x(0)]
+ [x(2) - x(1)] + ... + [x(\infty) - x(\infty - 1)]
\]
Al secondo membro, quindi, avremo solo $x(\infty)$ perch\`e i campioni
tendono ad annullarsi ``a coppie'' oppure sono nulli. In conclusione:
\[
\lim\limits_{z \to 1}X(z)(1 - z^{-1}) = x(\infty)
\]
\subsection{Differenziazione complessa}\label{DifferenziazioneComplessa}
Possiamo differenziare rispetto a $z$ una serie di potenze $X(z)$
nella propria regione di convergenza. La derivata di $X(z)$ che ne
deriva \`e una serie convergente nella stessa regione di convergenza
di $X(z)$. Si consideri
\[
X(z) = \sum_{k=0}^{\infty}x(k)z^{-k}
\]
Differenziando otteniamo
\[
\dfrac{d}{dz}X(z) = \sum_{k=0}^{\infty} (-k) x(k) z^{-k-1}
\]
\[
\dfrac{d}{dz}X(z) = -\sum_{k=0}^{\infty} k \cdot x(k) z^{-k-1}
\]
\[
\dfrac{d}{dz}X(z) = -z^{-1}\sum_{k=0}^{\infty} k \cdot x(k) z^{-k}
\]
\[
-z\dfrac{d}{dz}X(z) = \sum_{k=0}^{\infty} k \cdot x(k) z^{-k}
\]
Dalla propriet\`a di moltiplicazione si ha che:
\[
Z[kx(k)] = -z\dfrac{d}{dz} X(z)
\]
Derivando ulteriormente:
\[
\dfrac{d}{dz}\left[-z\dfrac{d}{dz}X(z)\right]=
\dfrac{d}{dz}\left[\sum_{k=0}^{\infty} k \cdot x(k) z^{-k}\right] 
\]
\[
\dfrac{d}{dz}\left[-z\dfrac{d}{dz}X(z)\right]=
\dfrac{d}{dz}\left[\sum_{k=0}^{\infty} (-k^2) \cdot x(k) z^{-k}\right] 
\]
\[
Z[k^2 x(k)] = \dfrac{d}{dz}\left[-z\dfrac{d}{dz}X(z)\right]
\]
Generalizzando, abbiamo:
\[
Z[k^m x(k)] = \left ( -z \dfrac{d}{dz} \right )^m X(z)
\]

Notiamo quindi che
\begin{itemize}
\item se nel dominio del tempo discreto $k$ moltiplichiamo per $k$ la
  sequenza $x(k)$, nel dominio della $Z$ stiamo derivando la
  Z-trasformata $Z[x(k)]$
\item possiamo calcolare la Z-trasformata di funzioni a partire da
  Z-trasformate note.
\end{itemize}
\[
\left ( -z \dfrac{d}{dz} \right )^m 
\]
indica l'applicazione per $m$ volte dell'operatore $\left ( -z
\dfrac{d}{dz} \right )$, ovvero la derivata \mbox{m-sima} rispetto alla
varibile $z$; non equivale a fare $m$ volte la derivata rispetto alla
variabile complessa $z$ per poi moltiplicare per $z^m$.

\subsection{Integrazione complessa}
\[
X(z) = Z[x(k)]
\]
\[
g(k) = \dfrac{x(k)}{k}
\]
\[
G(z) = \sum_{k = 0}^{\infty} \dfrac{x(k)}{k}z^{-k}
\]
Applichiamo la propriet\`a di derivazione complessa:
\[
\dfrac{d}{dz}G(z) = \dfrac{d}{dz}\left[\sum_{k = 0}^{\infty}
  \dfrac{x(k)}{k}z^{-k}\right] 
\]
\[
\dfrac{d}{dz}G(z) = \dfrac{d}{dz}\left[\sum_{k = 0}^{\infty}
  (-k)\dfrac{x(k)}{k}z^{-k-1}\right] 
\]
\[
\dfrac{d}{dz}G(z) = \dfrac{d}{dz}\left[\sum_{k = 0}^{\infty}
  -z^{-1}\dfrac{x(k)}{k}z^{-k}\right] 
\]
\[
\dfrac{d}{dz}G(z) = -z^{-1}X(z)
\]
\[
\dfrac{d}{dz}G(z) = -\dfrac{X(z)}{z}
\]
Possiamo integrare ambo i membri rispetto a $z$ tra $z$ a $\infty$ a
patto di effettuare un cambio di variabile al secondo membro:
\[
\int_{z}^{\infty}\dfrac{d}{dz}G(z) = \int\limits_{z}^{\infty}
-\dfrac{X(\zeta)}{\zeta}
\]
\[
G(\infty) - G(z) = \int\limits_{z}^{\infty}
-\dfrac{X(\zeta)}{\zeta}
\]
Dal teorema del valore iniziale
\[
G(\infty) = \lim\limits_{k \to 0} x(k) = x(0)
\]
Quindi:
\[
G(z) = \int\limits_{z}^{\infty} \dfrac{X(\zeta)}{\zeta} - \lim_{k \to
  0} x(k)
\]
Se nel dominio del tempo discreto $k$ dividiamo per $k$ la sequenza
$x(k)$ nel dominio della variabile complessa $z$ stiamo
integrando opportunamente la Z-trasformata $z[x(k)]$.

\subsection{Trasformazione di una sequenza periodica}
Sia la sequenza $x_p(k)$ periodica id periodo $p$. Sia $x(k)$ la
seguente successione di campioni:
\[
x(k) =
\left\{
\begin{array}{lll}
  x_p(k) & \textrm{per} & 0 \leq k \leq p\\
  0 & \textrm{per} & k > p
\end{array}
\right.
\]
A questo punto, possiamo sfruttare questa propriet\`a per descrivere
la sequenza $x_p(k)$ come sequenza di campioni $x(k)$ opportunamente
traslati di un periodo $p$:
\[
x_p(k) = x(k) + x(k - p) + x(k -2p) + ... = \sum_{i = 0}^{\infty} x(k
- ip)
\]
\begin{figure}[!h]
  \begin{center}
    \includegraphics[scale=0.4]{./figures/trasformazioneSequenzaPeriodica}
    \caption{Trasformazione Sequenza
      Periodica}\label{fig:circonferenzaUnitaria} 
  \end{center}
\end{figure}
\[
Z[x_p(k)] = \sum_{k=0}^{\infty} \sum_{i = 0}^{\infty} x(k- ip) z^{-k}
\]
\[
Z[x_p(k)] = \sum_{i=0}^{\infty} \sum_{k = 0}^{\infty} x(k- ip) z^{-k}
\]
\[
Z[x_p(k)] = \sum_{i=0}^{\infty} Z[x(k - ip)]
\]
Per la propriet\`a di traslazione nel tempo:
\[
Z[x_p(k)] = \sum_{i=0}^{\infty} z^{-ip}X(z)
\]
\[
Z[x_p(k)] = X(z)\sum_{i=0}^{\infty} z^{-ip}
\]
Se $|z| > 1$ 
\[
\sum_{i=0}^{\infty} z^{ip}
\]
\`e una serie geometrica di ragione $z^{-p}$, cio\`e una successione
di potenze convergente ad $\dfrac{1}{1 - z^{-p}}$. Quindi
\[
Z[x_p(k)] = X(z) \dfrac{1}{1 - z^{-p}}
\]

\subsubsection{Serie geometrica convergente}
Ricordiamo che se $|x| < 1$ la serie esiste e vale:
\[
\sum_{k=0}^{\infty} x^{1 \cdot k} = \lim\limits_{n \to \infty} \sum_{k=0}^{n}
x^k = \lim\limits_{n \to \infty} \dfrac{1 - n^{n + 1}}{1 - x} =
\dfrac{1}{1 - x^{1}}
\]
Ne caso preso in esame
\[
\sum_{i=0}^{\infty} z^{-p \cdot i}
\]
considerato l'esponente negativo, la serie converger\`a a
\[
\dfrac{1}{1 - z^{-p}}
\]
per $|z| > 1$.

\section{Z-trasformate di funzioni elementari}
\subsection{Impulso discreto unitario}
Sia data la funzione
\[
\delta(k) =
\left\{
\begin{array}{lll}
  1 & \textrm{per} & k = 0\\
  0 & \textrm{per} & k \neq 0
\end{array}
\right.
\]
Applichiamo la definizione di Z-trasformata:
\[
Z[\delta(k)] = \sum_{k=0}^{\infty} \delta(k) z^{-k}
\]
Per definizione, la funzione $\delta(k)$ \`e valida solo per
$k=0$. Applicando questa considerazione alla Z-trasformata in esame,
abbiamo che:
\[
Z[\delta(k)] = 1z^{0} + 0z^{-1} + ... = 1
\]

\subsection{Gradino discreto unitario}
Sia data la funzione
\[
h(k) =
\left\{
\begin{array}{lll}
  1 & \textrm{per} & k \geq 0\\
  0 & \textrm{per} & k < 0
\end{array}
\right.
\]
\[
Z[h(k)] = H(z) = \sum_{k=0}^{\infty} h(k) z^{-k}
\]
che, per definizione di $h(k)$, possiamo riscrivere
\[
H(z) = \sum_{k=0}^{\infty} z^{-k}
\]
$H(z)$ \`e una serie geometrica di ragione $z^{-1}$, convergente a
\[
\dfrac{1}{1 - z^{-1}} = \dfrac{z}{z - 1}
\]
per $|z| > 1$.

\subsection{Rampa discreta unitaria}
\[
x(k) =
\left\{
\begin{array}{lll}
  kT & \textrm{per} & k \geq 0\\
  0 & \textrm{per} & k < 0
\end{array}
\right.
\]
\[
X(z) = \sum_{k=0}^{\infty} x(kT) z^{-k} = \sum_{k=0}^{\infty} kT
z^{-k} = T \sum_{k=0}^{\infty} k z^{-k}
\]
Esplodendo la sommatoria:
\[
T \sum_{k=0}^{\infty} k z^{-k} = T (z^{-1} + 2 z^{-2} + 3z^{-3} + ...)
\]
Mettendo in evidenza $z^{-1}$, abbiamo ottenuto una serie geometrica:
\[
T z^{-1}(1 + 2z^{-1} + 3z^{-2} + ...)
\]
\[
T z^{-1} \dfrac{1}{(1 - z^{-1})^{2}}
\]
convergente per $|z| > 1$.

Alternativamente, possiamo sfruttare il fatto che
\[
x(k) = kT \cdot h(k)
\]
\[
X(z) = T\sum_{k=0}^{\infty} k \cdot h(k) z^{-k}
\]
La propriet\`a di derivazione(\ref{DifferenziazioneComplessa}) dice
che se nel dominio del tempo discreto moltiplichiamo per $k$ la
sequenza $h(k)$, nel dominio della variabile complessa $z$ stiamo
derivando la Z-trasformata:
\[
X(z) = -T \cdot z \dfrac{d}{dz} H(z) = -T \cdot z \dfrac{d}{dz} \left[
 \dfrac{1}{1 - z^{-1}}\right]
\]
Effettuando la derivata, otteniamo
\[
X(z) = T \dfrac{z}{(z - 1)^2}
\]

\subsection{Funzione potenza}
La funzione potenza $x(k)$ \`e cos\`i definita:
\[
x(k) =
\left\{
\begin{array}{lll}
  a^k & \textrm{per} & k \geq 0\\
  0 & \textrm{per} & k < 0
\end{array}
\right.
\]
con $a$ costante reale o complessa.
\[
X(z) = \sum_{k=0}^{\infty} a^k z^{-k}
\]
Esplodendo la sommatoria, abbiamo
\[
X(z) = 1 + az^{-1} + a^2 z^{-2} + a^3 z^{-3} + ...
\]
\`E ancora una serie geometrica di ragione $az^{1}$, convergente a
\[
X(z) = \dfrac{1}{1 - az^{-1}}
\]
per $|z| > |a|$, cio\`e per punti del piano complesso $z$ esterni al
cerchio di raggio $|a|$ centrato nell'origine.

Alternativamente possiamo dire che
\[
x(k) = a^k h(k)
\]
\[
X(z) = \sum_{k=0}^{\infty} a^k h(k)z^{-k}
\]
Ricordando la propriet\`a di moltiplazione per $a^k$ e la trasformata
del gradino $H(z)$, possiamo riscrivere
\[
X(z) = H(az^{-1}) = \dfrac{1}{1 - az^{-1}}
\]
Nota: se $a = 1$, $X(z) = H(z)$.

\subsection{Funzione esponenziale}
\[
x(k) =
\left\{
\begin{array}{lll}
  e^{-akT} & \textrm{per} & k \geq 0\\
  0 & \textrm{per} & k < 0
\end{array}
\right.
\]
con $a$ costante reale o complessa. Possiamo riscrivere $x(k)$ come
\[
x(k) =
\left\{
\begin{array}{lll}
  (e^{-aT})^k = \rho^k & \textrm{per} & k \geq 0\\
  0 & \textrm{per} & k < 0
\end{array}
\right.
\]
Se nel dominio del tempo continuo $t$, campioniamo una funzione
esponenziale $x(t) = e^{-at}$ con un tempo di campionamento $T$, nel
dominio del tempo discreto $k$ avremo una funzione potenza $x(k) =
\rho^{-k}$ la cui Z-trasformata si ottiene dalla gi\`a nota
Z-trasformata della funzione potenza $a^k$:
\[
X(z) = \dfrac{1}{1 - e^{-aT}z^{-1}}
\]
serie geometrica convergente per $|z| > e^{-Re(a)T}$. Si noti che per
$a = 0$ $X(z)~=~H(z)$.

Questa importante propriet\`a della Z-trasformata della funzione
potenza ci consente di trattare agevolmente le funzioni $sin$ e $cos$,
riconducibilii a funzioni esponenziali grazie alla formula di Eulero.

\subsection{Funzione sinusoidale non smorzata - costante}
\[
x(k) =
\left\{
\begin{array}{lll}
  sin \omega Tk & \textrm{per} & k \geq 0\\
  0 & \textrm{per} & k < 0
\end{array}
\right.
\]
Sostituiamo $\omega T = \theta$
\[
x(k) =
\left\{
\begin{array}{lll}
  sin \theta k & \textrm{per} & k \geq 0\\
  0 & \textrm{per} & k < 0
\end{array}
\right.
\]
La formula di Eulero ci mostra che
\[
sin \theta k = \dfrac{e^{j\theta k} - e^{-j \theta k}}{2j}
\]
\[
X(z) = Z[sin \theta k] = Z \left[ \dfrac{e^{j\theta k} - e^{-j \theta
      k}}{2j} \right] = \dfrac{1}{2j} Z \left[ e^{j\theta k} - e^{-j
    \theta k} \right]
\]
Per la propriet\`a di linearit\` della Z-trasformata
\[
X(z) = \dfrac{1}{2j} Z [e^{j\theta k}] - Z [e^{-j\theta k}]
\]
Noto che
\[
Z[e^{-akT}] = \dfrac{1}{1 - e^{-aT}z^{-1}}
\]
\[
X(z) = \dfrac{1}{2j} \left[ \dfrac{1}{1 - e^{j\theta}
    z^{-1}}\dfrac{1}{1 - e^{-j\theta} z^{-1}}\right] 
\]
\[
X(z) = \dfrac{1}{2j} \left[ \dfrac{1 - e^{-j \theta}z^{-1} -1 + e^{j
      \theta}z^{-1} }{(1 - e^{j\theta}z^{-1}) (1 - e^{-j\theta}
    z^{-1})}\right]
\]
Con la messa in evidenza di $z^{-1}$ al numeratore, otteniamo
\[
X(z) = \dfrac{1}{2j} \left[ \dfrac{z^{-1}(e^{j\theta} - e^{-j
      \theta})}{(1 - e^{j\theta}z^{-1}) (1 - e^{-j\theta}
    z^{-1})}\right]
\]
Dalla formula di Eulero del $sin$ e del $cos$ e dall'esplosione della
moltiplazione al denominatore, otteniamo:
\[
X(z) = \dfrac{z^{-1} sin \theta}{1 - z^{-1} 2 cos \theta + z^{-2}} =
\dfrac{z sin \theta}{z^2 - 2 z cos \theta + 1}
\]

\subsection{Funzione cosinusoidale non smorzata - costante}
\[
x(k) =
\left\{
\begin{array}{lll}
  cos \omega Tk & \textrm{per} & k \geq 0\\
  0 & \textrm{per} & k < 0
\end{array}
\right.
\]
Sostituiamo $\omega T = \theta$
\[
x(k) =
\left\{
\begin{array}{lll}
  cos \theta k & \textrm{per} & k \geq 0\\
  0 & \textrm{per} & k < 0
\end{array}
\right.
\]
Con un ragionameno analogo al caso della $Z[sin \theta k]$, otteniamo
\[
Z[cos \theta k] = \dfrac{1 - z^{-1} cos \theta}{1 - z^{-1} 2 cos
  \theta + z^{-2}} = z \dfrac{z - cos \theta}{z^2 - 2z cos \theta + 1}
\]

\subsection{Funzioni $sin$ e $cos$ in rappresentazione cartesiana}
Per ottenere una forma della Z-trasformata del $sin \theta k$ e $cos
\theta k$ pi\`u facile da ricordare, possiamo sfruttare la
rappresentazione cartesiana ``parte reale $\alpha$ e parte immaginaria
$\omega$'' piuttosto che la rappresentazione polare, o ``modulo $\rho$
e fase $\theta$''.

Dobbiamo per\`o attenderci ad alcune uguaglianze:
\[
\begin{array}{l}
  \alpha = cos \theta\\
  \omega = sin \theta\\
  \alpha^2 + \omega^2 = 1
\end{array}
\]
A questo punto
\[
Z[sin \theta k ] = \dfrac{z \omega}{z^2 - 2 \alpha z + \alpha^2 +
  \omega^2} = z \dfrac{\omega}{(z - a)^2 + \omega^2}
\]
\[
Z[cos \theta k] = z \dfrac{z - a}{z^2 - 2 \alpha z + \alpha^ +
  \omega^2} = z \dfrac{z - \alpha}{(z - \alpha)^2 + \omega^2}
\]

\subsection{Come capire se la funzione \`e non smorzata - costante,
  non smorzata - divergente o smorzata - convergente}

\subsection{Funzione sinusoidale smorzata - convergente}
\[
x(k) =
\left\{
\begin{array}{lll}
  e^{\alpha k T}sin \omega Tk & \textrm{per} & k \geq 0\\
  0 & \textrm{per} & k < 0
\end{array}
\right.
\]
Ponendo $\rho = e^{\alpha T}$ e $\theta = \omega T$
\[
x(k) = \rho^{k} sin (\theta k)
\]
funzione smorzata se $\rho < 1$. Considerando che $e^{\alpha T} =
\rho$, quando $\alpha < 0$, $0 < \rho < 1$ il moto di evoluzione \`e
convergente sia in $t$ che in $k$.
\[
Z[\rho^k sin(\theta k)] = \dfrac{\rho z sin(\theta)}{z^2 - 2 \rho
  cos(\theta) + \rho^2}
\]

\subsection{Funzione cosinusoidale smorzata - convergente}
\[
x(k) =
\left\{
\begin{array}{lll}
  e^{\alpha k T} cos \omega Tk & \textrm{per} & k \geq 0\\
  0 & \textrm{per} & k < 0
\end{array}
\right.
\]
Ponendo $\rho = e^{\alpha T}$ e $\theta = \omega T$
\[
x(k) = \rho^{k} cos (\theta k)
\]
funzione smorzata se $\rho < 1$. Considerando che $e^{\alpha T} =
\rho$, quando $\alpha < 0$, $0 < \rho < 1$ il moto di evoluzione \`e
convergente sia in $t$ che in $k$.
\[
Z[\rho^k cos(\theta k)] = z\dfrac{z - \rho cos(\theta)}{z^2 - 2 \rho
  cos(\theta) + \rho^2}
\]

\section{La Z-antitrasformata}
L'antitrasformata \`e uno strumento per ottenere in modo univoco la
sequenza $x_k$ a partire dalla sua Z-antitrasformata
$X(z)$. L'antitrasformata non fornisce per\`o una univoca $x(t)$: si
pu\`o sapere il valore di $x(t)$ in ogni istante di tempo $t/T = 0, 1,
2, ...$, ma non si pu\`o conoscere l'andamento di $x(t)$ negli istanti
intermedi. Esistono infinite funzioni $x(t)$ che campionate negli
istanti $t = kT$ forniscono la stessa $x(k)$.

\subsection{Metodo della lunga divisione}
Questo metodo consiste nell'espandere la $X(z)$ in una serie di
potenze di $z^{-1}$. \`E un buon metodo quando si vuole ottenere solo
un piccolo numero di termini di $x(k)$, tipicamente i primi 3 o 4
termini.

Se consideriamo la $X(z)$ come funzione razionale fratta, possiamo
ottenere la versione come serie di potenze di $z^{-1}$ semplicemente
dividendo il numeratore per il denominatore. Otteniamo cos\`i la forma
di un unico polinomio i cui termini sono genericamente $c_k z^{-k}$
con $k = 0, 1, 2, ...$
\[
X(z) = \dfrac{b_0 + b_1 z^{-1} + ... + b_m z^{m}}{a_0 + a_1 z + ... +
  a_n z^{-n}} = c_0 + c_1z^{-1} + c_zz^{-1}
\]
\[
\begin{array}{l}
  x(0) = c_0\\
  x(T) = c_1\\
  x(2T) = c_2\\
  ...
\end{array}
\]

\subsection{Metodo computazionale}
Il metodo computazionale \`e un metodo di calcolo dei coefficienti che
pu\`o essere eseguito da un calcolatore, mediante un opportuno
algoritmo ricorsivo. Istante per istante, il calcolatore memorizza i
valori dei campioni e pu\`o calcolare il valore del campione
all'istante $k$.

Considerando per esempio la
\[
X(z) = \dfrac{3}{(1 - z^{-1})^2 (1 - 0.5z^{-1})} = \dfrac{3}{-0.5
  z^{-3} + 2 z^{-2} - 2.5 z^{-1} + 1} U(z)
\]
con $U(z) = Z[\delta(k)] = 1$, Z-trasformata dell'impulso unitario
discreto:
\[
u(0) = 1, \;\;\; u(k) = 0, \;\;\; k = 1, 2, 3, ...
\]
Se consideriamo $z^{-1}$ come un ritardo unitario, possiamo riscrivere
la $X(z)$ come
\[
X(z)(1 - 2.5z^{-1} + 2 z^{-2} - 0.5z^{-3}) = 3 U(z)
\]
Sotto forma di equazione alle differenze:
\[
x(k) - 2.5x(k -1) + 2x(k -2) - 0.5x(k - 3) = 3u(k)
\]
Le condizioni iniziali $k = 0$ sono:
\[
\begin{array}{l}
  u(0) = 1\\
  x(-1) = x(-2) = x(-3) = 0\\
  x(0) = 3\\
  x(1) = 2.5x(0) = 7.5\\
  x(2) = 2.5x(1) - 2x(0) = 12.75\\
  x(3) = 2.5x(2) - 2x(1) + 0.5x(0) = 18.375\\
  ...
\end{array}
\]
Ricorsivamente, sar\`a quindi possibile calcolare tutti i valori a cui
siamo interessati.

\subsection{Metodo della scomposizione in fratti semplici}
Fare riferimento a \ref{FrattiSemplici}.

\chapter{Sistemi discreti lineari tempo invarianti}
\begin{equation}
  \left\{
  \begin{array}{l}
    x(k + 1) = Ax(k) + Bu(k)\\
    y(k) = C^T x(k) + Du(k)
  \end{array}
  \right.
\end{equation}
Il vettore $x$ \`e il vettore degli stati di dimensione $N$, con $N$
ordine del sistema dinamico. Il sistema \`e SISO: $u$ e $y$ sono due
scalari o funzioni di scalari. $A$ ha dimensioni $(N \times N)$, $B$
ha dimensioni $(N \times 1)$, $C^T$ ha dimensioni $(1 \times N)$ e $D$
ha dimensioni $(1 \times 1)$. Sono matrici costanti, perch\`e il
sistema \`e tempo invariante.

Applichiamo la Z-trasformata:
\[
\begin{array}{l}
  X(z) = Z[x(k)]\\
  U(z) = Z[u(k)]\\
  Y(z) = Z[y(k)]
\end{array}
\]
Ovviamente anche $X(z)$ \`e un vettore di dimensione $N$. La prima
equazione \`e:
\[
Z[x(k + 1)] = Z[Ax(k) + Bu(k)]
\]
\[
z(X(z) - x(0)) = AX(z) + BU(z)
\]
Sono necessarie le condizioni iniziali, altrimenti si avrebbero
infinite soluzioni.
\[
zX(z) - AX(z) = zx(0) + BU(z)
\]
\[
(zI - A)X(z) = zx(0) + BU(z)
\]
Abbiamo ottenuto un sistema puramente algebrico in $z$. Sapendo che
$(zI - A)$ ha dimensioni $N \times N$ e quindi invertibile, $z$ \`e
uno scalare e $x(0)$ \`e un vettore, ricaviamo $X(z)$: 
\begin{equation}
X(z) = z(zI - A)^{-1}x(0) + (zI - A)^{-1}BU(z)
\end{equation}
La seconda equazione \`e:
\[
Y(z) = C^T X(z) + DU(z)
\]
Sostituendo, otteniamo:
\begin{equation}
\begin{array}{l}
  X(z) = z(zI - A)^{-1}x(0) + (zI - A)^{-1}BU(z)\\
  Y(z) = \underbrace{zC^{T} (zI - A)^{-1} x(0)}_\text{Evoluzione
    libera} + \underbrace{[C^T (zI - A)^{-1} B +
      D]U(z)}_\text{Evoluzione forzata}
\end{array}
\end{equation}
L'evoluzione libera esprime l'andamento delle $N$ componenti dello
stato del sistema, che parte da una condizione iniziale $0$ ed evolve
senza forzamenti. Diversamente, l'evoluzione forzata parte da
condizioni iniziali nulle e descrive l'andamento delle $N$ componenti
dello stato del sistema sottoposte ad un forzamento, cio\`e
l'ingresso $U(z)$.
\begin{equation}
  [C^T (zI - A)^{-1} B + D]
\end{equation}
\`e detta {\bo funzione di trasferimento} e lega l'uscita di un
sistema al suo ingresso in evoluzione forzata, cio\`e a condizioni
iniziali $x(0)$ nulle.

In entrambi i termini della $Y(z)$ \`e presente il termine
\[
(zI - A)^{-1}
\]
che \`e l'inverso di una matrice, cio\`e il rapporto tra la matrice
dei cofattori trasposta e il determinante di $(zI - A)^{-1}$. Il
determinante \`e il polinomio caratteristico le cui soluzioni sono gli
autovalori della matrice $A$. Dai valori della matrice $A$ dipendono i
modi di evoluzione del sistema.

\section{Modi di evoluzione in funzione degli autovalori}
Effettuiamo una catalogazione delle combinazioni degli $N$ modi di
evoluzione di un sistema in funzione degli autovalori della matrice
$A$ e di come vengono collocati in relazione alla circonferenza
unitaria.

Consideriamo il piano $z$ e la circonferenza di raggio unitaria,
mostrata in figura~\ref{fig:circonferenzaUnitaria}.
\begin{figure}[!h]
  \begin{center}
    \includegraphics[scale=0.5]{./figures/circonferenzaUnitaria}
    \caption{Circonferenza unitaria}\label{fig:circonferenzaUnitaria} 
  \end{center}
\end{figure}
La circonferenza individua tre regioni:
\begin{itemize}
\item una interna
\item una esterna
\item una esattamente sulla circonferenza
\end{itemize}

Cardine del nostro studio \`e il calcolo del $|\rho|$ che ci
consentir\`a di capire di che modo di evoluzione si tratti.

DA CONTROLLARE
-------------------------------------------------

Come gi\`a detto, i modi di evoluzione sono gli stessi sia che si parli
di evoluzione libera che di evoluzione forzata. Tuttavia, per esaltare
un modo di evoluzione, si parte da una condizione iniziale unitaria in
evoluzione libera, il che equivale a considerare una condizione
iniziale di ampiezza pari a 1 posizionata sull'autovettore
corrispondente all'autovalore considerato. In questo modo si isola una
particolare dinamica del sistema rispetto alle altre.
-------------------------------------------------

\subsection{Modi di evoluzione asintoticamente stabili}
\subsubsection{Autovalore reale positivo}
In questo caso si ha un autovalore reale positivo, $\rho$, con
modulo minore di~1:
\[
|\rho| < 1
\]
la cui evoluzione sar\`a:
\[
\rho^k
\]
che corrisponde ad un modo di evoluzione convergente dovuto al
modulo minore di 1.

\begin{figure}[!h]
  \begin{center}
    \includegraphics[scale=0.4]{./figures/autovaloreRealePositivo00.png}
    \caption{Autovalore reale positivo}\label{fig:autovaloreRealePositivo00}
  \end{center}
\end{figure}

\begin{figure}[!h]
  \begin{center}
    \includegraphics[scale=0.4]{./figures/autovaloreRealePositivo01.png}
    \caption{Autovalore reale positivo}\label{fig:autovaloreRealePositivo01}
  \end{center}
\end{figure}

\begin{figure}[!h]
  \begin{center}
    \includegraphics[scale=0.4]{./figures/autovaloreRealePositivo02.png}
    \caption{Autovalore reale positivo}\label{fig:autovaloreRealePositivo02}
  \end{center}
\end{figure}
La costante di tempo \`e la velocit\`a con cui il sistema
converge:
\[\left\{
\begin{array}{l}
  e^{\alpha t} \to \tau = - \dfrac{1}{\alpha} \;\;\textrm{Tempo
    continuo}\\
  \rho^k = e^{\ln \rho} \to \tau = - \dfrac{1}{\ln \rho}
  \;\;\textrm{Tempo discreto}
\end{array}
\right.
\]
Se desideriamo una dinamica veloce, dobbiamo assicurarci che la
costante di tempo $\tau$ si piccola. Ci\`o corrisponde in
evoluzione tempo continuo ad allontanarsi dall'asse
immaginario. Per dinamiche convergenti si ha
\[
\begin{array}{l}
  |\rho| < 1\\
  \ln \rho < 0\\
  \tau > 0
\end{array}
\]
Per avere un valore piccolo di $\tau$, quindi, si dovr\`a avere
un valore grande di $\ln \rho$, ottenibile per $\rho \to
0$. Ricapitolando: quando $\rho \to 0$, tanto pi\`u l'autovalore
si allontana dalla circonferenza di raggio unitario, tanto pi\`u
sar\`a piccola la costante di tempo $\tau$ e tanto pi\`u veloce
sar\`a il modo di evoluzione.

\subsubsection{Autovalore reale negativo}
\begin{figure}[!h]
  \begin{center}
    \includegraphics[scale=0.3]{./figures/autovaloreRealeNegativo00.png}
    \caption{Autovalore reale
      negativo}\label{fig:autovaloreRealeNegativo00.png} 
  \end{center}
\end{figure}
\begin{figure}[!h]
  \begin{center}
    \includegraphics[scale=0.3]{./figures/autovaloreRealeNegativo01.png}
    \caption{Autovalore reale
      negativo}\label{fig:autovaloreRealeNegativo01.png} 
  \end{center}
\end{figure}
Simile al caso precedente, con la differenza che l'autovalore \`e
negativo:
\[
(- \rho)^k = (-1)^k \rho^k
\]
Riconosciamo il modo di evoluzione a parte reale positiva, ma se $k$
\`e pari si ottiene un campione positivo, se, invece, $k$ \`e
dispari si ottiene un campione negativo.

Questo modo, vista l'assenza di una componente immaginaria, non \`e
oscillatorio. \`E, per\`o, detto {\em alternato} perch\`e alterna un
campione positivo ad uno negativo.

\subsubsection{Autovalore nell'origine}
\begin{figure}[!h]
  \begin{center}
    \includegraphics[scale=0.4]{./figures/autovaloreNellOrigine00.png}
    \caption{Autovalore nell'origine}\label{fig:autovaloreNellOrigine00}
  \end{center}
\end{figure}
\begin{figure}[!h]
  \begin{center}
    \includegraphics[scale=0.4]{./figures/autovaloreNellOrigine01.png}
    \caption{Autovalore nell'origine}\label{fig:autovaloreNellOrigine01}
  \end{center}
\end{figure}
Al decrescere di $\rho$ si avr\`a il caso limite, cio\`e un polo
nel centro della circonferenza unitaria. Nel continuo, invece, \`e
impossibile posizionare un polo all'infinito.

In questo caso, avremo $\tau = 0$: il fenomeno si estinguer\`a
istantaneamente. L'evoluzione partir\`a da 1 e raggiunger\`a 0
istantaneamente.
  
\subsubsection{Autovalore complesso e coniugato a parte reale positiva}
\begin{figure}[!h]
  \begin{center}
    \includegraphics[scale=0.3]{./figures/autovaloreComplessoConiugatoRealePositivo00.png}
    \caption{Autovalore complesso e coniugato a parte reale
      positiva}\label{fig:autovaloreComplessoConiugatoRealePositivo00.png} 
  \end{center}
\end{figure}
\begin{figure}[!h]
  \begin{center}
    \includegraphics[scale=0.3]{./figures/autovaloreComplessoConiugatoRealePositivo01.png}
    \caption{Autovalore complesso e coniugato a parte reale
      positiva}\label{fig:autovaloreComplessoConiugatoRealePositivo01.png} 
  \end{center}
\end{figure}
Per descrivere questo modo di evoluzione sfrutteremo la
rappresentazione ``modulo e fase'' $\rho^k (A_1 cos \theta k +
A_2 sin \theta k)$. La convergenza e la velocit\`a sono date
dalla funzione potenza $\rho^k$. La costante di tempo \`e $\tau
= - \dfrac{1}{\ln \rho}$, quindi quanto pi\`u l'autovalore \`e
vicino al centro della circonferenza unitaria, tanto pi\`u il
fenomeno sar\`a veloce.

\subsubsection{Autovalore complesso e coniugato a parte reale nulla}
\begin{figure}[!h]
  \begin{center}
    \includegraphics[scale=0.3]{./figures/autovaloreComplessoConiugatoRealeNulla00.png}
    \caption{Autovalore complesso e coniugato a parte reale
      nulla}\label{fig:autovaloreComplessoConiugatoRealeNulla00.png}
  \end{center}
\end{figure}
\begin{figure}[!h]
  \begin{center}
    \includegraphics[scale=0.3]{./figures/autovaloreComplessoConiugatoRealeNulla01.png}
    \caption{Autovalore complesso e coniugato a parte reale
      nulla}\label{fig:autovaloreComplessoConiugatoRealeNulla01.png}
  \end{center}
\end{figure}
L'autovalore in questione \`e immaginrio puro. Nel continuo
ci\`o equivale a modi costanti. Nel discreto, invece, avremo
modi con fase pari a $90^{\circ}$. Comparando le figure
\ref{fig:autovaloreComplessoConiugatoRealePositivo01.png} e
\ref{fig:autovaloreComplessoConiugatoRealeNulla01.png} notiamo
delle similitudini. Esaminando con attenzione la
\ref{fig:autovaloreComplessoConiugatoRealeNulla01.png}, ci
accorgiamo che i campioni avranno valore positivo, nullo,
negativo, nullo e cos\`i via.

\subsection{Modi di evoluzione instabili}
I modi di evoluzione instabili hanno la stessa forma matematica dei
modi stabili con la differenza che $|\rho| > 1$.

\subsubsection{Autovalore reale positivo}
\begin{figure}[!h]
  \begin{center}
    \includegraphics[scale=0.4]{./figures/autovaloreRealePositivoInstabile00.png}
    \caption{Autovalore reale positivo}\label{fig:autovaloreRealePositivoInstabile00}
  \end{center}
\end{figure}
\begin{figure}[!h]
  \begin{center}
    \includegraphics[scale=0.4]{./figures/autovaloreRealePositivoInstabile01.png}
    \caption{Autovalore reale positivo}\label{fig:autovaloreRealePositivoInstabile01}
  \end{center}
\end{figure}
Come nel caso stabile, il modo di evoluzione sar\`a sempre
$\rho^k$. In questo caso, per\`o, a causa del $|\rho| > 1$, il modo di
evoluzione sar\`a divergente.

La velocit\`a del modo sar\`a sempre influenzata dalla distanza
dell'autovalore dalla circonferenza unitaria: minore \`e la distanza
dalla circonferenza unitaria, minore sar\`a la velocit\`a; maggiore
\`e la distanza, maggiore sar\`a la velocit\`a.

La costante di tempo \`e adesso negativa, $\tau = - \dfrac{}{\ln
  \rho}$, a causa del $|\rho| > 1$. Dal punto di vista sistemistico
\`e una informazione insiglificante: un tempo non pu\`o essere
negativo. Dal punto di vista matematico, lo si pu\`o considerare
$|\tau|$ ed avere un'idea di quanto il sistema sia veloce a
divergere. Informazione comunque ``inutile'', poich\`e se un sistema
diverge, \`e insiglificante sapere quanto velocemente.

\subsubsection{Autovalore complesso e coniugato a parte reale positiva}
\begin{figure}[!h]
  \begin{center}
    \includegraphics[scale=0.3]{./figures/autovaloreComplessoConiugatoRealePositivoInstabile00.png} 
    \caption{Autovalore complesso e coniugato a parte reale
      positiva}\label{fig:autovaloreComplessoConiugatoRealePositivoInstabile00.png} 
  \end{center}
\end{figure}
\begin{figure}[!h]
  \begin{center}
    \includegraphics[scale=0.3]{./figures/autovaloreComplessoConiugatoRealePositivoInstabile01.png}
    \caption{Autovalore complesso e coniugato a parte reale
      positiva}\label{fig:autovaloreComplessoConiugatoRealePositivoInstabile01.png} 
  \end{center}
\end{figure}
Similmente al caso stabile, anche in questa situazione il modo di
evoluzione \`e:
\[
\rho^k (A_1 cos \theta k + A_2 sin \theta k)
\]
L'andamento \`e detto {\em pseudoperiodico}.

\subsubsection{Autovalore complesso e coniugato a parte reale nulla}
\begin{figure}[!h]
  \begin{center}
    \includegraphics[scale=0.3]{./figures/autovaloreComplessoConiugatoRealeNullaInstabile00.png}
    \caption{Autovalore complesso e coniugato a parte reale
      nulla}\label{fig:autovaloreComplessoConiugatoRealeNullaInstabile00.png}
  \end{center}
\end{figure}
\begin{figure}[!h]
  \begin{center}
    \includegraphics[scale=0.3]{./figures/autovaloreComplessoConiugatoRealeNullaInstabile01.png}
    \caption{Autovalore complesso e coniugato a parte reale
      nulla}\label{fig:autovaloreComplessoConiugatoRealeNullaInstabile01.png}
  \end{center}
\end{figure}
Come nel caso stabile, anche in questo caso si avr\`a un campione
positivo, uno nullo, uno negativo, uno nullo e uno positivo. La fase
di $90^{\circ}$ fa in modo che il campionamento sia sincrono rispetto
al passaggio sull'asse dei tempi.

\subsubsection{Autovalore reale negativo}
\begin{figure}[!h]
  \begin{center}
    \includegraphics[scale=0.3]{./figures/autovaloreRealeNegativoInstabile00.png}
    \caption{Autovalore reale
      negativo}\label{fig:autovaloreRealeNegativoInstabile00.png} 
  \end{center}
\end{figure}
\begin{figure}[!h]
  \begin{center}
    \includegraphics[scale=0.3]{./figures/autovaloreRealeNegativoInstabile01.png}
    \caption{Autovalore reale
      negativo}\label{fig:autovaloreRealeNegativoInstabile01.png} 
  \end{center}
\end{figure}
Del tutto simile all'andamento alternato del caso stabile. Il modo di
evoluzione \`e:
\[
(-1)^k \rho^k
\]
con un'alternanza di campioni positivi e negativi in base al valore di
$k$.

\subsection{Autovalori sulla circonferenza unitaria}

\subsubsection{Autovalore reale positivo}
\begin{figure}[!h]
  \begin{center}
    \includegraphics[scale=0.4]{./figures/autovaloreRealePositivoCirconferenza00.png}
    \caption{Autovalore reale positivo}\label{fig:autovaloreRealePositivoCirconferenza00}
  \end{center}
\end{figure}
\begin{figure}[!h]
  \begin{center}
    \includegraphics[scale=0.4]{./figures/autovaloreRealePositivoCirconferenza01.png}
    \caption{Autovalore reale positivo}\label{fig:autovaloreRealePositivoCirconferenza01}
  \end{center}
\end{figure}
Il modo di evoluzione \`e sempre $\rho^k$, ma $|\rho| = 1$. Questo
modo nel continuo \`e il gradino unitario.

\subsubsection{Autovalore complesso e coniugato a parte reale positiva}
\begin{figure}[!h]
  \begin{center}
    \includegraphics[scale=0.3]{./figures/autovaloreComplessoConiugatoRealePositivoCirconferenza00.png} 
    \caption{Autovalore complesso e coniugato a parte reale
      positiva}\label{fig:autovaloreComplessoConiugatoRealePositivoCirconferenza00.png} 
  \end{center}
\end{figure}
Anche in questo caso l'andamento \`e
\[
\rho^k (A_1 cos \theta k + A_2 sin \theta k)
\]
e il modulo unitario generer\`a un andamento costante, simile ad una sinusoide.

\subsubsection{Autovalore complesso e coniugato a parte reale nulla}
\begin{figure}[!h]
  \begin{center}
    \includegraphics[scale=0.3]{./figures/autovaloreComplessoConiugatoRealeNullaCirconferenza00.png}
    \caption{Autovalore complesso e coniugato a parte reale
      nulla}\label{fig:autovaloreComplessoConiugatoRealeNullaCirconferenza00.png}
  \end{center}
\end{figure}
\begin{figure}[!h]
  \begin{center}
    \includegraphics[scale=0.3]{./figures/autovaloreComplessoConiugatoRealeNullaCirconferenza01.png}
    \caption{Autovalore complesso e coniugato a parte reale
      nulla}\label{fig:autovaloreComplessoConiugatoRealeNullaCirconferenza01.png}
  \end{center}
\end{figure}
Anche in questo caso, la fase di $90^{\circ}$ far\`a s\`i che i
campioni si alternino: positivo, nullo, negativo, nullo, positivo, ...

\subsubsection{Autovalore reale negativo}
\begin{figure}[!h]
  \begin{center}
    \includegraphics[scale=0.3]{./figures/autovaloreRealeNegativoCirconferenza00.png}
    \caption{Autovalore reale
      negativo}\label{fig:autovaloreRealeNegativoCirconferenza00.png} 
  \end{center}
\end{figure}
\begin{figure}[!h]
  \begin{center}
    \includegraphics[scale=0.3]{./figures/autovaloreRealeNegativoCirconferenza01.png}
    \caption{Autovalore reale
      negativo}\label{fig:autovaloreRealeNegativoCirconferenza01.png} 
  \end{center}
\end{figure}
Nuovamente abbiamo un modo alternato al variare di $k$: positivo,
nullo, positivo, nullo, ...

\section{Stabilit\`a e guadagno statico}
Per definizione, un punto di equilibrio $\bar{x}$ appartenente ad un
segnale $x(k)$ \`e stabile se
\begin{equation}
  \forall \varepsilon > 0 \; \exists \;\delta > 0 \;\;t.c. \;\; \parallel x(0) -
  \bar{x} \parallel \leq \varepsilon \;\; \textrm{allora} \;\;
  \parallel x(k) - \bar{x} \parallel \leq \delta
\end{equation}
Se si parte da una condizione iniziale $x(0)$ prossima al punto di
equilibrio $\bar{x}$ e l'evoluzione rimane in un intorno del punto
di equilibrio, il punto di equilibrio $\bar{x}$ si dice {\em stabile}.

Il sistema \`e asintoticamente stabile se
\[
\lim_{k \to \infty} \parallel x(k) - \bar{x} \parallel = 0
\]
cio\`e se all'infinito la distanza tra l'evoluzione e il punto di
equilibrio si annulla. In questo caso, considerato il sistema dinamico,
tempo discreto, lineare e tempo invariante, tutti gli autovalori della
matrice A hanno modulo minore di 1.

Il sistema pu\`o essere anche marginalmente stabile se ha un polo o un
modo di evoluzione sulla circonferenza unitaria. Se la molteplicit\`a
di questo polo \`e maggiore di 1, il sistema \`e instabile e diverge
con andamento ``a rampa'' (2 poli), ``a parabola'' (3 poli).

\begin{definizione}
  Dato un sistema discreto, tempo invariante e asintoticamente stabile,
  si definisce {\em guadagno statico}\index{Guadagno statico} il
  rapporto tra l'uscita a regime e l'ingresso costante con cui si eccita
  il sistema.
\end{definizione}
$G(z)$ \`e una generica funzione di trasferimento. Il sistema in esame
\`e in evoluzione forzata. Sollecitiamo il sistema con un ingresso
costante $u(k) = \overline{U}$, che nel dominio della $z$ diventa
\[
U(z) = \overline{U}\dfrac{z}{z - 1}
\]
\[
Y(z) = G(z) U(z)
\]
Applicando il teorema del valore finale(\ref{teoremaFinaleDiscreto})
otteniamo il valore a regime:
\[
Y_{\infty} = \lim_{z \to 1} (z - 1)Y(z) = \lim_{z \to 1} (z - 1) G(z)
\overline{U}\dfrac{z}{(z - 1)} = G(1)\overline{U}
\]
Il guadagno statico \`e il rapporto tra l'uscita a regime e l'ingresso
costante:
\[
k = \dfrac{G(1) \overline{U}}{\overline{U}} = G(1)
\]
Il guadagno statico, nel dominio del tempo discreto, \`e, quindi, pari
alla funzione di trasferimento valutata in 1, come nel dominio del
tempo continuo era pari alla funzione di trasferimento valutata in
$s~=~0$
\[
z \to 1 \;\;\; s \to 0
\]

\chapter{Campionamento e ricostruzione del segnale}
\begin{figure}[!h]
  \begin{center}
    \includegraphics[scale=0.3]{./figures/campionamentoRicostruizioneSegnale.png}
    \caption{Cascata ADC-DAC}\label{fig:campionamentoRicostruizioneSegnale}
  \end{center}
\end{figure}
Consideriamo un generico segnale di $x(t)$ in ingresso alla cascata
ADC e DAC, figura~\ref{fig:campionamentoRicostruizioneSegnale}. In
teoria, dovremmo ottenere
\[
x(t) = x_r(t)
\]
In realt\`a riusciamo ad ottenere la stessa quantit\`a di informazione
del segnale originario $x(t)$. Si \`e disposti a perdere alcune
informazioni, purch\`e il segnale ricostruito $x_r(t)$ contenga le
informazioni necessarie ad approssimare il segnale di ingresso $x(t)$
in maniera sufficientemente accurata da controllare il sistema.

\section{Campionatore o convertitore analogico/digitale ADC}
Il campionatore converte un segnale a tempo continuo in una sequenza
di campioni prelevati negli istanti $t = 0, T, 2T, ...$, dove $T$ \`e
il periodo di campionamento. I parametri fondamentali di un
campionatore sono quindi
\begin{itemize}
\item $T$ o $T_s$ il tempo di campionamento, che indica quanto sia
  distanziato nel tempo un campione dal campione successivo;
\item $f_s = \dfrac{1}{T_s}$ la frequenza di campionamento, che indica il numero di
  volte al secondo in cui il segnale analogico viene misurato e
  memorizzato in forma digitale;
\item $\omega_s = 2 \pi f_s = \dfrac{2 \pi}{T_s}$ la pulsazione di campionamento
\end{itemize}

\section{Mantenitore o convertitore digitale/analogico DAC}
Il convertitore digitale/analogico \`e tipicamente chiamato
ricostruttore ed ha il compito di trasformare il segnale a tempo
discreto ($u(kT)$) nel segnale tempo continuo ($u(t)$). I parametri
fondamentali di un mantenitore sono quindi
\begin{itemize}
\item $T$ o $T_m$ il tempo di mantenimento
\item $f_m = \dfrac{1}{T_m}$ la frequenza di mantenimento
\item $\omega_m = 2 \pi f_m = \dfrac{2 \pi}{T_m}$ la pulsazione di
  mantenimento
\end{itemize}

\subsection{Mantenitore di ordine zero o
  ZOH}\label{ricostruttoreOrdineZeroAccenni} 
Il ricostruttore di ordine zero \`e il ricostruttore pi\`u
semplice. \`E detto di ordine zero perch\`e approssima l'andamento del
segnale tra un campione e l'altro con una funzione lineare di ordine
zero, cio\`e una costante.

\begin{figure}[!h]
  \begin{center}
    \includegraphics[scale=0.3]{./figures/zoh00.png}
    \caption{Ricostruttore ZOH - Segnale di partenza}\label{fig:zoh00}
  \end{center}
\end{figure}
\begin{figure}[!h]
  \begin{center}
    \includegraphics[scale=0.3]{./figures/zoh01.png}
    \caption{Ricostruttore ZOH - Segnale ricostruito}\label{fig:zoh01}
  \end{center}
\end{figure}

La figura~\ref{fig:zoh00} mostra una sequenza generica di campioni
$x(kT)$. Dalla sola sequenza di campioni non possiamo sapere cosa ci
sia tra un campione, all'istante $t = kT$, e l'altro, all'istante $t =
(k + 1)T$. Potrebbero esserci infinite funzioni $x(t)$ associate alla
stessa sequenza $x(kT)$. Il ricostruttore ZOH mantiene quindi l'uscita
per $kT < t < (k + 1)T$ al valore del campione ricevuto all'istante
$t~=~kT$. 

La figura~\ref{fig:zoh01} mostra il risultato della ricostruzione: una
sommatoria di gradini tali che il segnale ricostruito $x_r(t)$ possa
essere scritto come: 
\begin{equation}\label{eq:zoh00}
  x_r(t) = \sum_{k = 0}^{\infty} x(kT) [h(t - kT) - h(t - (k + 1)T)]
\end{equation}
dove
\begin{itemize}
\item $h(t - kT)$ \`e la funzione gradino ritardata di $kT$;
\item $h(t - (k + 1)T)$ \`e la successiva funzione gradino ritardata di
  $(k + 1)T$;
\item $[h(t - kT) - h(t - (k + 1)T)]$ \`e la finestra unitaria
  descritta come differenza di due gradini o anche come gradino che si
  attiva nell'istante $kT$ e termina nell'istante $(k + 1)T$;
\item $x(kT)$ \`e l'ampiezza di ciascuna finestra appena definita.
\end{itemize}

Con la trasformata di Laplace $X_r(s)$ si ottiene una combinazione
lineare di trasformate di Laplace del gradino traslato:
\[
X_r(s) = \sum_{k=0}^{\infty} x(kT) \left[ \dfrac{1}{s}e^{-kTs} -
  \dfrac{1}{s}e^{-(k+1)T}\right] 
\]
Mettendo in evidenza $e^{-kTs}$
\[
X_r(s) = \sum_{k=0}^{\infty} x(kT) e^{-kTs}\left[ \dfrac{1 -
    e^{-Ts}}{s}\right]  
\]
\[
X_r(s) = \left[ \dfrac{1 - e^{-Ts}}{s}\right]  \sum_{k=0}^{\infty}
x(kT) e^{-kTs}
\]
Notiamo che $\left[ \dfrac{1 - e^{-Ts}}{s}\right]$ \`e la trasformata
di Laplace della prima finestra unitaria, tra 0 e $T$: $L[h(t) - h(t -
  T)]$

A questo punto, cominciamo a considerare la trasformata di Laplace
di $x_r(t)$ come
\[
X_r(s) = H_0(s) X^{*}(s)
\]
\begin{itemize}
\item $H_0(s) = \dfrac{1 - e^{-Ts}}{s}$ \`e la trasformata di Laplace
  della prima finestra:\\$L[h(t)~-~h(t~-~T)]$;
\item $X^{*}(s) = \sum_{k=0}^{\infty} x(kT) e^{-kTs}$ cio\`e una
  combinazione lineare di infiniti termini esponenziali in funzione di
  $s$, pari alla trasformata di un segnale $x^{*}(t)$ a sua volta
  funzione della sequenza di campioni $x(kT)$.
\end{itemize}
Quindi, si nota la comodit\`a di lavorare nel dominio della $s$ e
poter comunque ritornare al segnale $x(kT)$ antitrasformando $X_r(s)$,
ottenendo $x_r(t)$ e infine $x(kT)$.

La funzione di trasferimento di ZOH presenta quindi anche una
componente di {\em ritardo} che incide sulla catena di andata. Ci
potremmo ritrovare nella situazione di riuscire a ricostruire con
soddisfazione il segnale $x(t)$, ma avremo inserito un ritarto tanto
pi\`u grande quanto grande \`e il tempo di campionamento $T$. Questo
ritardo influisce sul margine di fase $\varphi_m$ e potrebbe portare
all'instabilit\`a del sistema a ciclo chiuso.

Dall'antitrasformata di $X^{*}(s)$ cerchiamo di ottenere $x^{*}(t)$:
\[
X^{*}(s) = \sum_{k=0}^{\infty} x(kT) e^{-kTs}
\]
\[
x^{*}(t) = \sum_{k=0}^{\infty} x(kT) \delta (t - kT)
\]
con $\delta(t - kT)$ impulso di Dirac di area unitaria applicato
all'istante $t = kT$. Quindi l'antitrasformata di $X^{*}(s)$ \`e
combinazione lineare delle singole antitrasformate dei termini
esponenziali, la cui antitrasformata \`e proprio l'impulso di Dirac
traslato $\delta(t - kT)$.

Dalla propriet\`a del campionamento impulsivo del segnale $x(t)$,
cio\`e l'operazione di moltiplazione di un segnale $x(t)$ per una
sequenza di impulsi $\delta_T(t)$, possiamo scrivere:
\[
x^{*}(t) = \sum_{k=0}^{\infty} x(kT) \delta (t - kT) =
\sum_{k=0}^{\infty} x(t) \delta (t - kT) = x(t)\sum_{k=0}^{\infty}
\delta (t - kT) 
\]
Per comodit\`a riscriviamo $x^{*}(t)$ come:
\begin{equation}
  x^{*}(t) = x(t) \delta_T(t)
\end{equation}
con
\[
\delta_T(t) = \sum_{k=0}^{\infty} \delta(t - kT)
\]
cio\`e la sequenza di impulsi di Dirac di area unitaria, e avendo
l'accortezza di considerare $x(t) = 0$ per $t < 0$. In definitiva, il
segnale $x^{*}(t)$ rappresenta una sequenza di impulsi di Dirac
modulati in ampiezza dai campioni $x(kT)$ e, quindi, nell'ipotesi che
il DAC sia descritto da una funzione di trasferimento $H_0(s)$
possiamo considerare $x^{*}(t)$ nel tempo continuo $t$ equivalente
alla sequenza di campioni $x(kT)$ nel tempo discreto $k$.

Se consideriamo la trasformata di Laplace del segnale impulsivo
\[
X^{*}(s) = \sum_{k=0}^{\infty} x(kT) e^{-kTs}
\]
e introduciamo la variabile complezza $z$
\[
z = e^{sT} \;\;\; s = \dfrac{1}{T}\ln z
\]
\[
X^{*}(s)\left|_{s = \dfrac{1}{T}\ln z}\right. = \sum_{k=0}^{\infty} x(kT) z^{-k}
\]
\[
X^{*}(s)\left|_{s = \dfrac{1}{T}\ln z}\right. = X^{*}\left(
\dfrac{1}{T} \ln z \right) = X(z) = \sum_{k=0}^{\infty} x(kT) z^{-k}
\]
Risulta chiara la corrispondenza tra la trasformata di Laplace
$X^{*}(s)$ del segnale campionato ad impulsi di Dirac e la
Z-trasformata $X(z)$ della sequenza di valori $x(kT)$. L'uso della
Z-antitrasformata di $x(kT)$ piuttosto che quello della trasformata di
Laplace del segnale $x^{*}(t)$ \`e motivato dal fatto di voler operare
con funzioni razionali fratte piuttosto che con funzioni trascendenti
di variabile complezza.

\section{Spettro del segnale campionato}
Se consideriamo $t < 0$, possiamo riscrivere $x^{*}(t)$ come
\[
x^{*}(t) = x(t) \delta_T(t) = x(t) \sum_{n = -\infty}^{\infty} \delta
(t - nT)
\]
e considerare $\delta_T(t)$ estesa a tutto l'asse del tempo. Il nuovo
segnale $\delta_T(t)$ \`e periodo di periodo $T$ e pu\`o essere
sviluppato in serie di Fourier, usando la formula a coefficienti
complessi:
\[
\delta_T(t) = \sum_{n = -\infty}^{\infty} c_n e^{j n \omega_s t}, \;\;\;
c_n = \dfrac{1}{T} \int_{0}^{T} \delta_T(t) e^{-j n \omega_s t } dt =
\dfrac{1}{T} 
\]
\[
x^{*}(t) = x(t) \dfrac{1}{T} \sum_{n = -\infty}^{\infty} e^{j n
  \omega_s t} = \dfrac{1}{T} \sum_{n = -\infty}^{\infty} x(t) e^{j n
  \omega_s t} 
\]
A questo punto calcoliamo la trasformata di Laplace e sfruttiamo le
propriet\`a di linearit\`a e traslazione:
\begin{equation}
X^{*}(s) = \dfrac{1}{T} \sum_{n = - \infty}^{\infty} X(s - j n
\omega_s)
\end{equation}
Si nota che la trasformata di Laplace di $X^{*}{s}$ del segnale
campionato \`e data dalla somma degli infiniti termini $X(s - j n
\omega_s)$, ottenuto mediante traslazione di $j n \omega_s$. Va
comunque tenuta in considerazione la costante moltiplicativa
$\dfrac{1}{T}$. 

Possiamo passare nel dominio della frequenza sostituendo $s = j
\omega$
\begin{equation}
  X^{*}(j \omega) = \dfrac{1}{T} \sum_{n = - \infty}^{\infty} X(j\omega - j n
\omega_s)
\end{equation}
L'andamento spettrale $X^{*}(j \omega$ del segnale campionato
$x^{*}(t)$ si ottiene a partire dallo spettro del segnale $x(t)$ pi\`u
una sommatoria di infinite repliche dello stesso spettro, ma traslato
di $j n \omega_s$ con $n \in (-\infty, +\infty)$:
\begin{equation}
  |X^{*}(j \omega)| = \dfrac{1}{T} \sum_{n = - \infty}^{\infty} |X(j\omega - j n
  \omega_s)|
\end{equation}

\subsection{Segnale originario $x(t)$ avente uno spettro $|X(j
  \omega|)$ ``a banda limitata''}
\begin{figure}[!h]
  \begin{center}
    \includegraphics[scale=0.3]{./figures/spettroSegnaleCampionatoBandaLimitata.png}
    \caption{Spettro del segnale campionato a banda
      limitata - scala naturale}\label{fig:spettroSegnaleCampionatoBandaLimitata} 
  \end{center}
\end{figure}
$\omega_c$ \`e la pulsazione oltre la quale il generico segnale $x(t)$
non ha pi\`u componenti frequenziali. $\omega_c$ \`e un indicatore della
banda passente del segnale $x(t)$. $\omega_c$ non \`e la pulsazione di
attraversamento della funzione $L(s)$.
\begin{figure}[!h]
  \begin{center}
    \includegraphics[scale=0.3]{./figures/spettroSegnaleCampionatoBandaLimitata01.png}
    \caption{Spettro del segnale campionato
      $x^{*}(t)$}\label{fig:spettroSegnaleCampionatoBandaLimitata01}    
  \end{center}
\end{figure}
Abbiamo supposto che il segnale $x(t)$ sia a banda limitata, cio\`e
che vada a zero. Questa \`e esattamente una supposizione. Nella
realt\`a la banda non va mai a zero, ma avr\`a inevitabilmente delle
code. Possiamo solo considerare ``nulle'' le componenti attenuate di 
$20dB$ o $40dB$. Abbiamo indicato la pulsazione massima di interesse
con $\omega_c$. La
figura~\ref{fig:spettroSegnaleCampionatoBandaLimitata01} mostra
l'andamento spettrale del segnale campionato $x^{*}(t)$ nel caso in
cui $\omega_s > 2 \omega_c$, in scala naturale.

Per $n = 0$ abbiamo la replica primaria\index{Replica primaria} o
fondamentale\index{Replica fondamentale} $\dfrac{|X(j \omega)|}{T}$
che coincide, a meno della costante $\dfrac{1}{T}$, con lo spettro
frequenziale $|X(j \omega)|$ del segnale originario $x(t)$. Per $n
\neq 0$ abbiamo le componenti complementari $\dfrac{|X(j \omega + j n
  \omega_s)}{T}$.

Ricordiamo ancora una volta, che se la pulsazione di campionamento
$\omega_s > 2 \omega_c$, cio\`e la distanza tra una replica e la
successiva \`e maggiore del doppio della banda passante del segnale
originario $x(t)$ le repliche non si sovrapporranno.

\subsection{Teorema di Shannon}\index{Teorema di Shannon}
\begin{definizione}
  Sia $\omega_s = \dfrac{2 \pi}{T}$ la pulsazione di campionamento e
  $\omega_c$ (o $\omega_b$) la pi\`u alta componente spettrale del
  segnale a tempo continuo $x(t)$, il segnale originario $x(t)$ \`e
  completamente ricostruibile a partire dal segnale campionato
  $x^{*}(t)$ se e solo se la pulsazione di campionamento $\omega_s$
  \`e maggiore del doppio della pulsazione $\omega_c$ (o $\omega_b$)
  \[
  \omega_s = 2\cdot \omega_c
  \]
\end{definizione}

Se il Teorema di Shannon non \`e soddisfatto le repliche saranno
parzialmente sovrapposte, dando vita al fenomeno
dell'aliasing\index{Aliasing}, cio\`e mediante il campionamento si
generano componenti spettrali alla stessa frequenza della componente
spettrale di partenza che impediscono la corretta ricostruzione del
segnale di partenza. Ulteriore problema sar\`a la sovrapposizione
delle repliche complementari sulla replica fondamentale, che sar\`a
difficilmente isolabile tramite un filtro ideale, vanificando ogni
possibilit\`a di ricostruire il segnale $x(t)$ a partire da
$x^{*}(t)$. 
\begin{figure}[!h]
  \begin{center}
    \includegraphics[scale=0.3]{./figures/aliasing.png}
    \caption{Aliasing - sovrapposizione delle
      repliche}\label{fig:aliasing} 
  \end{center}
\end{figure}

\subsection{Segnale originario $x(t)$ avente uno spettro $|X(j
  \omega)|$ ``a banda illimitata''}
\begin{figure}[!h]
  \begin{center}
    \includegraphics[scale=0.3]{./figures/spettro_banda_illimitata.png}
    \caption{Spettro $|X(j \omega)|$ a banda
      illimitata}\label{fig:spettroBandaIllimitata} 
  \end{center}
\end{figure}
La figura~\ref{fig:spettroBandaIllimitata} mostra il confronto tra il
caso ideale che abbiamo trattato finora, cio\`e un segnale a banda
rigorosamente limitata e il caso reale in cui un segnale ha
tipicamente delle componenti ad alta frequenza che non possono essere
semplicemente ignorate.

I segnali reali vanno, quindi, valutati singolarmente e bisogna
scegliere fino a quele pulsazione si vogliono considerare
significative le componenti del segnale. Bisogna, in sostanza,
scegliere la banda passante $\omega_c$ (o $\omega_b$) del segnale.

Tipicamente possiamo considerare trascurabili le componenti armoniche
del segnale attenuate di $20dB$ o $40dB$. 

\section{Filtro ideale}\index{Filtro ideale}\label{filtroIdeale}
\begin{figure}[!h]
  \begin{center}
    \includegraphics[scale=0.5]{./figures/filtroIdeale.png}
    \caption{Spettro del filtro ideale}\label{fig:filtroIdeale}
  \end{center}
\end{figure}
Cardine della teoria della ricostruzione del segnale \`e la
possibilit\`a di ottenere la replica primaria, filtrando lo spettro
$|X(j \omega)|$ del segnale campionato $x^{*}(t)$ con un filtro
ideale. La figura\ref{fig:filtroIdeale} mostra lo spettro del filtro
ideale $G_I(j \omega)$. Dal punto di vista matematico, possiamo
formalizzarlo come
\begin{equation}
  G_I(j \omega) = 
  \left\{
  \begin{array}{ll}
    T & -\dfrac{\omega_s}{2} \leq \omega \leq \dfrac{\omega_s}{2}\\
    0 & \textrm{altrove}
  \end{array}
  \right.
\end{equation}

\subsubsection{Fisica realizzabilit\`a del filtro ideale}
Vogliamo assicurarci che il filtro ideale sia ``fisicamente
realizzabile''. Ne calcoliamo la risposta all'impulso.

La $G_I(j \omega)$ \`e la risposta impulsiva nel dominio della
frequenza $\omega$. Possiamo calcolare la risposta impulsiva nel
dominio della $t$ antitrasformando $G_I(j \omega)$.
\[
g_I(t) = \dfrac{1}{2 \pi} \int_{- \infty}^{\infty} G_I(j \omega) e^{j
  \omega t} d\omega
\]
Dalla definizione di $G_I(j \omega)$ possiamo restringere l'intervallo
di integrazione e sostituire i valori di $G_I(j \omega)$:
\[
g_I(t) = \dfrac{T}{2 \pi} \int_{-\dfrac{\omega_s}{2}}^{\dfrac{\omega_s}{2}}e^{j
  \omega t} d\omega
\]
\[
g_I(t) = \dfrac{T}{2 \pi} \left.\left[ \dfrac{e^{j \omega t}}{j \omega
    t}\right]\right|_{-\frac{\omega_s}{2}}^{\frac{\omega_s}{2}}
\]
\[
g_I(t) = \dfrac{T}{2 \pi} \left( e^{j \frac{\omega_2}{2}t} - e^{-j
  \frac{\omega_2}{2}t}\right) = \dfrac{T}{\pi
  t}sin\dfrac{\omega_s}{2}t
\]
con $sin \dfrac{\omega_s}{2}t = \dfrac{e^{j \frac{\omega_2}{2}t} - e^{-j
  \frac{\omega_2}{2}t}}{2j}$

A questo punto, con delle opportune manipolazioni matematiche, $T =
\dfrac{2 \pi}{\omega_s}$, possiamo riscrivere:
\[
g_I(t) = \dfrac{T}{\pi t}sin\dfrac{\omega_s}{2}t = \dfrac{sin
  \frac{\omega_s}{2}t}{\frac{\omega_s}{2}t} 
\]
Considerando che $\dfrac{sin xt}{x} = sinc (xt)$
\[
g_I(t) = sinc \dfrac{\omega_s}{2}t
\]
\begin{figure}[!h]
  \begin{center}
    \includegraphics[scale=0.5]{./figures/filtroIdealesinc.png}
    \caption{$sinc(\dfrac{\omega_s}{2}t)$}\label{fig:filtroIdealesinc}
  \end{center}
\end{figure}
La figura~\ref{fig:filtroIdealesinc} mostra l'andamento nel tempo
della risposta impulsiva di $g_I(t)$. Si nota con facilit\`a che
applicando un impulso di Dirac all'istante zero, il sistema risponde
con un segnale che non \`e nullo per $t < 0$. Il sistema $G_I(j
\omega)$ per $t < 0$ {\em prevede} l'arrivo dell'impulso a $t = 0$. Un
sistema di questo tipo \`e detto {\em anticipativo}\index{Anticipativo
- Sistema} o {\em anticausale}\index{Anticausale - Sistema} e,
purtroppo, \`e fisicamente irrealizzabile.

\section{Tipici ricostruttori di segnale}
Ricordiamo che i ricostruttori di segnale sono dei dispositivi che
ricevono in ingresso una sequenza $x(kT)$ di valori campionati e
forniscono in uscita un segnale continuo che approssima il segnale
$x(t)$ da cui \`e stata ricavata la sequenza $x()k$.

I ricostruttori di uso comune sono quelli ottenuti dallo sviluppo in
serie di Taylor del segnale $x(t)$ nell'intorno del punto $t = kT$:
\begin{equation}\label{eq:taylorRicostruttori}
  x(t) = x(kT) + \left. \dfrac{dx(t)}{dt}\right|_{t = kT} (t - kT) +
  \left. \dfrac{d^2x(t)}{dt^2}\right|_{t = kT} \dfrac{(t - kT)^2}{2!}
  + ...
\end{equation}
Se invece di considerare solo l'intorno $t = kT$ considerassimo tutti
i termini della serie, avremmo un'espressione molto complessa, ma
estremamente precisa: non avremmo una approssimazione, ma una vera
uguaglianza.

Avendo a disposizione solamente i valori campionati a $x(kT)$, le
derivate del segnale $x(t)$ nel punto $t = kT$ vengono calcolare
secondo le seguenti espressioni:
\[
\begin{array}{l}
\left. \dfrac{dx(t)}{dt}\right|_{t = kt} \simeq \dfrac{x(kT) - x((k -
  1)T)}{T}\\

\left. \dfrac{d^2x(t)}{dt^2}\right|_{t = kt} \simeq
\dfrac{\left. \dfrac{dx(t)}{dt}\right|_{t = kt} -
  \left. \dfrac{dx(t)}{dt}\right|_{t = (k - 1)t}}{T} \simeq
\dfrac{x(kT) - 2x((k - 1)T) + x((k - 2)T)}{T^2}
\end{array}
\]
Il numero di termini derivativi che vengono presi in considerazione
nell'equazione~\ref{eq:taylorRicostruttori} identifica {\em l'ordine
  del ricostruttore}. Maggiore \`e l'ordine del ricostruttore
maggiore \`e la precisione, maggiore \`e la complessit\`a, maggiore
\`e il pericolo che deriva dall'introduzione dei ritardi nell'anello
di controllo. 

Per rappresentare con una funzione di trasferimento continua $H_r(s)$
i ricostruttori, dobbiamo assumere che la sequenza $x(kT)$ di valori
in ingresso sia interpretata come una sequenza di impulsi di Dirac
aventi area pari ai valori $x(kT)$. In questo modo potremo ottenere
$H_r(s)$ semplicemente effettuando la trasformata di Laplace della
risposta impulsiva del ricostruttore.

\subsubsection{Astrazione matematica}\label{astrazioneMatematica}
Se consideriamo che il ricostruttore \`e un sistema ibrido, formato da
una parte tempo-continua e da una parte tempo-discreta capiamo che \`e
impossibile descrivere il ricostruttore con una funzione di
trasferimento.

Se si rimane nell'ipotesi che si effettui un campionamento ideale ad
opera di impulsi di Dirac, il segnale campionato $x^{*}(t)$ \`e un
segnale tempo-continuo e il ricostruttore pu\`o essere descritto con
una funzione di trasferimento.

Dobbiamo quindi rimanere nell'ipotesi che si lavori non sulla sequenza
di campioni $x(kT)$, ma sul segnale campionato $x^{*}(t)$, ottenuto
moltiplicando il segnale originario $x(t)$ col treno campionatore
$\delta_T(t)$.
\begin{figure}[!h]
  \begin{center}
    \includegraphics[scale=0.5]{./figures/astrazioneMatematica.png}
    \caption{Ricostruttore - Funzione di
      trasferimento}\label{fig:astrazioneMatematica} 
  \end{center}
\end{figure}

\subsection{Ricostruttore di ordine zero - ZOH}
Aggiungiamo qualche altra informazione alla teoria del ricostruttore
di ordine zero accennata nella
sezione~\ref{ricostruttoreOrdineZeroAccenni}. Come accennato in
precedenza, questo ricostruttore prende il nome dal termine
dell'espansione di Taylor che prendiamo in considerazione. Il legame
ingresso-uscita \`e definito come:
\begin{equation}\label{eq:ricostruttoreOrdineZero00} 
  x_0(t) = x(kT) \;\;\; kT \leq t \leq (k + 1)T
\end{equation}

Possiamo ottenere la funzione di trasferimento del ricostruttore di
ordine zero $H_0(s)$ effettuando la trasformata di Laplace della
risposta all'impulso $g_0(t)$. Il ricostruttore di ordine zero manterr\`a,
quindi, costante il valore nell'origine fino al campione successivo e
quindi la riposta $g_0(t)$ varr\`a 1 fino all'istante $T$, dopodich\`e
fino all'istante successivo $2T$ avr\`a valore pari a quello
nell'istante $T$, ovvero 0.

La risposta impulsiva \`e una funzione costante di ampiezza unitaria
non nulla solo all'interno dell'intervallo $[0, T]$, cio\`e la
finestra rettangolare mostrata in
figura~\ref{fig:ricostruttoreOrdineZeroRispostaImpulsiva}
\begin{equation}\label{eq:ricostruttoreOrdineZero}
  H_0(s) = L[g_0(t)] = L[h(t) - h(t - T)] = \dfrac{1}{s} - \dfrac{e^{-sT}}{s} =
  \dfrac{1 - e^{-sT}}{s}
\end{equation}

\begin{figure}[!h]
  \begin{center}
    \includegraphics[scale=0.5]{./figures/ricostruttoreOrdineZeroRispostaImpulsiva.png}
    \caption{Risposta impulsiva -
      ZOH}\label{fig:ricostruttoreOrdineZeroRispostaImpulsiva}
  \end{center}
\end{figure}

\subsection{Ricostruttore di ordine uno}
In riferimento alla serie di Taylor trattata in precedenza, arrestata
al secondo termine, il ricostruttore di ordine uno approssima il
segnale originario $x(t)$ nell'intorno del punto $t = kT$.

Nell'intervallo di tempo $kT \leq t \leq (k + 1)T$, il ricostruttore
di ordine uno fornisce un segnale $x(t)$ funzione del campione $x(kT)$
e del campione precedente $x((k - 1)T)$
\begin{equation}\label{eq:ricostruttoreOrdineUno}
  x_1(t) = x(kT) + \dfrac{x(kT) - x((k - 1)T)}{T}(t - kT)
\end{equation}
con $kT \leq t \leq (k + 1)T$
\begin{figure}[!h]
  \begin{center}
    \includegraphics[scale=0.5]{./figures/ricostruttoreOrdineUno00.png}
    \caption{Ricostruttore di ordine uno}\label{fig:ricostruttoreOrdineUno00}
  \end{center}
\end{figure}
La figura~\ref{fig:ricostruttoreOrdineUno} mostra un esempio di
ricostruzione effettuata con un ricostruttore di ordine
uno. Considerando l'intervallo di interesse  $kT \leq t \leq (k + 1)T$
abbiamo la necessit\`a di rappresentare il segnale $x(t)$ di cui non
conosciamo ancora il valore per $x((k + 1)T)$ nell'istante $t = (k +
1)T$. Essendo un ricostruttore di ordine uno, tra due campioni
successivi ci sar\`a una funzione del primo ordine: una retta. La
pendenza della retta \`e data dal rapporto incrementale dei valori dei
due campioni a $x(kT)$ e $x((k - 1)T)$.

La figura~\ref{fig:ricostruttoreOrdineUno} mostra anche il punto
debole del ricostruttore di ordine uno: reagisce lentamente alle brusche
variazioni di pendenza del segnale (inversioni di pendenza). Questa
debolezza \`e comunque ``ben assorbita'' da un efficace campionamento:
se si rispetta il Teorema di Shannon \`e improbabile assistere a
ripetute inversioni di pendeza del segnale.

Continuando a lavorare nell'ipotesi dell'astrazione
matematica~\ref{astrazioneMatematica}, possiamo calcolare la funzione
di trasferimento $H_1(s)$ facendo la trasformata di Laplace della sua
risposta impulsiva $g_1(t)$.
\begin{figure}[!h]
  \begin{center}
    \includegraphics[scale=0.5]{./figures/ricostruttoreOrdineUno01.png}
    \caption{Ricostruttore di ordine uno - riposta
      impulsiva}\label{fig:ricostruttoreOrdineUno01} 
  \end{center}
\end{figure}
La figura~\ref{fig:ricostruttoreOrdineUno01} mostra la risposta
impulsiva $g_1(t)$ del ricostruttore di ordine uno.

Nell'intervallo $0 \leq t \leq T$ sappiamo che nell'istante $t = 0$
($kT$ con $k = 0$) $\delta(0)$ vale 1, mentre $\delta(-T)$ vale
0 all'istante precedente $t = -T$ ($(k - 1)T$ con $k = 0$). Sfruttando
l'equazione~\ref{eq:ricostruttoreOrdineUno}, calcoliamo
\[
g_1(t) = 1 + \dfrac{1 - 0}{T} = 1 + \dfrac{1}{T}t
\]
che \`e esattamente la rampa di pendenza $\dfrac{1}{T}$ mostra nella
figura~\ref{fig:ricostruttoreOrdineUno01}. Iterando lo stesso
ragionamento per per l'intervallo $T \leq t \leq 2T$:
\[
g_1(t) = 0 + \dfrac{0 - 1}{T} (t - T) = - \dfrac{t - T}{T} = 1 -
\dfrac{1}{T}t
\]
Nell'ultimo intervallo $2T \leq t \leq 3T$ sappiamo solo che
nell'istante $t = 2T$, $\delta(2T) = 0$ e che per $t = T$, $\delta(T)
= 0$. Quindi
\[
g_1(t) = 0 + \dfrac{0 - 0}{T} (t - 2T) = 0
\]
Abbiamo ottenuto cos\`i la risposta impulsiva $g_1(t)$ complessiva
come combinazione di gradini e rampe:
\[
g_1(t) = x_1(t)h(t) + x_2(t)h(t - T) + x_3(t)h(t - 2T)
\]
Calcoliamo adesso la trasformata di Laplace $L[g_1(t)]$, considerando
intervallo per intervallo:
\begin{itemize}
\item $0 \leq t \leq T$
  \[
  \left\{
  \begin{array}{l}
    g_1(t) = x_1(t) \;\;,\;\;h(t) = 1 \;\;\textrm{Gli altri termini sono
      nulli}\\
    g_1(t) = 1 + \dfrac{1}{T}t
  \end{array}
  \right.
  \]
  \[
  \begin{array}{l}
    x_1(t) = 1 + \dfrac{1}{T}t\\
    x_1(t) = h(t) + \dfrac{r(t)}{T}
  \end{array}
  \]

\item $T \leq t \leq 2T$
  \[
   \left\{
   \begin{array}{l}
     g_1(t) = x_1(t) + x_2(t)  \;\;,\;\;h(t) = h(t - T) = 1, \;\;h(t -
     2T) = 0\\
     g_1(t) = 1 - \dfrac{1}{T}t\\
     x_1(t) = 1 + \dfrac{1}{T}t
   \end{array}
   \right.
   \]
   \[
   \begin{array}{l}
     x_1(t) + x_2(t) = 1 - \dfrac{1}{T}t\\
     x_2(t) = 1 - \dfrac{1}{T}t - 1 - \dfrac{1}{T}t\\
     x_2(t) = -\dfrac{2}{T}t\\
     x_2(t) =  -\dfrac{2}{T}t(t - T + T)\\
     x_2(t) = -2 - \dfrac{2}{T}(t - T)\\
     x_2(t) = -2h(t - T) - \dfrac{2}{T}r(t - T)
   \end{array}
   \]
 \item $t > 2T$
   \[
   \left\{
   \begin{array}{l}
     g_1(t) = x_1(t) + x_2(t) + x_3(t) \;\;h(t) = h(t - T) = h(t - 2T)
     = 1\\
     g_1(t) = 0\\
     x_1(t) = 1 + \dfrac{1}{T}t\\
     x_2(t) = - \dfrac{2}{T}t
   \end{array}
   \right.
   \]
   \[
   \begin{array}{l}
     x_1(t) + x_2(t) + x_3(t) = 0\\
     x_3(t) = - 1 - \dfrac{1}{T}t + \dfrac{2}{T}t\\
     x_3(t) = - 1 + \dfrac{1}{T}t\\
     x_3(t) =  - 1 + \dfrac{1}{T}(t - 2T + 2T)\\
     x_3(t) = 1 + \dfrac{1}{T}(t - 2T)\\
     x_3(t) = h(t - 2T) + \dfrac{1}{T}r(t - 2T)
   \end{array}
   \]
\end{itemize}
A questo punto possiamo ricomporre
\[
g_1(t) = h(t) + \dfrac{r(t)}{T} - 2h(t - T) - \dfrac{2}{T}r(t - T) +
h(t - 2T) + \dfrac{1}{T}r(t - 2T) 
\]
La trasformata di Laplace a questo punto \`e
\[
H_1(s) = \dfrac{1}{s} + \dfrac{1}{T s^2} - 2\dfrac{e^{-sT}}{s} -
2\dfrac{e^{-sT}}{T s^2} + \dfrac{e^{-2sT}}{s} + \dfrac{e^{-2sT}}{T
  s^2}
\]
Mettendo in evidenza $\dfrac{1}{s} + \dfrac{1}{T s^2}$ e ricordando
che $1 - 2 e^{-sT} + e^{-2sT} = (1 - e^{-sT})^2$ abbiamo
\begin{equation}\label{eq:ricostruttoreOrdineUno}
  H_1(s) = \dfrac{1 + Ts}{T} \left( \dfrac{1 - e^{-sT}}{s}\right)^2 =
  \dfrac{1 + Ts}{T} H_0^2(s)
\end{equation}
Pi\`u preciso dello ZOH, ma notevolmente pi\`u complicato.

\subsection{Ricostruttore frazionario}
Il ricostruttore frazionario \`e una variante del ricostruttore di
ordine uno. Il funzionamente \`e relativamente simile. L'unica
differenza sta nella pendenza della retta che collega due campioni
successivi: si considera una frazione $\alpha$ della pendenza della
retta del caso di ordine uno.
\begin{equation}
  \begin{array}{l}
    x_f(t) = x(kT) + \alpha \dfrac{x(kT) - x((k - 1)T)}{T}(t - kT)\\
    kT \leq t \leq (k + 1)T\\
    \alpha \in [0, 1]
  \end{array}
\end{equation}
\`E immediato notare che con
\begin{itemize}
\item $\alpha = 0$ otteniamo il ricostruttore di ordine zero;
\item $\alpha = 1$ otteniamo il ricostruttore di ordine uno.
\end{itemize}
\begin{figure}[!h]
  \begin{center}
    \includegraphics[scale=0.4]{./figures/ricostruttoreFrazionario00.png}
    \caption{Ricostruttore frazionario}\label{fig:ricostruttoreFrazionario00}
  \end{center}
\end{figure}
\begin{figure}[!h]
  \begin{center}
    \includegraphics[scale=0.5]{./figures/ricostruttoreFrazionario01.png}
    \caption{Ricostruttore frazionario - risposta
      impulsiva}\label{fig:ricostruttoreFrazionario01} 
  \end{center}
\end{figure}
\begin{equation}
\left\{
\begin{array}{ll}
  1 + \dfrac{\alpha}{T}t & 0 \leq t \leq T\\
  \alpha - \dfrac{\alpha}{T}t & T \leq t \leq 2T\\
  0 & t \geq 2T
\end{array}
\right.
\end{equation}
Applicando il procedimento mostrato per il ricostruttore di ordine
uno, otteniamo
\begin{equation}
  H_f(s) = \dfrac{\alpha + sT}{T}\left( \dfrac{1 -
    e^{-sT}}{s}\right)^2 + (1 - \alpha)\left( \dfrac{1 -
    e^{-sT}}{s}\right)^2 e^{-sT}
\end{equation}

\subsection{Ricostruttore ad uscita continua}
Tutti i ricostruttori visti finora presentano una discontinuit\`a  del
segnale di controllo $u(t)$ in uscita all'istante $T$ di commutazione
da un periodo all'altro. Questa discontinuit\`a pu\`o sollecitare
eccessivamente l'attuatore e provocare un'usura irregolare.

Il legame ingresso-uscita \`e
\begin{equation}
  x_c(t) = x((k - 1)T) + \dfrac{x(kT) - x((k - 1)T)}{T}(t - kT) \;\;\;
  kT \leq t \leq (k + 1)T
\end{equation}
\begin{itemize}
\item \`E un ricostruttore del primo ordine: una retta collega due
  campioni successivi;
\item La pendenza \`e pari al rapporto incrementale tra il campione e
  quello precedente;
\item Il punto di partenza coincide con il valore del campione $x((k -
  1)T)$ dell'istante precedente $t = (k -1)T$.
\end{itemize}
\begin{figure}[!h]
  \begin{center}
    \includegraphics[scale=0.4]{./figures/ricostruttoreContinuo00.png}
    \caption{Ricostruttore continuo}\label{fig:ricostruttoreContinuo00}
  \end{center}
\end{figure}
La figura~\ref{fig:ricostruttoreContinuo00} mostra un esempio di
ricostruttore continuo.
\begin{figure}[!h]
  \begin{center}
    \includegraphics[scale=0.5]{./figures/ricostruttoreContinuo01.png}
    \caption{Ricostruttore continuo - riposta
      impulsiva}\label{fig:ricostruttoreContinuo01} 
  \end{center}
\end{figure}
La figura\ref{fig:ricostruttoreContinuo01} mostra la risposta
impulsiva con
\begin{equation}
  g_1(t) = 
  \left\{
  \begin{array}{ll}
    \dfrac{1}{T}t & 0 \leq t \leq T\\
    - \dfrac{1}{T}t + 2 & T \leq t \leq 2T\\
    0 & t \geq 2 T
  \end{array}
  \right.
\end{equation}
Calcolando la risposta impulsiva complessiva $g_c(t)$, possiamo
calcolare la funzione di trasferimento $H_c(s)$:
\begin{equation}
  g_c(t) = \dfrac{1}{T} r(t) - \dfrac{2}{T}r(t - T) + \dfrac{1}{T}r(t
  - 2T)
\end{equation}
\begin{equation}
  H_c(s) = \dfrac{1}{T s^2}(1 - e^{-sT}) = \dfrac{1}{T}\left( \dfrac{1
  - e^{-sT}}{s}\right)^2
\end{equation}

\section{Risposta in frequenza dei ricostruttori}
Analizzando in frequenza i ricostruttori di ordine zero ed uno,
cerchiamo di capire quale possa approssimare meglio il filtro ideale
(\ref{filtroIdeale}).

\subsection{Risposta in frequenza del ricostruttore di ordine zero}
Ricordiamo la funzione di trasferimento
\[
H_0(s) = \dfrac{1 - e^{-sT}}{s}
\]
e lo spettro
\[
H_0(j \omega) = \dfrac{1 - e^{-j \omega T}}{j \omega}
\]
Mettiamo in evidenza il termine $e^{-j \omega \frac{T}{2}}$,
moltiplichiamo e dividiamo per 2 ed otteniamo
\[
H_0(j \omega) = \dfrac{2e^{-j \omega \frac{T}{2}}}{j \omega} \left(
\dfrac{e^{j \omega \frac{T}{2}} - e^{-j \omega \frac{T}{2}}}{2j}\right)
\]
Il termine tra parentesi \`e la forma di Eulero di un seno:
\[
H_0(j \omega) = \dfrac{2e^{-j \omega \frac{T}{2}}}{\omega} sin
\left(\omega \dfrac{T}{2} \right)
\]
Moltiplicando e dividendo per $T$, potremo riscrivere tutto come
\[
H_0(j \omega) = T \dfrac{sin \left(\omega \frac{T}{2} \right)}{\omega
\frac{T}{2}} e^{-j \omega \frac{T}{2}} = T\;sinc \left(\omega
\dfrac{T}{2} \right) e^{-j \omega \frac{T}{2}}
\]

\subsubsection{Analisi del modulo dello spettro $H_0(j \omega)$}
\[
|H_0(j \omega)| = \left| T\;sinc \left(\omega \dfrac{T}{2} \right)
e^{-j \omega \frac{T}{2}} \right|
\]
Se consideriamo che $|e^{-j \omega \frac{T}{2}} = 1$ e che $T$ \`e
costante:
\begin{equation}\label{eq:ricostruttoreOrdineZeroSpettro}
  |H_0(j \omega)| = T \left|sinc \left(\omega \dfrac{T}{2} \right)
  \right| 
\end{equation}
\begin{figure}[!h]
  \begin{center}
    \includegraphics[scale=0.5]{./figures/sincPositiva.png}
    \caption{Sinc positiva}\label{fig:sincPositiva}
  \end{center}
\end{figure}
La figura~\ref{fig:sincPositiva} mostra il grafico in scala lineare
dell'equazione~\ref{eq:ricostruttoreOrdineZeroSpettro} per le
sole~$\omega$~positive. 

Notiamo che la $sinc \left(\omega \dfrac{T}{2} \right)$ per $\omega =
0$ vale $T$, che va a compensare l'attenuazione di $\dfrac{1}{T}$
causata dal campionamento impulsivo. Pi\`u precisamente, per $\omega
\ll \omega_s$, nelle vicinanze dell'origine, possiamo approssimare
\begin{equation}
  \textrm{Per}\;\;\omega \ll \omega_s \Rightarrow
  \begin{array}{l}
    sin \left( \dfrac{\omega T}{2}\right) \approx \dfrac{\omega T}{2}\\
    sinc \left( \dfrac{\omega T}{2}\right) = 1\\
    |H_0(j \omega)| = T
  \end{array}
\end{equation}
e affermare con soddisfazione che il ricostruttore di ordine zero
approssima con efficacia il filtro ideale.

Al crescere di $\omega$, $sinc \left( \dfrac{\omega T}{2}\right)$
decresce fino ad annullarsi quando il $sin \left( \dfrac{\omega
  T}{2}\right)$ si annulla, cio\`e quando
\begin{equation}
  \begin{array}{l}
    \dfrac{\omega T}{2} = k \pi\\
    \omega = k \dfrac{2 \pi}{T}\\
    \omega = k \omega_s
  \end{array}
\end{equation}
L'approssimazione del filtro ideale non \`e pi\`u efficace come
nell'intorno dell'origine, ma pu\`o comunque bastare poich\`e, in fase
di campionamento impulsivo del segnale originario $x(t)$, abbiamo
scelto tempo di campionamento $T$ e pulsazione di campionamento
$\omega_s > 2 \omega_b$ tali da non riscontrare aliasing. Quindi,
tutte le informazioni di cui abbiamo bisogno per ricostruire il
segnale originario $x(t)$ di banda passante $\omega_b$ a partire dal
segnale $x_r(t)$ si trovano a pulsazione $\omega =
\dfrac{\omega_s}{2}$. In definitiva, non andremo mai oltre la
pulsazione $\dfrac{\omega_s}{2}$ e, scegliendo opportunamente $T$,
saremo sempre a basse frequenze, ottenendo una buona approssimazione
del filtro ideale.

\subsubsection{Analisi della fase dello spettro di $H_0(s)$}
\[
\begin{array}{l}
  Arg[H_0(j \omega)] = Arg \left[ T sinc \left(\omega \dfrac{T}{2}
    \right) e^{-j \omega \frac{T}{2}} \right] \\
  = Arg \left[ T \dfrac{sin\left( \omega \frac{T}{2}\right)}{\omega
      \frac{T}{2}} e^{-j \omega \frac{T}{2}} \right]\\
\end{array}
\]
I termini $T$ e $\omega \dfrac{T}{2}$ con $\omega > 0$ non hanno
contributo in fase perch\`e sono entrambi positivi.
\[
\begin{array}{l}
  = Arg \left[ sin\left( \omega \frac{T}{2}\right) e^{-j \omega
      \frac{T}{2}} \right]\\
  = Arg \left[ sin\left( \omega \frac{T}{2}\right) \right] Arg
  \left[e^{-j \omega \frac{T}{2}} \right]\\
  Arg[H_0(j \omega)] = Arg \left[ sin\left( \omega \frac{T}{2}\right)
    \right] - \omega \dfrac{T}{2} 
\end{array}
\]
Se consideriamo $Arg[H_0(j \omega)] = Arg \left[ T sinc \left(\omega
  \dfrac{T}{2} \right) e^{-j \omega \frac{T}{2}} \right]$
\begin{itemize}
\item il termine $T$ \`e un reale positivo che non d\`a contributo;
\item $sinc \left(\omega \dfrac{T}{2} \right)$ al variare di
  $\omega$ d\`a un contributo in fase di 0 o $2 \pi$;
\item $- sinc \left(\omega \dfrac{T}{2} \right)$ al variare di
  $\omega$ d\`a un contributo in fase di $\pi$ o $- \pi$;
\item $e^{-j \omega \frac{T}{2}}$ d\`a un contributo in fase di $-
  \omega \dfrac{T}{2}$, cio\`e una retta di pendenza $\dfrac{T}{2}$
\end{itemize}
come mostra la figura\ref{fig:ricostruttoreOrdineZeroSpettroFase}.

Nei punti di transizione, per $\dfrac{\omega T}{2} = k \pi \rightarrow
\omega = k \dfrac{2 \pi}{T} \rightarrow \omega = k \omega_s$, la
funzione $sin \left( \omega \dfrac{T}{2}\right)$ si annulla per poi
cambiare di segno aggiungendo $\pi$ a $Arg[H_0(j \omega)]$, che di
conseguenza si riporta a 0: per $\omega = k \omega_s$ compare una
discontinuit\`a di ampiezza $\pi$, visibile in
figura~\ref{fig:ricostruttoreOrdineZeroSpettroFase}.
\begin{figure}[!h]
  \begin{center}
    \includegraphics[scale=0.5]{./figures/ricostruttoreOrdineZeroSpettroFase.png}
    \caption{Ricostruttore ordine zero -
      Fase}\label{fig:ricostruttoreOrdineZeroSpettroFase} 
  \end{center}
\end{figure}

Ricapitolando, nelle strette vicinanze dell'origine, cio\`e per
$\omega \ll \omega_s$
\begin{itemize}
\item \`e possibile approssimare $sin \left( \dfrac{\omega
  T}{2}\right) \approx \dfrac{\omega T}{s} \rightarrow sinc \left(
  \dfrac{\omega T}{2}\right) = 1$ e quindi $|H_0(j \omega)| = T$
\item l'unico contributo in fase lo d\`a l'esponenziale $e^{-j \omega
  \frac{T}{2}}$ da cui $Arg[H_0(j \omega)] = - \omega \dfrac{T}{2}$
\end{itemize}

In conclusione
\begin{equation}
  H_0(j \omega) \approx T e^{-j \omega \frac{T}{2}}
  \;\;\textrm{per}\;\; \omega \ll \omega_s
\end{equation}
Scelto opportunamente il tempo di campionamento $T$, si riesce a
lavorare in una banda di frequenza $\omega$ in cui la presenza del
ricostruttore di ordine zero \`e modellata come un ritardo
$\dfrac{T}{2}$.

Il controllore digitale, quindi, \`e influenzato anche da un ritardo
pari a $\dfrac{T}{2}$ introdotto proprio dal ricostruttore ZOH sulla
catena di andata.

\subsection{Risposta in frequenza del ricostruttore di ordine uno}
\[
H_1(s) = \dfrac{1 + Ts}{T} \left( \dfrac{1 - e^{-sT}}{s}\right)^2
\]
\[
H_1(j \omega) = \dfrac{1 + j \omega T}{T} \left( \dfrac{1 - e^{-j
    \omega T}}{j \omega}\right)^2
\]
L'equazione~\ref{eq:ricostruttoreOrdineUno} ci ricorda che la funzione
di trasferimento del ricostruttore di ordine uno contiene la funzione
di trasferimento $H_0(s)$ del ricostruttore di ordine zero:
\[
H_1(j \omega) = \dfrac{1 + j \omega T}{T} \left[ T sinc\left( \omega
  \frac{T}{2}\right) e^{-j \omega \frac{T}{2}}\right]^2
\]
Sviluppando il quadrato e ordinando i termini, otteniamo:
\[
H_1(j \omega) = T sinc^2 \left( \dfrac{\omega T}{2}\right)(1 + j
\omega T)e^{-j \omega T}
\]

\subsubsection{Analisi del modulo dello spettro $H_1(j \omega)$}
\[
|H_1(j \omega)| = \left| T sinc^2 \left( \dfrac{\omega T}{2}\right)(1 + j
\omega T)e^{-j \omega T}\right|
\]
Considerando che l'esponenziale non d\`a contributo e $T$ pu\`o essere
portato fuori dal modulo, abbiamo
\[
|H_1(j \omega)| = T \left|sinc^2 \left( \dfrac{\omega T}{2}\right)\right| \sqrt{1 + \omega^2 T^2}
\]
\begin{figure}[!h]
  \begin{center}
    \includegraphics[scale=0.4]{./figures/ricostruttoreOrdineUnoSpettro00.png}
    \caption{Modulo spettro $H_1(j
      \omega)$}\label{fig:ricostruttoreOrdineUnoSpettro00} 
  \end{center}
\end{figure}
La figura\ref{fig:ricostruttoreOrdineUnoSpettro00} mostra il grafico
in scala lineare per le sole $\omega$ positive. All'aumentare di
$\omega$ il termine sotto radice fa aumentare il $|H_1(j \omega)|$,
che comincer\`a a diminuire dop ouna specifica pulsazione $\omega$, in
modo simile a quanto faceva $|H_0(j \omega)|$. Per valori di $\omega
\ll \omega_s$ possiamo approssimare $|H_1(j \omega) \approx T$.

\subsubsection{Analisi della fase dello spettro di $|H_1(j \omega)$}
\[
Arg \left[H_1(j \omega)|\right] = Arg \left[T \left|sinc^2 \left(
  \dfrac{\omega T}{2}\right)\right| \sqrt{1 + \omega^2 T^2}\right] 
\]
Per $\omega > 0$, $T$, $\omega \dfrac{T}{2}$ e $sinc^2 \left(
\dfrac{\omega T}{2}\right)$ non danno contributo in fase perch\`e sono
tutti reali positivi.
\[
Arg \left[H_1(j \omega)\right] = Arg \left[ (1 + j \omega T) e^{-j
    \omega T}\right] = Arg \left[1 + j \omega T \right] + Arg
\left[ e^{-j  \omega T} \right] = arctan(\omega T) - \omega T
\]
\begin{figure}[!h]
  \begin{center}
    \includegraphics[scale=0.5]{./figures/ricostruttoreOrdineUnoSpettroFase.png}
    \caption{}\label{fig:}
  \end{center}
\end{figure}
Notiamo che
\[
\lim_{\omega \to \infty} arctan(\omega T) = \dfrac{\pi}{2}
\]
e rimane costante a tale valore. Quando $\omega \in [0, \omega_s]$, la
funzione $arctan(\omega T)$ d\`a un certo contributo positivo in fase,
mentre l'esponenziale $e^{-jT}$ contribuisce con una retta $-\omega T$
di pendeza $-T$ che in $\omega_s$ varr\`a proprio $-2 \pi$. Di
conseguenza la fase di $H_1(s)$ assumer\`a un valore pari a $-2 \pi$
solo per pulsazioni $\omega > \omega_s$.

In analogia con quanto visto in precedenza, anche in questo caso ci
sar\`a una discontinuit\`a di ampiezza $-2 \pi$ e l'andamento si
ripeter\`a anche negli intervalli successivi proprio perch\`e per una
pulsazione $\omega > k\omega_s$ il contributo dovuto alla funzione
arcotangente si compenser\`a con quello dovuto all'esponenziale
$e^{-jT}$. In generale, quindi, l'introduzione del controllore
digitale comporta per $\omega \ll \omega_s$ un ritardo maggiore che
coincide con quello dovuto alla presenza del ricostruttore di ordine
uno e dunque all'esponenziale $e^{-j T}$.

\chapter{Corrispondenza tra piano $s$ e piano $z$}
A seguito del processo di campionamento impulsivo del segnale $x(t)$,
la trasformata da Laplace $X^{*}(s)$ del segnale campionato $x^{*}(t)$
\`e legata alla Z-trasformata $X(z)$ della sequenza di campioni
$x(kT)$ dalla relazione:
\[
X^{*}(s) = X(z)_{s = e^{sT}}
\]
Le variabil complesse $s$ e $x$ sono legate tra loro dalla relazione
fondamentale
\begin{equation}
  z = e^{sT} \;\;\; s = \dfrac{1}{T} \ln z
\end{equation}
Se consideriamo $s = \sigma + j \omega$, parte reale e parte
immaginaria, abbiamo che
\[
z = e^{(\sigma + j \omega)T} = e^{\sigma T} e^{j \omega T}
\]
Pe ogni punto nel piano $s$, identificato da parte reale e parte
immaginaria, abbiamo un punto nel piano $z$ identificato da un certo
modulo $\rho$ e una certa fase $\theta$:
\[
\rho = e^{\sigma T} \;\;\; \theta = \omega T
\]
\begin{figure}[!h]
  \begin{center}
    \includegraphics[scale=0.3]{./figures/pianoSpianoZ.png}
    \caption{Corrispondenza tra piano $s$ e piano
      $z$}\label{fig:pianoSpianoZ} 
  \end{center}
\end{figure}
Purtroppo, per\`o, riportare i punti del piano $s$ sul piano $z$ ci
svela una caratteristica del piano $z$: la circonferenza unitaria. I
punti sul piano $s$ si dispongono in ogni posizione, in base alla
parte reale e a quella immaginaria. Nel piano $z$ si dispongono in
funzione della circonferenza.

Per esempio, una serie di punti nel piano $s$ con parte reale costante
e parte immaginaria crescente si posizioner\`a sul piano $s$ con un
andamento ``verticale'': aumenta solo $\omega$. Sul piano $z$ questa
serie di punti si posizioner\`a su una circonferenza: $\rho =
e^{\sigma T}$ \`e costante, mentre la fase $\theta = \omega T$ aumenta
costantemente fino a completare la circonferenza. A questo punto, un
ulteriore aumento della fase $\theta$ ci porta ad avere un valore
della fase $\theta = \omega T + 2k \pi$. A questo punto, possiamo
riscrivere la relazione fondamentale come
\[
z = e^{(\sigma + j \omega)T} = e^{\sigma T} e^{j \omega T} = e^{\sigma
  T}e^{j(\omega T + 2k \pi)}
\]
Mettendo in evidenza $T$ nel secono esponenziale abbiamo
\[
z = e^{\sigma T}e^{j(\omega T + 2k \pi)} = e^{\sigma T} e^{j(\omega +
  \frac{2 k \pi}{T})T} = e^{\sigma T} e^{j(\omega + k \omega_s)T}
\]
con $\omega_s = 2 \pi f_s = \dfrac{2 \pi}{T}$.

Abbiamo finalmente definito il concetto di fascia
primaria\index{Fascia primaria}, mostrato nella
figura~\ref{fig:pianoSpianoZ}. La fascia primaria \`e la zona 
verticale del piano $s$ di ampiezza $\omega_s$ centrata in zero. La 
fascia primaria corriponde esattamente alla circonferenza primaria in
$z$. Le fascie esterne alla fascia primaria sono dette complementari e
nel piano $z$ sono le circonferenze multimple della circonferenze
primaria.

Le informazioni che abbiamo fino a questo momento ci consentono di
affermare che per ogni punto nel piano $s$ abbiamo un unico punto nel
piano $z$, ma per ogni punto nel piano $z$ abbiamo infiniti punti nel
piano $z$. Tutti questi punti sono posti su una immaginaria retta
verticale che ne mostra stessa parte reale $\sigma$ e parte
immaginaria $\omega$ traslata di $\pm k \omega_s$:
\begin{equation}
  z = e^{\sigma T} e^{j(\omega + k \omega_s)T}
\end{equation}

\subsubsection{Fascia primaria, tempo di campionamento e aliasing}
Supponiamo di essere nel piano $s$ ed aver scelto un particolare tempo
di campionamento $T$ e relativa pulsazione di campionamento
$\omega_s$, che identifica la fascia primaria. Notiamo che alcuni
punti sono esterni alla fascia primaria. Abbiamo evidentemente scelto
un tempo di campionamento errato e stiamo subendo l'effetto aliasing.

Scegliere correttamente il tempo di campionamento $T$, ci consente di
avere una fascia primaria che contenga senza difficolt\`a tutti i
nostri punti del piano $s$. Formalizzando, se tutti i poli della
funzione di trasferimento si trovano correttamente nella fascia
primaria, possiamo mappare biunivocamente il segnale dal piano $s$ al
piano $z$.

Quando qualche dinamica compare nella fascie complementari, a causa di
un errato tempo di campionamento $T$, il passaggio dal piano $s$ al
piano $z$ (il campionamento) mappa ugualmente la dinamica che si trova
nella fascia complementare (piano $s$) nella circonferenza primaria
(piano $z$). \`E evidente che quando si ritorner\`a al piano $s$, la
dinamica che inizialmente si trovava nella fascia complementare,
passando nel piano $z$, ritorna nel piano $s$ nella fascia primaria:
una componente ad alta frequenza viene riportata a bassa frequenza per
un errore di conversione ``piano $s$ - piano $z$'' causato da un
errore nella scelta del tempo di campionamento $T$. Questo ci porta
all'alising.

\section{Dal piano $s$ al piano $z$: variazioni della parte reale}
Vediamo come si rappresentano i punti nel piano $z$ in relazione alla
variazione della parte reale del punto nel piano $s$.
\begin{itemize}
\item $\sigma < 0$\\
  \`E la regione di piano $s$ che contiene i modi di evoluzione
  convergenti. Ognuno di questi punti \`e in corrispondenza con un
  punto interno alla circonferenza di raggio unitario. Nel piano $z$,
  la circonferenza unitaria \`e proprio la regione che contiene i modi
  di evoluzione convergenti:
  \[
  \sigma < 0 \Rightarrow |z| = e^{\sigma T} < 1
  \]
\item $\sigma = 0$\\
  Sono i punti che giacciano sull'asse immaginario. Sono i modi
  costanti, n\`e convergenti n\`e divergenti. Corrispondono ai punti
  che giacciano sulla circonferenza unitaria:
  \[
  \sigma = 0 \Rightarrow |z| = e^{\sigma T} = 1
  \]
\item $\sigma > 0$\\
  \`E la regione di piano $s$ che contiene i modi di evoluzione
  divergenti. Ognuno di questi punti \`e in corrispondenza con un
  punto esterno alla circonferenza di raggio unitario:
  \[
  \sigma > 0 \Rightarrow |z| = e^{\sigma T} > 1
  \]
\end{itemize}

\section{Parte reale $\sigma$ costante $\rightarrow z =
  e^{\overline{\sigma} T} e^{j \omega T}$ - Specifica sul tempo di
  assestamento $t_{a_{\varepsilon\%}}$}
Supponiamo di voler imporre una specifica sul tempo di assestamento
$t_{a_{\varepsilon\%}}$:
\begin{itemize}
\item Nel piano $s$, questa specifica corrisponde ad imporre che la
  parte reale $\sigma$ sia alla sinistra dell'asse $\overline{\sigma}$;
\item Nel piano $z$, equivale ad imporre un modulo $\rho$ costante,
cio\`e percorrere una circonferenza di raggio $|z| = e^{\sigma T}$.
\end{itemize}
Naturalmente in base al segno di $\sigma$, la circonferenza sar\`a
esterna o interna alla circonferenza unitaria, come mostrato in
figura~\ref{fig:pianoSsigmaCostante} 
\begin{figure}[!h]
  \begin{center}
    \includegraphics[scale=0.3]{./figures/pianoSsigmaCostante.png}
    \caption{Piano $s$ Piano $z$ - $\sigma$
      costante}\label{fig:pianoSsigmaCostante} 
  \end{center}
\end{figure}

\section{Pulsazione $\omega$ costante $\rightarrow z = e^{\sigma T}
  e^{j \overline{\omega} T}$}
\begin{figure}[!h]
  \begin{center}
    \includegraphics[scale=0.3]{./figures/pianoSomegaCostante.png}
    \caption{Piano $s$ Piano $z$ - $\omega$
      costante}\label{fig:pianoSomegaCostante}
  \end{center}
\end{figure}
Nel caso volessimo imporre una pulsazione costante, la
figura~\ref{fig:pianoSomegaCostante} ci mostra l'andamento sia nel
piano $s$ che nel piano $z$. Nel piano $s$ avermo una variazione della
sola parte reale dei punti, mentre nel piano $z$ avermo una fase
$\theta = \omega T$ costante e un modulo $\rho = e^{\sigma T}$ che
varier\`a. I colori mostrano con chiarezza come l'attraversamente
dell'asse immaginario in $s$ corrisponda all'attraversamento della
circonferenza unitaria in $z$: il passaggio da modi stabili
convergenti a modi instabili divergenti.

\section{Coefficiente di smorzamento costante $\overline{\zeta}$}
Una specifica sul coefficiente di smorzamento, si traduce nel piano
$s$ con una limitazione nella posizione dei punti nel piano. Il piano
viene limitato grazie a due semirette che partono dall'origine, come
mostrato in precedenza nella figura~\ref{fig:vincoliLuogo}, con un
angolo pari a $arcocos \zeta$.

Se consideriamo le due seguenti espressioni:
\begin{equation}\label{eq:zetaSigmaOmega}
\begin{array}{l}
  \sigma = - \zeta \omega_n\\
  \omega = \omega_n \sqrt{1 - \zeta^2}
\end{array}
\end{equation}
ci rendiamo conto anche dal punto di vista matematico che lo
smorzamento influenza sia la parte reale che la parte immaginaria dei
punti. Nel piano $z$ questo si traduce nell'influenzare sia il modulo
$\rho$ che la fase $\theta$:
\[
\begin{array}{l}
  \rho = e^{\sigma T}\\
  \theta = \omega T
\end{array}
\]
Se sostituiamo i valori dell'equazione~\ref{eq:zetaSigmaOmega}, otteniamo
\begin{equation}
  \begin{array}{l}
    \rho = e^{- \zeta \omega_n T}\\
    \theta = \omega_n \sqrt{1 - \zeta^2} T\\
    z = e^{sT} = e^{\sigma T}e^{j \omega T} = e^{[- \zeta \omega_n T]}
    e^{[\omega_n \sqrt{1 - \zeta^2}T]}
  \end{array}
\end{equation}
Notiamo subito che il modulo $\rho$ \`e un esponenziale negativo
convergente, poich\`e la pulsazione natura, il tempo di campionamento
e lo smorzamento sono valori positivi, mentre la fase \`e un valore
positivo. L'andamente nel piano $z$ sar\`a quindi un prodotto di un
esponenziale positivo e uno negativo: l'andamento a spirale mostrato
in figura~\ref{fig:pianoSsmorzamentoCostante}.
\begin{figure}[!h]
  \begin{center}
    \includegraphics[scale=0.3]{./figures/pianoSsmorzamentoCostante.png}
    \caption{Piano $s$ Piano $z$ - $\zeta$
      costante}\label{fig:pianoSsmorzamentoCostante}
  \end{center}
\end{figure}

\subsection{Smorzamento costante limitato alla fascia primaria}
Ipotizziamo di trovarci nel piano $s$ con $\omega \in \left(
-\dfrac{\omega_s}{2}, \dfrac{\omega_s}{2} \right)$ e $0 < \zeta < 1$.
\begin{figure}[!h]
  \begin{center}
    \includegraphics[scale=0.3]{./figures/pianoSsmorzamentoCostanteCardioide.png}
    \caption{Piano $s$ Piano $z$ - $\zeta$
      costante in fascia primaria}\label{fig:pianoSsmorzamentoCostanteCardioide}
  \end{center}
\end{figure}
La figura\ref{fig:pianoSsmorzamentoCostanteCardioide} mostra come le
spirali varino all'avvicinarsi di $\zeta$ ad 1.

\section{Pulsazione $\omega_n$ costante}
\begin{figure}[!h]
  \begin{center}
    \includegraphics[scale=0.3]{./figures/pianoSpulsazioneNaturaleCostante.png}
    \caption{Piano $s$ Piano $z$ - $\omega_n$
      costante}\label{fig:pianoSpulsazioneNaturaleCostantee}
  \end{center}
\end{figure}
La figura~\ref{fig:pianoSpulsazioneNaturaleCostantee} mostra
l'andamento dei punti nel piano $z$ per una pulsazione naturale
$\omega_n$ costante. Nel piano $s$, al crescere di $\omega_n$ cresce
il raggio della semicirconferenza centrata in zero. Nel piano $z$, la
semicirconferenza muove da destra a sinistra sempre pi\`u curva, fino
a diventare una curva che parte dalla circonferenza unitaria e
attraversa l'asse reale a destra dell'asse immaginario.




\begin{figure}[!h]
  \begin{center}
%    \includegraphics[scale=0.5]{./figures/ricostruttoreOrdineUnoSpettro00.png}
    \caption{}\label{fig:}
  \end{center}
\end{figure}


% APPENDICI
\appendix
\chapter {Calcolo della Jacobiana per la valutazione della stabilit\`a}\label{apx:jacob}
Per valutare il tipo (stabile o instabile) di un punto di equilibrio,
si pu\`o procedere calcolando gli autovalori del determinante di una
matrice detta \textsl{Jacobiana}. In particolare essa si calcola come
segue:
\begin{equation}\label{eq:jacobian}
  J\triangleq (\lambda I - A)~\footnote{$I$ \`e la matrice identit\`a}
\end{equation}
dove $A$ \`e la matrice della dinamica trattata nel paragrafo
\ref{eq:matrix}.\\
Calcolando poi il suo determinante
\begin{displaymath}
\det(\lambda I -A)
\end{displaymath}
si trova un'equazione che rappresenta il l \emph{polinomio
  caratteristico} associato ad A, le cui radici sono proprio gli
autovalori utilizzati per valutare il tipo del punto di eq. scelto. In
particolare: 
\begin{itemize}
\item[*] Se l'autovalore ha $\Re>0 \Longrightarrow$ Il p.e. \`e
  \textbf{INSTABILE} 
\item[*] Se l'autovalore ha $\Re<0 \Longrightarrow$ Il p.e. \`e
  \textbf{STABILE} 
\end{itemize}
Un generico esempio del calcolo della \emph{Jacobiana} lo si pu\`o
trovare nell'Appendice \ref{apx:stabil} 

\chapter{Considerazioni sul polinomio caratteristico e regola di
  Cartesio}\label{apx:stabil} 
Per un sistema del $II$ ordine
\begin{displaymath}
  A=\left[
    \begin {array}	{ll} 
      a_{11} & a_{12}\\
      a_{21} & a_{22}
    \end{array}\right]
\end{displaymath}
ed il polinomio caratteristico associato ad A \`e:
\begin{displaymath}
  |\lambda I-A| = \left|
  \begin{array}{ll}(\lambda
    -a_{11})&-a_{12}\\-a_{21} & (\lambda -a_{22})
  \end{array}\right|
\end{displaymath}
Calcolando il $\det(\lambda I - A)$ si ha:
\begin{displaymath}
  \lambda^2 + \lambda\underbrace{(-a_{11}-a_{12})}_b\underbrace{-a_{12}a_{21}}_c =
\end{displaymath}
\begin{displaymath}
  =\lambda^2+b\lambda+c
\end{displaymath}
I coefficienti sono \qquad 1 \qquad b \qquad c \qquad e possiamo fare
le seguenti considerazioni: 
\begin {itemize}
\item if $b$,$c$ sono $>0$  $\Rightarrow$  le radici sono a parte reale negativa
\item if $b>0$, ma $c<0$   $\Rightarrow$  ho una radice a parte reale positiva
\item if $b$,$c$ sono $<0$  $\Rightarrow$  ho una radice a parte reale positiva
\item if $b<0$ e $c >0$  $\Rightarrow$  ho due radici a parte reale positiva
\end{itemize}
In generale: 
\newtheorem{cartesio}{Theorem}[chapter]
\begin{cartesio}
  $(\star) ~a\lambda^2+b\lambda+c \qquad \qquad a,b,c \in \Re$\\
  ($\star$) ha tante radici a parte $\Re$ positiva quante sono le
  variazioni di segno tra i suoi coefficienti ordinati secondo le
  potenze crescenti di $\lambda$.
\end{cartesio}

Casi:
\begin{enumerate}
\item $a,b,c>0 \\
  ac>0 \Rightarrow |\Delta|=|b^2-4ac|<b^2$ e $\lambda_{1,2}=
  \frac{-b\pm\sqrt{b^2-4ac}}{2a} < 0$\\
  quindi si avranno parti $\Re$ negative
\item $a,b>0$\\
  $c<0\Rightarrow ac<0 \Rightarrow|\Delta|>b^2$\\
  $\Re\{\lambda_{1,2}\}\`e\left\{\begin{array}{l}<0 \qquad per + \\ >
  0 \qquad per - \end{array}\right.$
\item $a,c>0$\\
  $b<0 \Rightarrow a,c>0\Rightarrow
  \Re\{\lambda{1,2}\}\`e\left\{\begin{array}{l}> 0 \qquad per + \\ >0
  \qquad per - \end{array}\right.$
\end{enumerate}
Per i polinomi di grado n si applica il criterio di Routh \ref{pg:routh}.

\subsection{Interludio sulla stabilit\`a valutata con il criterio di Routh}
\`E importante sottolineare che per valutare la stabilit\`a del
sistema, quando si hanno a disposizione tutti i valori della prima
colonna della tabella di Routh, bisogna effettuare
un'\textbf{\emph{intersezione}} delle soluzioni trovate per ogni
coefficiente. In particolare prendendo in considerazione un polinomio
del tipo 
\begin{displaymath}
  a \lambda^2 + b\lambda + c
\end{displaymath}
se $a$ \`e concorde col segno della disequazione allora si considera
positiva la porzione dell'asse (su cui si riportano le radici della
disequazione) individuata da
$segmento>\lambda_1$ e $segmento<\lambda_2$.\\
Dualmente se $a$ \`e discorde col segno della disequazione allora la
positivit\`a si ha per $segmento<\lambda_1$ e $segmento>\lambda_2$\\
con
\begin{displaymath}
  \lambda_1= \frac{-b +\sqrt{b^2 - 4ac}}{2a}\\
  \lambda_2= \frac{-b -\sqrt{b^2 - 4ac}}{2a}
\end{displaymath}
~\footnote{Per le disequazioni fratte, bisogna valutare il segno}


\chapter{Trasformata di Laplace}\label{apx:laplace}\index{Trasformata
  di Laplace}
{\em La trasformata di Laplace di una funzione $f(t)$ \`e una funzione
lineare che permette di passare dallo studio di una variabile
temporale (reale) allo studio di una variabile complessa, e
viceversa.}

Supponiamo di avere una funzione complessa $f$ della variabile reale
$t$. Supponiamo di avere $s = \sigma + j \omega \in C$, una variabile
complessa di parte reale $\sigma$ e coefficiente della parte
immaginaria $j$ pari a $\omega$. Per convenzione:
\[
f(t) = 0 \;per\; t < 0
\]
Se la funzione
\begin{equation}\label{eq:laplaceq}
  F(s) = \int_{0}^{+\infty}f(t)\; e^{-st} dt
\end{equation}
estiste almeno per qualche valore di s, essa di dice {\em trasformata
  di Laplace di $f(t)$}.
La trasformata di Laplace della funzione $f(t)$ si denota come: 
\[
F(s) = \mathfrak{L}\{f(t)\}
\]
L'antitrasformata di Laplace\index{Antitrasformata di Laplace} si
denota come: 
\[
f(t)=\mathfrak{L^{-1}}\{F(s)\} = \dfrac{1}{2 \pi j} \int_{\sigma - j
  \infty}^{\sigma + j \infty} F(s)\; e^{st} ds
\]
Analizzando la \ref{eq:laplaceq}, si ha:
\begin{displaymath}
  e^{-st} = e^{-(\sigma + j \omega)t} = e^{-\sigma t}e^{-j\omega t} =
  e^{-\sigma t}\underbrace{(\cos(\omega t)-j \sin(\omega
    t)}_{e^{-j\omega t}}) = \frac{1}{e^{\sigma t}}\frac{1}{e^{j \omega t}} 
\end{displaymath}
La funzione \`e definita solo per $\sigma > 0$, quindi la trasformata
\`e definita solo per valori di $s$ tali che l'equazione
\ref{eq:laplaceq} converga, cio\`e $Re(s) > 0$.

Come gi\`a datto, se $F(s)$ esiste pe run valore $s = \sigma + j
\omega$, allora esiste per tutti i valori di $s$ tali che $Re(s)
\geq \sigma$. Il pi\`u piccolo valore di $\sigma$ per cui esiste
$F(s)$ viene detto {\em ascissa di convergenza}\index{Ascissa di
  convergenza} e la regione a destra di $Re(s) \geq \sigma$ \`e detta
{\em regione di convergenza}\index{Regione di convergenza}.

%% Trasformatate DELL'IMPULSO
\section{Tasformata dell'impulso}\index{Trasformata dell'impulso}
Sia
\[
f(t) = imp(t)
\]
per una qualunque $s$, si ottiene:
\begin{equation}
  \mathfrak{L}[imp(t)] = \int_{0^-}^{+\infty} imp(t)\; e^{-st} dt =
  e^{-s0} = 1
\end{equation}

\section{Trasformata del gradino}\index{Trasformata del gradino}
Sia
\[
f(t) = sca(t)
\]
si ottiene
\[
\mathfrak{L}[sca(t)] = \int_{0}^{+\infty} sca(t)\; e^{-st} dt =
\int_{0}^{+\infty} e^{-st} = \left
. \dfrac{e^{-st}}{-s}\right|^{+\infty}_{0} =
\]
\[
 = \left . \left [ \dfrac{e^{-\sigma
    t}}{-(\sigma + j \omega)} (cos(\omega t)) - j sin(\omega t)
  \right] \right|^{+\infty}_{0}
\]
e per $\sigma > 0$
\begin{equation}\label{Trasformata del gradino}
  \mathfrak{L}[sca(t)] = \dfrac{0 - 1}{- (\sigma + j \omega)} = \dfrac{1}{s}
\end{equation}
Dai calcoli, ci accorgiamo che $\bar{\sigma} = 0$, ma $\dfrac{1}{s}$
\`e definito per qualsiasi $s \neq 0$.

\section{Trasformata dell'esponenziale}

\section{Trasformata della rampa}


\section {Propriet\`a della trasformata}
\begin{itemize}
\item{ \textbf{Linearit\`a}: la trasformata di Laplace \`e lineare ovvero: 
  \begin{equation}\label{eq:laplinear}
    \mathfrak{L}[af(t)+bg(t)]=aF(s)+bG(s) \longrightarrow \textrm{$f$
      e $g$ sono funzioni e a e b sono} \in \mathbb{C}
\end{equation}
}
\item{\textbf{Traslazione nel dominio del tempo}: Se si trasla la
  funzione $f(t)$ di una quantit\`a $\tau>0$, ovvero si considera 
  $\hat{f}(t)=f(t-\tau)$, si trova: 
\begin{equation}\label{eq:laptraslt}
  \mathfrak{L}\{\hat{f}(t)\} = \mathfrak{L}\{f(t-\tau\} = e^{-s\tau}F(s)
\end{equation}
}
\item{\textbf{Traslazione nel dominio della variabile complessa}: Sia
  $\alpha \in \mathbb{C}$ e si consideri la funzione
  $\hat{f}(t)=e^{\alpha t}f(t)$ allora la sua trasformata di Laplace sar\`a: 
  \begin{equation}\label{eq:laptrasls}
    \mathfrak{L}\{\hat{f}(t)\}=\mathfrak{L}\{e^{\alpha t}f(t)\}=F(s-\alpha)
  \end{equation}
}
\item{\textbf{Derivazione nel dominio del tempo}: Se $f(t)$ \`e
  derivabile allora risulta:
\begin{eqnarray}\label{eq:lapdert}
  \mathfrak{L}\{\dot f (t)\}=sF(s)-f(0) \longrightarrow \textrm{derivata prima} \\
  \mathfrak{L}\{\ddot f (t)\}=s^2F(s)-sf(0)-\dot f(0) \longrightarrow \textrm{derivata seconda} \\
  \textsl{in generale} ~\mathfrak{L}\{\frac{d^nf(t)}{dt^n}\}=s^nF(s) -
  \sum\limits_{i=1}^n s^{n-i} \frac{d^{i-1}f(t)}{dt^{i-1}}\Bigg |_{t=0}
\end{eqnarray}
ovvero $s$ \`e l'\emph{operatore di derivazione}.
}
\item{\textbf{Derivazione nel dominio della variabile complessa}: Si
  suppone che $F(s)$ sia derivabile $\forall s$ allora: 
\begin{equation}\label{eq:lapders}
  \mathfrak{L}\{tf(t)\}=-\frac{dF(s)}{ds}
\end{equation}
}
\item{\textbf{Integrazione nel dominio del tempo}: 
\begin{equation}\label{eq:lapintt}
  \mathfrak{L} \left\{ \int_{0}^{t} f(\tau)d\tau \right\} = \frac{1}{s}F(s)
\end{equation}
ovvero $\frac{1}{s}$ \`e l'\emph{operatore di integrazione}.
}
\item{\textbf{Convoluzione nel dominio del tempo}: Il \emph{prodotto
    di convoluzione} di due funzioni $f$ e $g$ si calcola come segue: 
\begin{displaymath}
  f(t)\ast g(t)=\int_{-\infty}^{+\infty}f(\tau)g(t-\tau)d\tau =
  \int_{-\infty}^{+\infty}f(t-\eta)g(\eta)d\eta = g(t)\ast f(t)
\end{displaymath}
Siccome consideriamo per convenzione segnali che prima dello zero sono
nulli allora si ha: 
\begin{displaymath}
  f(t)\ast g(t) =
  \int_{0}^{t}f(\tau)g(t-\tau)d\tau=\int_{0}^{t}f(t-\eta)g(\eta)d\eta
  = g(t)\ast f(t)
\end{displaymath}
e quindi:
\begin{equation}\label{eq:lapconvt}
  \mathfrak{L}\{f(t)\ast g(t)\} = F(s)G(s)
\end{equation}
ovvero, la convoluzione nel tempo equivale ad un prodotto nel dominio di Laplace.
}
\end{itemize}
La tabella riassuntiva delle principali trasformate di Laplace per i
vari segnali la si pu\`o trovare nel testo di
riferimento. \cite{FCAlaptab}

ESEMPIO: Trasformata di una costante~\footnote{\`e il gradino}
$\delta_{-1}(t)$~\footnote{Per annullare una funzione prima dello 0,
  la moltiplico per $\delta_{-1}(t)$}\\
Sia
\begin{displaymath}
  f(t) = \delta_{-1}(t)\left\{
\begin{array}{ll}
  1 & t\ge0\\
  0&t<0
\end{array}\right.
\end{displaymath}
allora
\begin{displaymath}
  \delta_{-1}(t)\stackrel{\mathfrak{L}}{\longrightarrow}\Delta_{-1}(s)
\end{displaymath}
\begin{displaymath}
f(A)\stackrel{\mathfrak{L}}{\longrightarrow}A\Delta_{-1}(s)
\end{displaymath}
In particolare la $\mathfrak{L}\{\delta_{-1}(t)\}$ si calcola come segue:
\begin{equation}\label{eq:laptransfsca}
  \int_{0}^{+\infty}\delta_{-1}(t)e^{-st}dt=
\end{equation}
\begin{displaymath}
  = -\frac{1}{s}e^{-st}\Bigg |_{0}^{+\infty} =
  \frac{1}{s}\left[e^{-st}\Bigg |_{t=0} - e^{-st} \Bigg |_{t \to
      \infty} \right ]=
\end{displaymath}
\begin{displaymath}
  = \frac{1}{s}\left[1-e^{-st}\Bigg |_{t \to \infty}\right]
\end{displaymath}
...per $e^{-st}\Bigg |_{t \to \infty}$ dobbiamo valutare il $\lim_{t
  \to \infty}$: 
\begin{displaymath}
  \lim_{t \to \infty} e^{-st} = \lim_{t \to \infty} \frac{1}{e^{\alpha
      t}}\frac{1}{e^{j\omega t}} = \lim_{t \to
    \infty}\frac{1}{e^{\alpha t}}\left( \cos(\omega t)-j\sin(\omega
  t)\right) = \bigoplus
\end{displaymath}
...ho tre variabili: $t$,$\omega$,$\alpha$; il limite lo valuto per t,
quindi tale limite ``sembrerebbe'' dipendere da $\alpha$ e $\omega$
(in realt\`a solo da $\alpha$) per cui:
\begin{displaymath}
  \lim_{t \to \infty}e^{-st} = \left\{
  \begin{array}{ll}
    0 & \textrm{if} ~\alpha >0 \\
    \nexists & \textrm{if} ~\alpha =0\\
    \nexists & \textrm{if} ~\alpha <0
  \end{array}\right.
\end{displaymath}
quindi il limite esiste solo per $\alpha >0$ e vale:
\begin{displaymath}
  \bigoplus = \frac{1}{s}-0 = \frac{1}{s}
\end{displaymath}
Se $\alpha = 0$ ho l'\emph{ascissa di convergenza} (figura
\ref{fig:fig5}) della trasformata di Laplace
\begin{figure}[!hbp]
  \begin{center}
    \includegraphics[scale=0.5]{./figures/semipconv.png}
    \caption{Semipiano di convergenza}\label{fig:fig5}
  \end{center}
\end{figure} 
Il semipiano di convergenza \`e la parte a destra dell'asse $\Im m$
(equazione $\alpha=0$ ovvero $\Re\{s\}=0$) tale che $\Re(s)>0$ ed \`e
quindi definito il $\lim_{t \to \infty}e^{-st}$ ovvero risulta
soddisfatta la condizione affinch\`e l'integrale \ref{eq:laptransfsca}
converga.

Si possono introdurre  due importanti teoremi che legano il
guadagno statico (\ref{ch:chapter4}) di un sistema con la sua Funzione
di Trasferimento (\ref{ch:chapter4}). Questi teoremi sono:

\section{Teorema del valore iniziale}
Data la funzione $f(t)$ tale che la sua trasformata sia razionale e
con grado del denominatore maggiore del grado del numeratore, allora:
\begin{equation}
  \lim_{s \to \infty} sF(s)=f(0)
\end{equation}

Nota: il teorema \`e valido che per funzioni non razionali, ma $f(0)$
deve essere definito.

\section{Teorema del valore finale}\label{teoremaValoreFinale}
Data la funzione $f(t)$ tale che la sua trasformata sia razionale e
con grado del denominatore maggiore del grado del numeratore e poli
nulli o con parte reale negativa, allora:
\begin{equation}
  \lim_{t \to \infty} f(t)=\lim_{s \to 0} s F(s)
\end{equation}
Nota: il teorema \`e valido che per funzioni non razionali, ma $f(0)$
deve essere definito.






\begin{figure}[!hbp]
  \begin{center}
%    \includegraphics[scale=0.5]{./figures/}
    \caption{}\label{fig:}
  \end{center}
\end{figure} 

\begin{thebibliography}{99}
\bibitem{FCA} Bolzen, Scattolini, Schiavoni: \emph{Fondamenti di controlli automatici ed. 2} - CAP.2 Par. 2.2.3
\bibitem{FCAlaptab} Bolzen, Scattolini, Schiavoni: \emph{Fondamenti di controlli automatici ed. 2} - Appendice B Pag. 515
\bibitem{FCAimg} Figure prese da: Bolzen, Scattolini, Schiavoni: \emph{Fondamenti di controlli automatici ed. 2} 
\end{thebibliography}

\printindex
\end{document}
